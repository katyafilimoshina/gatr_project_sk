{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and installs"
      ],
      "metadata": {
        "id": "LIZlu957c-bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7Qvgc13tIaV",
        "outputId": "06f6f74d-140c-4a3c-a57f-31aef2ae5efc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_-Y5s31mA0d",
        "outputId": "d03e3f4a-5b6c-4b82-939a-4b5b1dc42c1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'geometric-algebra-transformer'...\n",
            "remote: Enumerating objects: 369, done.\u001b[K\n",
            "remote: Counting objects: 100% (369/369), done.\u001b[K\n",
            "remote: Compressing objects: 100% (253/253), done.\u001b[K\n",
            "remote: Total 369 (delta 171), reused 304 (delta 112), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (369/369), 386.79 KiB | 12.09 MiB/s, done.\n",
            "Resolving deltas: 100% (171/171), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/Qualcomm-AI-research/geometric-algebra-transformer.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigate into the project directory\n",
        "%cd geometric-algebra-transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHpyYNoNm1Wh",
        "outputId": "0986def1-f82e-43fe-dd20-bc8dfee21400"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision numpy mlflow hydra-core omegaconf xformers torch_ema e3nn torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONt5Kgvpmmny",
        "outputId": "5121aa54-f829-4627-85a1-e9770a0af637"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.28.post1)\n",
            "Requirement already satisfied: torch_ema in /usr/local/lib/python3.10/dist-packages (0.3)\n",
            "Requirement already satisfied: e3nn in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: mlflow-skinny==2.17.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.17.0)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.3)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.4)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<18,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (16.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.36)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.0)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (0.36.0)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.43)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (24.1)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.20.3)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (0.5.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: opt-einsum-fx>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from e3nn) (0.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.10)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.6)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.5)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from opt-einsum-fx>=0.1.4->e3nn) (3.4.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (2024.8.30)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.15.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (2.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (4.0.11)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.0->mlflow) (3.20.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.2.14)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (75.1.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (0.37b0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric) (0.2.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall dgl -y  # Remove any existing DGL installation\n",
        "# !pip install dgl-cu118 dglgo -f https://data.dgl.ai/wheels/repo.html  # Install DGL for CUDA 11.8 (matching Colab environment)\n",
        "!pip install  dgl -f https://data.dgl.ai/wheels/torch-2.1/repo.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT3-cG48oCW1",
        "outputId": "e7cab869-d5dd-4cf6-8c8d-8cf5d44644cb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping dgl as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in links: https://data.dgl.ai/wheels/torch-2.1/repo.html\n",
            "Collecting dgl\n",
            "  Using cached https://data.dgl.ai/wheels/torch-2.1/dgl-2.4.0-cp310-cp310-manylinux1_x86_64.whl (7.8 MB)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dgl) (24.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgl) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.9.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from dgl) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.5)\n",
            "Collecting torch<=2.4.0 (from dgl)\n",
            "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch<=2.4.0->dgl)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<=2.4.0->dgl) (12.6.77)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<=2.4.0->dgl) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<=2.4.0->dgl) (1.3.0)\n",
            "Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, dgl\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.0.50\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.0.50:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.0.50\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.1+cu121\n",
            "    Uninstalling torch-2.4.1+cu121:\n",
            "      Successfully uninstalled torch-2.4.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.4.0 which is incompatible.\n",
            "torchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 2.4.0 which is incompatible.\n",
            "xformers 0.0.28.post1 requires torch==2.4.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dgl-2.4.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0 triton-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+${cpu}.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8E_JNpRp_pd",
        "outputId": "53b09f1b-dfa6-4916-f0da-793f4cd16609"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+.html\n",
            "Collecting torch-scatter\n",
            "  Using cached torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl size=3658842 sha256=03cd4699a7ed0ba8486597c1d8839c06ba20387d14d470260f38aa3776d0e52f\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/f1/2b/3b46d54b134259f58c8363568569053248040859b1a145b3ce\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to deal with geometric algebra:"
      ],
      "metadata": {
        "id": "GoiM9suAE3y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import itertools\n",
        "import operator\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "# copied from the itertools docs\n",
        "def _powerset(iterable):\n",
        "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
        "    s = list(iterable)\n",
        "    return itertools.chain.from_iterable(itertools.combinations(s, r) for r in range(len(s) + 1))\n",
        "\n",
        "\n",
        "class ShortLexBasisBladeOrder:\n",
        "    def __init__(self, n_vectors):\n",
        "        self.index_to_bitmap = torch.empty(2**n_vectors, dtype=int)\n",
        "        self.grades = torch.empty(2**n_vectors, dtype=int)\n",
        "        self.bitmap_to_index = torch.empty(2**n_vectors, dtype=int)\n",
        "\n",
        "        for i, t in enumerate(_powerset([1 << i for i in range(n_vectors)])):\n",
        "            bitmap = functools.reduce(operator.or_, t, 0)\n",
        "            self.index_to_bitmap[i] = bitmap\n",
        "            self.grades[i] = len(t)\n",
        "            self.bitmap_to_index[bitmap] = i\n",
        "            del t  # enables an optimization inside itertools.combinations\n",
        "\n",
        "\n",
        "def set_bit_indices(x: int):\n",
        "    \"\"\"Iterate over the indices of bits set to 1 in `x`, in ascending order\"\"\"\n",
        "    n = 0\n",
        "    while x > 0:\n",
        "        if x & 1:\n",
        "            yield n\n",
        "        x = x >> 1\n",
        "        n = n + 1\n",
        "\n",
        "\n",
        "def count_set_bits(bitmap: int) -> int:\n",
        "    \"\"\"Counts the number of bits set to 1 in bitmap\"\"\"\n",
        "    count = 0\n",
        "    for i in set_bit_indices(bitmap):\n",
        "        count += 1\n",
        "    return count\n",
        "\n",
        "\n",
        "def canonical_reordering_sign_euclidean(bitmap_a, bitmap_b):\n",
        "    \"\"\"\n",
        "    Computes the sign for the product of bitmap_a and bitmap_b\n",
        "    assuming a euclidean metric\n",
        "    \"\"\"\n",
        "    a = bitmap_a >> 1\n",
        "    sum_value = 0\n",
        "    while a != 0:\n",
        "        sum_value = sum_value + count_set_bits(a & bitmap_b)\n",
        "        a = a >> 1\n",
        "    if (sum_value & 1) == 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "\n",
        "def canonical_reordering_sign(bitmap_a, bitmap_b, metric):\n",
        "    \"\"\"\n",
        "    Computes the sign for the product of bitmap_a and bitmap_b\n",
        "    given the supplied metric\n",
        "    \"\"\"\n",
        "    bitmap = bitmap_a & bitmap_b\n",
        "    output_sign = canonical_reordering_sign_euclidean(bitmap_a, bitmap_b)\n",
        "    i = 0\n",
        "    while bitmap != 0:\n",
        "        if (bitmap & 1) != 0:\n",
        "            output_sign *= metric[i]\n",
        "        i = i + 1\n",
        "        bitmap = bitmap >> 1\n",
        "    return output_sign\n",
        "\n",
        "\n",
        "def gmt_element(bitmap_a, bitmap_b, sig_array):\n",
        "    \"\"\"\n",
        "    Element of the geometric multiplication table given blades a, b.\n",
        "    The implementation used here is described in :cite:`ga4cs` chapter 19.\n",
        "    \"\"\"\n",
        "    output_sign = canonical_reordering_sign(bitmap_a, bitmap_b, sig_array)\n",
        "    output_bitmap = bitmap_a ^ bitmap_b\n",
        "    return output_bitmap, output_sign\n",
        "\n",
        "\n",
        "def construct_gmt(index_to_bitmap, bitmap_to_index, signature):\n",
        "    n = len(index_to_bitmap)\n",
        "    array_length = int(n * n)\n",
        "    coords = torch.zeros((3, array_length), dtype=torch.uint8)\n",
        "    k_list = coords[0, :]\n",
        "    l_list = coords[1, :]\n",
        "    m_list = coords[2, :]\n",
        "\n",
        "    # use as small a type as possible to minimize type promotion\n",
        "    mult_table_vals = torch.zeros(array_length)\n",
        "\n",
        "    for i in range(n):\n",
        "        bitmap_i = index_to_bitmap[i]\n",
        "\n",
        "        for j in range(n):\n",
        "            bitmap_j = index_to_bitmap[j]\n",
        "            bitmap_v, mul = gmt_element(bitmap_i, bitmap_j, signature)\n",
        "            v = bitmap_to_index[bitmap_v]\n",
        "\n",
        "            list_ind = i * n + j\n",
        "            k_list[list_ind] = i\n",
        "            l_list[list_ind] = v\n",
        "            m_list[list_ind] = j\n",
        "\n",
        "            mult_table_vals[list_ind] = mul\n",
        "\n",
        "    return torch.sparse_coo_tensor(indices=coords, values=mult_table_vals, size=(n, n, n))"
      ],
      "metadata": {
        "id": "3KAc3Of9wJ5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "class CliffordAlgebra:\n",
        "    def __init__(self, metric):\n",
        "        self.metric = torch.as_tensor(metric, dtype=torch.float32)\n",
        "        self.num_bases = len(metric)\n",
        "        self.bbo = ShortLexBasisBladeOrder(self.num_bases)\n",
        "        self.dim = len(self.metric)\n",
        "        self.n_blades = len(self.bbo.grades)\n",
        "        self.cayley = construct_gmt(self.bbo.index_to_bitmap, self.bbo.bitmap_to_index, self.metric).to_dense()\n",
        "\n",
        "    def to(self, device: torch.device):\n",
        "        self.bbo.grades = self.bbo.grades.to(device)\n",
        "        self.metric = self.metric.to(device)\n",
        "        self.cayley = self.cayley.to(device)\n",
        "        return self\n",
        "\n",
        "    def geometric_product(self, a, b):\n",
        "        return torch.einsum(\n",
        "            \"bfi,ijk,bfk->bfj\",\n",
        "            a.view(len(a), -1, len(self.cayley)),\n",
        "            self.cayley,\n",
        "            b.view(len(b), -1, len(self.cayley)),\n",
        "        ).view(*a.size())\n",
        "\n",
        "    def reverse(self, mv, blades=None):\n",
        "        \"\"\"Perform the reversion operation on multivectors, an operation specific to geometric algebra.\n",
        "\n",
        "        In Geometric Algebra, the reverse of a multivector is formed by reversing the order of the vectors in each blade.\n",
        "\n",
        "        Args:\n",
        "            mv (torch.Tensor): Input multivectors.\n",
        "            blades (Union[tuple, list, torch.Tensor], optional): Specify which blades are present in the multivector.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The reversed multivector.\n",
        "        \"\"\"\n",
        "        grades = self.bbo.grades.to(mv.device)\n",
        "        if blades is not None:\n",
        "            grades = grades[torch.as_tensor(blades, dtype=int)]\n",
        "        signs = torch.pow(-1, torch.floor(grades * (grades - 1) / 2))\n",
        "        return signs * mv.clone()\n",
        "\n",
        "    def embed(self, tensor: torch.Tensor, tensor_index: Tuple[int]) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Embeds the input tensor into a multivector.\n",
        "\n",
        "        This method takes a tensor and embeds it into a multivector, with the tensor elements assigned to the basis blades\n",
        "        specified by the tensor_index.\n",
        "\n",
        "        Args:\n",
        "            tensor (torch.Tensor): The input tensor to be embedded.\n",
        "            tensor_index (tuple[int]): A tuple of integers specifying the blades where tensor elements are to be placed.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The multivector embedding of the input tensor.\n",
        "\n",
        "        Raises:\n",
        "            AssertionError: If the last dimension of tensor does not match the length of tensor_index.\n",
        "        \"\"\"\n",
        "        assert tensor.size(-1) == len(tensor_index)\n",
        "        blades = tuple(range(self.n_blades))\n",
        "        mv = torch.zeros(*tensor.shape[:-1], len(blades), device=tensor.device)\n",
        "        tensor_index = torch.as_tensor(tensor_index, device=tensor.device, dtype=int)\n",
        "        shape = *(1,) * (mv.dim() - 1), -1\n",
        "        tensor_index = tensor_index.view(shape).repeat(*tensor.size()[:-1], 1)\n",
        "        mv = torch.scatter(mv, -1, tensor_index, tensor)\n",
        "        return mv\n",
        "\n",
        "    def get(self, mv: torch.Tensor, blade_index: Tuple[int]) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Extracts the components of a multivector corresponding to the specified blade indices.\n",
        "\n",
        "        This method takes a multivector and a tuple of blade indices, and returns the components of the multivector\n",
        "        that correspond to those indices.\n",
        "\n",
        "        Args:\n",
        "            mv (torch.Tensor): The input multivector.\n",
        "            blade_index (tuple[int]): A tuple of integers specifying the blades to be extracted.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The tensor of components corresponding to the specified blade indices.\n",
        "        \"\"\"\n",
        "        blade_index = tuple(blade_index)\n",
        "        return mv[..., blade_index]\n",
        "\n",
        "    def mag2(self, mv):\n",
        "        return self.geometric_product(self.reverse(mv), mv)\n",
        "\n",
        "    def norm(self, mv):\n",
        "        mag2 = self.mag2(mv)[..., :1]\n",
        "        mag2.abs_().sqrt_()\n",
        "        return mag2\n",
        "\n",
        "    def sandwich(self, a, b):\n",
        "        \"\"\"aba'\"\"\"\n",
        "        return self.geometric_product(self.geometric_product(a, b), self.reverse(a))"
      ],
      "metadata": {
        "id": "2yCZguvNwKKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.modules.utils import _pair\n",
        "\n",
        "\n",
        "\n",
        "class PGAConjugateLinear(nn.Module):\n",
        "    \"\"\"\n",
        "    Linear layer that applies the PGA conjugation to the input.\n",
        "\n",
        "    Args:\n",
        "        in_features (int): Number of input features.\n",
        "        out_features (int): Number of output features.\n",
        "        algebra (Algebra): Algebra object that defines the geometric product.\n",
        "        input_blades (tuple): Nonnegative blades of the input multivectors.\n",
        "        action_blades (tuple, optional): Blades of the action. Defaults to (0, 5, 6, 7, 8, 9, 10, 15),\n",
        "                                         which encodes rotation and translation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features,\n",
        "        out_features,\n",
        "        algebra,\n",
        "        input_blades,\n",
        "        action_blades=(0, 5, 6, 7, 8, 9, 10, 15),\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert torch.all(algebra.metric == torch.tensor([0, 1, 1, 1]))\n",
        "        self.input_blades = input_blades\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.algebra = algebra\n",
        "        self.action_blades = action_blades\n",
        "        self.n_action_blades = len(action_blades)\n",
        "        self._action = nn.Parameter(torch.empty(out_features, in_features, self.n_action_blades))\n",
        "        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n",
        "        self.embed_e0 = nn.Parameter(torch.zeros(in_features, 1))\n",
        "\n",
        "        self.inverse = algebra.reverse\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Init the rotation parts uniformly.\n",
        "        torch.nn.init.uniform_(self._action[..., 0], -1, 1)\n",
        "        torch.nn.init.uniform_(self._action[..., 4:7], -1, 1)\n",
        "\n",
        "        # Init the translation parts with zeros.\n",
        "        torch.nn.init.zeros_(self._action[..., 1:4])\n",
        "        torch.nn.init.zeros_(self._action[..., 7])\n",
        "\n",
        "        norm = self.algebra.norm(self.algebra.embed(self._action.data, self.action_blades))\n",
        "        assert torch.allclose(norm[..., 1:], torch.tensor(0.0), atol=1e-3)\n",
        "        norm = norm[..., :1]\n",
        "        self._action.data = self._action.data / norm\n",
        "\n",
        "        torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "\n",
        "    @property\n",
        "    def action(self):\n",
        "        return self.algebra.embed(self._action, self.action_blades)\n",
        "\n",
        "    def forward(self, input):\n",
        "        M = self.algebra.cayley\n",
        "        k = self.action\n",
        "        k_ = self.inverse(k)\n",
        "        x = self.algebra.embed(input, self.input_blades)\n",
        "        x[..., 14:15] = self.embed_e0\n",
        "        # x[..., 14:15] = 1\n",
        "\n",
        "        k_l = get_clifford_left_kernel(M, k, flatten=False)\n",
        "        k_r = get_clifford_right_kernel(M, k_, flatten=False)\n",
        "\n",
        "        x = torch.einsum(\"oi,poqi,qori,bir->bop\", self.weight, k_r, k_l, x)\n",
        "\n",
        "        x = self.algebra.get(x, self.input_blades)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiVectorAct(nn.Module):\n",
        "    \"\"\"\n",
        "    A module to apply multivector activations to the input.\n",
        "\n",
        "    Args:\n",
        "        channels (int): Number of channels in the input.\n",
        "        algebra: The algebra object that defines the geometric product.\n",
        "        input_blades (list, tuple): The nonnegative input blades.\n",
        "        kernel_blades (list, tuple, optional): The blades that will be used to compute the activation. Defaults to all input blades.\n",
        "        agg (str, optional): The aggregation method to be used. Options include \"linear\", \"sum\", and \"mean\". Defaults to \"linear\".\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels, algebra, input_blades, kernel_blades=None, agg=\"linear\"):\n",
        "        super().__init__()\n",
        "        self.algebra = algebra\n",
        "        self.input_blades = tuple(input_blades)\n",
        "        if kernel_blades is not None:\n",
        "            self.kernel_blades = tuple(kernel_blades)\n",
        "        else:\n",
        "            self.kernel_blades = self.input_blades\n",
        "\n",
        "        if agg == \"linear\":\n",
        "            self.conv = nn.Conv1d(channels, channels, kernel_size=len(self.kernel_blades), groups=channels)\n",
        "        self.agg = agg\n",
        "\n",
        "    def forward(self, input):\n",
        "        v = self.algebra.embed(input, self.input_blades)\n",
        "        if self.agg == \"linear\":\n",
        "            v = v * torch.sigmoid(self.conv(v[..., self.kernel_blades]))\n",
        "        elif self.agg == \"sum\":\n",
        "            v = v * torch.sigmoid(v[..., self.kernel_blades].sum(dim=-1, keepdim=True))\n",
        "        elif self.agg == \"mean\":\n",
        "            v = v * torch.sigmoid(v[..., self.kernel_blades].mean(dim=-1, keepdim=True))\n",
        "        else:\n",
        "            raise ValueError(f\"Aggregation {self.agg} not implemented.\")\n",
        "        v = self.algebra.get(v, self.input_blades)\n",
        "        return v"
      ],
      "metadata": {
        "id": "xk3ajzWPwMqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/geometric-algebra-transformer')"
      ],
      "metadata": {
        "id": "XO4tl4yynK_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/geometric-algebra-transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Mdye2MAnXMh",
        "outputId": "49aa45fa-9648-4ef7-de92-560413c36098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHANGELOG.md  docker  img      pyproject.toml  scripts\t tests\n",
            "config\t      gatr    LICENSE  README.md       setup.py  tests_regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8L4xQsAt8fJ",
        "outputId": "d837f84d-bd40-4b65-bc67-bdb6ee6eee52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# N-body experiment"
      ],
      "metadata": {
        "id": "yoZBZHY9dFpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create dataset"
      ],
      "metadata": {
        "id": "-wyLT7Y8dIaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base directory for saving data\n",
        "BASEDIR = \"/content/nbody_data\"\n",
        "\n",
        "# Modify PYTHONPATH to include the current directory\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/geometric-algebra-transformer\"\n",
        "\n",
        "\n",
        "# Generate the N-body dataset\n",
        "!python scripts/generate_nbody_dataset.py base_dir=\"${BASEDIR}\" seed=42\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwWlnHqSmpNY",
        "outputId": "4d5ff4c2-9c07-45e6-9e3f-5749429abd47"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "Creating gravity dataset in /content/geometric-algebra-transformer/$/content/nbody_data/data/nbody\n",
            "Done, have a nice day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1000 training samples"
      ],
      "metadata": {
        "id": "KbCnFnw8CCLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GATr"
      ],
      "metadata": {
        "id": "B9wU_4j1Odtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the training experiment with the GATr model\n",
        "!python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=gatr_nbody data.subsample=0.01 training.steps=5000 run_name=gatr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TENKskHxnNO3",
        "outputId": "04c3f3b2-6e96-4f15-88e2-4e0b9cca248f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 14:53:24 I] Hoi.\n",
            "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
            "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
            "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
            "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
            "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
            "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
            "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
            "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
            "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
            "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
            "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
            "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
            "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
            "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
            "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
            "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
            "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
            "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
            "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
            "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
            "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
            "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
            "INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
            "INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
            "INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
            "INFO  [alembic.runtime.migration] Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
            "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
            "[2024-10-23 14:53:26 I] Created experiment nbody with ID 1\n",
            "[2024-10-23 14:53:26 I] Set experiment nbody with ID 1, artifact location file:/content/geometric-algebra-transformer/$/content/nbody_data/tracking/artifacts\n",
            "[2024-10-23 14:53:26 I] Logger already initialized - hi again!\n",
            "[2024-10-23 14:53:26 I] Running experiment at $/content/nbody_data/experiments/nbody/gatr\n",
            "[2024-10-23 14:53:26 I] Saving config at $/content/nbody_data/experiments/nbody/gatr/config.yml\n",
            "[2024-10-23 14:53:27 I] Model has 2.21M learnable parameters\n",
            "[2024-10-23 14:53:27 I] Starting training\n",
            "[2024-10-23 14:53:27 I] Training for 5000 steps, that is, 313 epochs on a dataset of size 1000 with batchsize 64\n",
            "Training epochs:   0% 0/313 [00:00<?, ?it/s]/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 14:53:29 I] Finished first forward pass with loss 0.055800341069698334\n",
            "Training epochs:  20% 62/313 [03:56<15:21,  3.67s/it][2024-10-23 14:57:27 I] Starting validation at step 1000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:12,  6.32it/s]\u001b[A\n",
            "Evaluating:   4% 3/79 [00:00<00:13,  5.82it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:12,  5.93it/s]\u001b[A\n",
            "Evaluating:   6% 5/79 [00:00<00:13,  5.44it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:01<00:15,  4.79it/s]\u001b[A\n",
            "Evaluating:   9% 7/79 [00:01<00:14,  4.81it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:01<00:14,  4.94it/s]\u001b[A\n",
            "Evaluating:  11% 9/79 [00:01<00:14,  4.98it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:01<00:13,  5.26it/s]\u001b[A\n",
            "Evaluating:  14% 11/79 [00:02<00:12,  5.51it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:02<00:12,  5.23it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:02<00:12,  5.24it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:02<00:12,  5.36it/s]\u001b[A\n",
            "Evaluating:  19% 15/79 [00:02<00:11,  5.41it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:02<00:10,  5.86it/s]\u001b[A\n",
            "Evaluating:  22% 17/79 [00:03<00:11,  5.61it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:03<00:11,  5.48it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:03<00:08,  7.30it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:03<00:06,  8.56it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:03<00:05,  9.64it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:04<00:05, 10.36it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:04<00:04, 10.78it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:04<00:04, 11.01it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:04<00:04, 11.41it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:04<00:03, 11.64it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:04<00:03, 11.70it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:05<00:03, 11.86it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:05<00:03, 11.92it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:05<00:03, 11.65it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:05<00:02, 11.86it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:05<00:02, 11.95it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:05<00:02, 12.02it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:06<00:02, 12.06it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:06<00:02, 11.89it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:06<00:02, 11.72it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:06<00:01, 11.90it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:06<00:01, 11.81it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:06<00:01, 11.81it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:07<00:01, 11.76it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:07<00:01, 11.71it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:07<00:01, 11.54it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:07<00:00, 11.69it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:07<00:00, 11.69it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:07<00:00, 11.75it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:08<00:00, 11.75it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:08<00:00, 11.57it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:08<00:00,  9.27it/s]\n",
            "[2024-10-23 14:57:35 I] Validation loop at step 1000:\n",
            "[2024-10-23 14:57:35 I]     loss = 0.0007296848088502885\n",
            "[2024-10-23 14:57:35 I]     mse = 0.0007133007768541575\n",
            "[2024-10-23 14:57:35 I]     rmse = 0.023625581418973998\n",
            "[2024-10-23 14:57:35 I]     output_reg = 0.0016384026570245623\n",
            "[2024-10-23 14:57:35 I]     mae = 0.01008966906964779\n",
            "Training epochs:  40% 125/313 [07:56<11:09,  3.56s/it][2024-10-23 15:01:24 I] Starting validation at step 2000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:06, 11.76it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:06, 12.09it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:06, 12.16it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.15it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.22it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 11.96it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.10it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 12.02it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.22it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.21it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.32it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 12.14it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.13it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 11.77it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:04, 11.05it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:04, 10.06it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:03<00:04,  9.59it/s]\u001b[A\n",
            "Evaluating:  44% 35/79 [00:03<00:04,  9.52it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:03<00:04,  9.37it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:03<00:04,  9.30it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:04,  9.31it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:04,  9.00it/s]\u001b[A\n",
            "Evaluating:  52% 41/79 [00:03<00:04,  8.75it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:04,  8.65it/s]\u001b[A\n",
            "Evaluating:  54% 43/79 [00:04<00:04,  8.37it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:04<00:04,  8.20it/s]\u001b[A\n",
            "Evaluating:  57% 45/79 [00:04<00:04,  7.86it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:04<00:04,  7.97it/s]\u001b[A\n",
            "Evaluating:  59% 47/79 [00:04<00:03,  8.12it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:04<00:03,  8.10it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:04<00:03,  8.14it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:03,  8.23it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:05<00:03,  7.81it/s]\u001b[A\n",
            "Evaluating:  67% 53/79 [00:05<00:02,  8.92it/s]\u001b[A\n",
            "Evaluating:  70% 55/79 [00:05<00:02,  9.66it/s]\u001b[A\n",
            "Evaluating:  72% 57/79 [00:05<00:02, 10.43it/s]\u001b[A\n",
            "Evaluating:  75% 59/79 [00:05<00:01, 10.88it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:05<00:01, 11.20it/s]\u001b[A\n",
            "Evaluating:  80% 63/79 [00:06<00:01, 11.34it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:06<00:01, 11.57it/s]\u001b[A\n",
            "Evaluating:  85% 67/79 [00:06<00:01, 11.42it/s]\u001b[A\n",
            "Evaluating:  87% 69/79 [00:06<00:00, 11.38it/s]\u001b[A\n",
            "Evaluating:  90% 71/79 [00:06<00:00, 11.17it/s]\u001b[A\n",
            "Evaluating:  92% 73/79 [00:06<00:00, 11.11it/s]\u001b[A\n",
            "Evaluating:  95% 75/79 [00:07<00:00, 11.32it/s]\u001b[A\n",
            "Evaluating:  97% 77/79 [00:07<00:00, 11.58it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 10.52it/s]\n",
            "[2024-10-23 15:01:31 I] Validation loop at step 2000:\n",
            "[2024-10-23 15:01:31 I]     loss = 0.0005154295749845916\n",
            "[2024-10-23 15:01:31 I]     mse = 0.0005130863996339031\n",
            "[2024-10-23 15:01:31 I]     rmse = 0.016611336406725047\n",
            "[2024-10-23 15:01:31 I]     output_reg = 0.0002343178150011226\n",
            "[2024-10-23 15:01:31 I]     mae = 0.003896650141477585\n",
            "Training epochs:  60% 187/313 [11:53<07:53,  3.76s/it][2024-10-23 15:05:22 I] Starting validation at step 3000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:05, 13.00it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:05, 12.54it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 12.37it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.21it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.22it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 11.99it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.18it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 11.99it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:05, 12.06it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 11.96it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.00it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 11.84it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 11.88it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 11.87it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:04, 11.78it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:04, 11.67it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 11.62it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:03<00:03, 11.45it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 11.64it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 11.65it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:03, 11.70it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:02, 11.67it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:03<00:02, 11.70it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:04<00:02, 11.55it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 11.58it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 11.38it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:02, 11.41it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:04<00:02, 11.44it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:04<00:01, 11.61it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:05<00:01, 11.42it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01, 11.54it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01, 11.42it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:05<00:01, 11.45it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:05<00:00, 11.43it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:05<00:00, 11.54it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:06<00:00, 11.39it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00, 11.46it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:06<00:00, 11.32it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 11.67it/s]\n",
            "[2024-10-23 15:05:29 I] Validation loop at step 3000:\n",
            "[2024-10-23 15:05:29 I]     loss = 0.0005029964467277751\n",
            "[2024-10-23 15:05:29 I]     mse = 0.0005013444874668494\n",
            "[2024-10-23 15:05:29 I]     rmse = 0.015994140967191796\n",
            "[2024-10-23 15:05:29 I]     output_reg = 0.00016519579640589656\n",
            "[2024-10-23 15:05:29 I]     mae = 0.0034449888020753857\n",
            "Training epochs:  80% 250/313 [15:48<03:43,  3.54s/it][2024-10-23 15:09:16 I] Starting validation at step 4000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:05, 12.87it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:05, 12.63it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 12.56it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.23it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 11.76it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:01<00:06, 10.24it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:06,  9.74it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:06,  9.54it/s]\u001b[A\n",
            "Evaluating:  22% 17/79 [00:01<00:06,  9.48it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:06,  9.31it/s]\u001b[A\n",
            "Evaluating:  24% 19/79 [00:01<00:06,  9.42it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:06,  9.05it/s]\u001b[A\n",
            "Evaluating:  27% 21/79 [00:02<00:06,  8.62it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:02<00:06,  8.60it/s]\u001b[A\n",
            "Evaluating:  29% 23/79 [00:02<00:06,  8.22it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:02<00:06,  8.03it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:02<00:06,  7.98it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:06,  7.90it/s]\u001b[A\n",
            "Evaluating:  34% 27/79 [00:02<00:06,  8.09it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:06,  8.26it/s]\u001b[A\n",
            "Evaluating:  37% 29/79 [00:03<00:05,  8.35it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:03<00:05,  8.49it/s]\u001b[A\n",
            "Evaluating:  39% 31/79 [00:03<00:05,  8.53it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:03<00:05,  8.36it/s]\u001b[A\n",
            "Evaluating:  42% 33/79 [00:03<00:05,  8.70it/s]\u001b[A\n",
            "Evaluating:  44% 35/79 [00:03<00:04, 10.05it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:03<00:03, 10.51it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:04<00:03, 11.03it/s]\u001b[A\n",
            "Evaluating:  52% 41/79 [00:04<00:03, 11.30it/s]\u001b[A\n",
            "Evaluating:  54% 43/79 [00:04<00:03, 11.49it/s]\u001b[A\n",
            "Evaluating:  57% 45/79 [00:04<00:02, 11.63it/s]\u001b[A\n",
            "Evaluating:  59% 47/79 [00:04<00:02, 11.82it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:04<00:02, 11.66it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:05<00:02, 11.83it/s]\u001b[A\n",
            "Evaluating:  67% 53/79 [00:05<00:02, 11.83it/s]\u001b[A\n",
            "Evaluating:  70% 55/79 [00:05<00:02, 11.83it/s]\u001b[A\n",
            "Evaluating:  72% 57/79 [00:05<00:01, 11.93it/s]\u001b[A\n",
            "Evaluating:  75% 59/79 [00:05<00:01, 11.86it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:05<00:01, 11.72it/s]\u001b[A\n",
            "Evaluating:  80% 63/79 [00:06<00:01, 11.89it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:06<00:01, 11.91it/s]\u001b[A\n",
            "Evaluating:  85% 67/79 [00:06<00:00, 12.01it/s]\u001b[A\n",
            "Evaluating:  87% 69/79 [00:06<00:00, 12.07it/s]\u001b[A\n",
            "Evaluating:  90% 71/79 [00:06<00:00, 11.85it/s]\u001b[A\n",
            "Evaluating:  92% 73/79 [00:06<00:00, 11.24it/s]\u001b[A\n",
            "Evaluating:  95% 75/79 [00:07<00:00, 11.41it/s]\u001b[A\n",
            "Evaluating:  97% 77/79 [00:07<00:00, 11.56it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 10.61it/s]\n",
            "[2024-10-23 15:09:24 I] Validation loop at step 4000:\n",
            "[2024-10-23 15:09:24 I]     loss = 0.0004945413998095318\n",
            "[2024-10-23 15:09:24 I]     mse = 0.00049306944985874\n",
            "[2024-10-23 15:09:24 I]     rmse = 0.015554920295040409\n",
            "[2024-10-23 15:09:24 I]     output_reg = 0.00014719455330632636\n",
            "[2024-10-23 15:09:24 I]     mae = 0.0032750777065753936\n",
            "Training epochs: 100% 312/313 [19:42<00:03,  3.77s/it][2024-10-23 15:13:11 I] Starting validation at step 5000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:05, 13.25it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:05, 12.76it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 12.84it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.71it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.67it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.42it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.55it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 12.48it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.58it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.38it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.35it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 12.14it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.17it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 12.22it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:03, 12.36it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:03, 12.14it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 12.13it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:02<00:03, 11.90it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 12.03it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 12.12it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:03, 12.24it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:02, 12.08it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:03<00:02, 12.09it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:03<00:02, 11.99it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 11.95it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 12.12it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:02, 12.09it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:04<00:01, 12.11it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:04<00:01, 12.04it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:04<00:01, 12.12it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01, 11.71it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01, 11.67it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:05<00:01, 11.75it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:05<00:00, 11.76it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:05<00:00, 11.82it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:05<00:00, 11.94it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00, 11.73it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:06<00:00, 11.75it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 12.09it/s]\n",
            "[2024-10-23 15:13:18 I] Validation loop at step 5000:\n",
            "[2024-10-23 15:13:18 I]     loss = 0.0004900302884285337\n",
            "[2024-10-23 15:13:18 I]     mse = 0.0004888237894512714\n",
            "[2024-10-23 15:13:18 I]     rmse = 0.015284546569784046\n",
            "[2024-10-23 15:13:18 I]     output_reg = 0.00012064996294211601\n",
            "[2024-10-23 15:13:18 I]     mae = 0.0032147706180810924\n",
            "Training epochs: 100% 313/313 [19:50<00:00,  3.80s/it]\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 10.64it/s]\n",
            "[2024-10-23 15:13:25 I] Validation loop at step 5000:\n",
            "[2024-10-23 15:13:25 I]     loss = 0.0004900302884285337\n",
            "[2024-10-23 15:13:25 I]     mse = 0.0004888237894512714\n",
            "[2024-10-23 15:13:25 I]     rmse = 0.015284546569784046\n",
            "[2024-10-23 15:13:25 I]     output_reg = 0.00012064996294211601\n",
            "[2024-10-23 15:13:25 I]     mae = 0.0032147706180810924\n",
            "[2024-10-23 15:13:25 I] Saving model at $/content/nbody_data/experiments/nbody/gatr/models/model_final.pt\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 10.78it/s]\n",
            "[2024-10-23 15:13:33 I] Ran evaluation on dataset object_generalization:\n",
            "[2024-10-23 15:13:33 I]     loss = 0.0011915164353093128\n",
            "[2024-10-23 15:13:33 I]     mse = 0.001174033795855939\n",
            "[2024-10-23 15:13:33 I]     rmse = 0.028887077219972017\n",
            "[2024-10-23 15:13:33 I]     output_reg = 0.001748265163414181\n",
            "[2024-10-23 15:13:33 I]     mae = 0.006566762692481278\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 11.49it/s]\n",
            "[2024-10-23 15:13:40 I] Ran evaluation on dataset e3_generalization:\n",
            "[2024-10-23 15:13:40 I]     loss = 0.0005260256293884596\n",
            "[2024-10-23 15:13:40 I]     mse = 0.0005247897899505917\n",
            "[2024-10-23 15:13:40 I]     rmse = 0.016154741875300062\n",
            "[2024-10-23 15:13:40 I]     output_reg = 0.00012358448765007778\n",
            "[2024-10-23 15:13:40 I]     mae = 0.003321611271426082\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 10.46it/s]\n",
            "[2024-10-23 15:13:47 I] Ran evaluation on dataset eval:\n",
            "[2024-10-23 15:13:47 I]     loss = 0.0007253927032157659\n",
            "[2024-10-23 15:13:47 I]     mse = 0.0007241862996510464\n",
            "[2024-10-23 15:13:47 I]     rmse = 0.01842727683861922\n",
            "[2024-10-23 15:13:47 I]     output_reg = 0.0001206406165380031\n",
            "[2024-10-23 15:13:47 I]     mae = 0.0034676930945366628\n",
            "[2024-10-23 15:13:47 I] Anders nog iets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=gatr_nbody data.subsample=0.01 training.steps=10000 run_name=gatr_10000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmTlZhFSBYh2",
        "outputId": "b1ab4c4c-63fc-46c0-d704-674026074447"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 16:11:10 I] Hoi.\n",
            "[2024-10-23 16:11:10 I] Set experiment nbody with ID 1, artifact location file:/content/geometric-algebra-transformer/$/content/nbody_data/tracking/artifacts\n",
            "[2024-10-23 16:11:10 I] Logger already initialized - hi again!\n",
            "[2024-10-23 16:11:10 I] Running experiment at $/content/nbody_data/experiments/nbody/gatr_10000\n",
            "[2024-10-23 16:11:10 I] Saving config at $/content/nbody_data/experiments/nbody/gatr_10000/config.yml\n",
            "[2024-10-23 16:11:11 I] Model has 2.21M learnable parameters\n",
            "[2024-10-23 16:11:11 I] Starting training\n",
            "[2024-10-23 16:11:11 I] Training for 10000 steps, that is, 625 epochs on a dataset of size 1000 with batchsize 64\n",
            "Training epochs:   0% 0/625 [00:00<?, ?it/s]/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 16:11:13 I] Finished first forward pass with loss 0.055800341069698334\n",
            "Training epochs:  10% 62/625 [03:42<33:09,  3.53s/it][2024-10-23 16:14:56 I] Starting validation at step 1000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:06, 11.06it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:06, 11.58it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:06, 12.03it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.20it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 11.82it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:01<00:05, 11.95it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.23it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 12.12it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.24it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.34it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.27it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 12.14it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.35it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 12.37it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:04, 12.15it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:03, 12.22it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 12.22it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:02<00:03, 12.25it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 12.27it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 12.36it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:03, 12.03it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:02, 11.97it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:03<00:02, 12.03it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:03<00:02, 12.12it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 12.20it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 12.17it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:02, 12.08it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:04<00:01, 12.16it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:04<00:01, 12.11it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:04<00:01, 12.17it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01, 12.31it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01, 12.31it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:05<00:01, 12.00it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:05<00:00, 12.01it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:05<00:00, 12.04it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:05<00:00, 12.05it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00, 12.10it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:06<00:00, 12.12it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 12.11it/s]\n",
            "[2024-10-23 16:15:02 I] Validation loop at step 1000:\n",
            "[2024-10-23 16:15:02 I]     loss = 0.0007296848088502885\n",
            "[2024-10-23 16:15:02 I]     mse = 0.0007133007768541575\n",
            "[2024-10-23 16:15:02 I]     rmse = 0.023625581418973998\n",
            "[2024-10-23 16:15:02 I]     output_reg = 0.0016384026570245623\n",
            "[2024-10-23 16:15:02 I]     mae = 0.01008966906964779\n",
            "Training epochs:  20% 125/625 [07:32<29:22,  3.53s/it][2024-10-23 16:18:44 I] Starting validation at step 2000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:06, 12.50it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:05, 12.55it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 12.61it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.62it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.75it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.53it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.36it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 12.47it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.55it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.54it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.58it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 12.44it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.23it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 12.07it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:04, 11.92it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:03, 11.95it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 11.93it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:02<00:03, 11.98it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 11.86it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 12.00it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:03, 12.24it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:02, 12.25it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:03<00:02, 12.32it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:03<00:02, 12.17it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 12.04it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 11.73it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:02, 11.99it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:04<00:01, 12.06it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:04<00:01, 12.17it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:04<00:01, 12.05it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01, 12.12it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01, 11.99it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:05<00:01, 11.34it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:05<00:01, 10.11it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:05<00:00,  9.91it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:06<00:00,  9.73it/s]\u001b[A\n",
            "Evaluating:  92% 73/79 [00:06<00:00,  9.52it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00,  9.60it/s]\u001b[A\n",
            "Evaluating:  95% 75/79 [00:06<00:00,  9.48it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:06<00:00,  9.05it/s]\u001b[A\n",
            "Evaluating:  97% 77/79 [00:06<00:00,  8.71it/s]\u001b[A\n",
            "Evaluating:  99% 78/79 [00:06<00:00,  8.32it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 11.34it/s]\n",
            "[2024-10-23 16:18:51 I] Validation loop at step 2000:\n",
            "[2024-10-23 16:18:51 I]     loss = 0.0005161873416975141\n",
            "[2024-10-23 16:18:51 I]     mse = 0.0005139602357055992\n",
            "[2024-10-23 16:18:51 I]     rmse = 0.016645913113549685\n",
            "[2024-10-23 16:18:51 I]     output_reg = 0.0002227105928119271\n",
            "[2024-10-23 16:18:51 I]     mae = 0.004077664595097302\n",
            "Training epochs:  30% 187/625 [11:19<25:34,  3.50s/it][2024-10-23 16:22:33 I] Starting validation at step 3000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:05, 13.37it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:05, 12.82it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 12.85it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.47it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.54it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.57it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.49it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 12.41it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.65it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.73it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.18it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:02<00:05, 10.69it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:05, 10.32it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:05, 10.05it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:04, 10.15it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:04,  9.75it/s]\u001b[A\n",
            "Evaluating:  42% 33/79 [00:02<00:04,  9.57it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:03<00:04,  9.16it/s]\u001b[A\n",
            "Evaluating:  44% 35/79 [00:03<00:04,  8.93it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:03<00:04,  8.65it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:03<00:04,  8.40it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:04,  8.47it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:03<00:04,  8.43it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:04,  8.11it/s]\u001b[A\n",
            "Evaluating:  52% 41/79 [00:03<00:04,  8.24it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:04<00:04,  8.19it/s]\u001b[A\n",
            "Evaluating:  54% 43/79 [00:04<00:04,  8.04it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:04<00:04,  8.39it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:04<00:03,  9.90it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:04<00:02, 10.83it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 11.44it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 11.59it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:05<00:02, 11.70it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:05<00:01, 11.67it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:05<00:01, 11.85it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:05<00:01, 11.97it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01, 12.15it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01, 12.00it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:06<00:01, 11.98it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:06<00:00, 11.89it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:06<00:00, 11.98it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:06<00:00, 12.06it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00, 12.18it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:06<00:00, 11.86it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 10.96it/s]\n",
            "[2024-10-23 16:22:40 I] Validation loop at step 3000:\n",
            "[2024-10-23 16:22:40 I]     loss = 0.0004891975589329376\n",
            "[2024-10-23 16:22:40 I]     mse = 0.00048665268850745625\n",
            "[2024-10-23 16:22:40 I]     rmse = 0.015261412853469972\n",
            "[2024-10-23 16:22:40 I]     output_reg = 0.0002544868669938296\n",
            "[2024-10-23 16:22:40 I]     mae = 0.003402612050622701\n",
            "Training epochs:  40% 250/625 [15:09<22:08,  3.54s/it][2024-10-23 16:26:21 I] Starting validation at step 4000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   1% 1/79 [00:00<00:09,  8.13it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:08,  8.89it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:06, 10.82it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:06, 11.59it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:06, 11.72it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 11.92it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:01<00:05, 12.06it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.27it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 12.26it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.31it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.21it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.34it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:02<00:04, 12.45it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.54it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 12.41it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:03, 12.44it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:03, 12.52it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 12.31it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:02<00:03, 12.35it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 12.39it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 12.14it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:03, 12.21it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:02, 12.29it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:03<00:02, 12.00it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:03<00:02, 12.07it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 12.21it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 12.12it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:02, 12.21it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:04<00:01, 12.24it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:04<00:01, 12.05it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:04<00:01, 12.15it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01, 12.26it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01, 12.15it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:05<00:01, 12.27it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:05<00:00, 12.22it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:05<00:00, 12.10it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:05<00:00, 12.11it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00, 12.19it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:06<00:00, 12.25it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 12.12it/s]\n",
            "[2024-10-23 16:26:28 I] Validation loop at step 4000:\n",
            "[2024-10-23 16:26:28 I]     loss = 0.0004777676680881995\n",
            "[2024-10-23 16:26:28 I]     mse = 0.0004767166464298499\n",
            "[2024-10-23 16:26:28 I]     rmse = 0.014517050103730054\n",
            "[2024-10-23 16:26:28 I]     output_reg = 0.00010510187824256715\n",
            "[2024-10-23 16:26:28 I]     mae = 0.0029579917147755617\n",
            "Training epochs:  50% 312/625 [18:55<18:56,  3.63s/it][2024-10-23 16:30:09 I] Starting validation at step 5000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:05, 13.49it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:05, 13.11it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 12.79it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.83it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.62it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.51it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.55it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 12.51it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.68it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.27it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.32it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 12.32it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.44it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 12.51it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:03, 12.61it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:03, 12.18it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 12.30it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:02<00:03, 12.13it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 12.26it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 12.29it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:03, 12.30it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:02, 11.86it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:03<00:02, 11.95it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:03<00:02, 11.95it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 11.94it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 12.06it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:02, 12.16it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:04<00:01, 11.81it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:04<00:01, 11.90it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:04<00:01, 11.83it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01, 12.00it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01, 12.06it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:05<00:01, 12.18it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:05<00:00, 12.07it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:05<00:00, 11.91it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:05<00:00, 11.89it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00, 12.02it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:06<00:00, 12.08it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 12.22it/s]\n",
            "[2024-10-23 16:30:16 I] Validation loop at step 5000:\n",
            "[2024-10-23 16:30:16 I]     loss = 0.0004784034483833238\n",
            "[2024-10-23 16:30:16 I]     mse = 0.00047688525588600913\n",
            "[2024-10-23 16:30:16 I]     rmse = 0.014554581571845054\n",
            "[2024-10-23 16:30:16 I]     output_reg = 0.00015181893673725421\n",
            "[2024-10-23 16:30:16 I]     mae = 0.0029833841755986215\n",
            "Training epochs:  60% 375/625 [22:48<14:45,  3.54s/it][2024-10-23 16:34:00 I] Starting validation at step 6000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:06, 12.58it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:05, 12.75it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 12.65it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.72it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.79it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.58it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.47it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 12.52it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.42it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.40it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.43it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 12.25it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.43it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 12.26it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:03, 12.39it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:03, 12.33it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 12.44it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:02<00:03, 12.46it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 12.49it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 12.18it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:03, 11.93it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:03, 10.30it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:03<00:03,  9.97it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:04<00:03,  9.66it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:04<00:03,  9.57it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:03,  9.65it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:04<00:02,  9.49it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02,  9.24it/s]\u001b[A\n",
            "Evaluating:  67% 53/79 [00:04<00:02,  8.98it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:02,  8.63it/s]\u001b[A\n",
            "Evaluating:  70% 55/79 [00:04<00:02,  8.21it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:05<00:02,  8.00it/s]\u001b[A\n",
            "Evaluating:  72% 57/79 [00:05<00:02,  7.99it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:05<00:02,  7.73it/s]\u001b[A\n",
            "Evaluating:  75% 59/79 [00:05<00:02,  7.95it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:05<00:02,  8.02it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:05<00:02,  8.18it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:02,  8.24it/s]\u001b[A\n",
            "Evaluating:  80% 63/79 [00:05<00:01,  8.03it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:06<00:01,  7.78it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:06<00:01,  7.71it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:06<00:01,  8.24it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:06<00:01,  9.20it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:06<00:00, 10.17it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:06<00:00, 10.88it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00, 11.24it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:07<00:00, 11.51it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 10.67it/s]\n",
            "[2024-10-23 16:34:08 I] Validation loop at step 6000:\n",
            "[2024-10-23 16:34:08 I]     loss = 0.0004751651102676989\n",
            "[2024-10-23 16:34:08 I]     mse = 0.00047455996698699893\n",
            "[2024-10-23 16:34:08 I]     rmse = 0.014391626346572022\n",
            "[2024-10-23 16:34:08 I]     output_reg = 6.051423106109724e-05\n",
            "[2024-10-23 16:34:08 I]     mae = 0.003012251599133016\n",
            "Training epochs:  70% 437/625 [26:35<10:51,  3.46s/it][2024-10-23 16:37:49 I] Starting validation at step 7000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:05, 13.18it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:05, 13.06it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 13.10it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 13.01it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.64it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.66it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.28it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:06, 10.35it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:06, 10.09it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:06,  9.81it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:05,  9.90it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:02<00:05,  9.62it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:02<00:05,  9.51it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:05,  9.10it/s]\u001b[A\n",
            "Evaluating:  34% 27/79 [00:02<00:05,  8.91it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:05,  8.67it/s]\u001b[A\n",
            "Evaluating:  37% 29/79 [00:02<00:05,  8.55it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:05,  8.53it/s]\u001b[A\n",
            "Evaluating:  39% 31/79 [00:03<00:05,  8.59it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:03<00:05,  8.63it/s]\u001b[A\n",
            "Evaluating:  42% 33/79 [00:03<00:05,  8.69it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:03<00:05,  8.77it/s]\u001b[A\n",
            "Evaluating:  44% 35/79 [00:03<00:05,  8.44it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:03<00:05,  8.26it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:04,  9.67it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 10.40it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:04<00:03, 11.09it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:04<00:03, 11.57it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:04<00:02, 11.74it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:04<00:02, 11.88it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 12.03it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 11.98it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:05<00:02, 11.98it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:05<00:01, 12.11it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:05<00:01, 11.94it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:05<00:01, 12.12it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01, 12.20it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01, 12.02it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:06<00:01, 12.05it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:06<00:00, 12.18it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:06<00:00, 12.19it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:06<00:00, 12.20it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00, 12.15it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:06<00:00, 11.99it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 10.99it/s]\n",
            "[2024-10-23 16:37:56 I] Validation loop at step 7000:\n",
            "[2024-10-23 16:37:56 I]     loss = 0.00047603733069845496\n",
            "[2024-10-23 16:37:56 I]     mse = 0.0004754930580267683\n",
            "[2024-10-23 16:37:56 I]     rmse = 0.014388110240460893\n",
            "[2024-10-23 16:37:56 I]     output_reg = 5.4427202156512077e-05\n",
            "[2024-10-23 16:37:56 I]     mae = 0.00292857142239809\n",
            "Training epochs:  80% 500/625 [30:27<07:35,  3.65s/it][2024-10-23 16:41:39 I] Starting validation at step 8000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:05, 13.10it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:06, 12.17it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 12.45it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.56it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.73it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.79it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.86it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 12.37it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.51it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.46it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.59it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 12.57it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.58it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 12.30it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:03, 12.34it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:03, 12.36it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 12.43it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:02<00:03, 12.41it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 12.52it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 12.53it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:03, 12.23it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:02, 12.18it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:03<00:02, 12.31it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:03<00:02, 12.42it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 12.42it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 12.37it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:02, 12.09it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:04<00:01, 12.07it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:04<00:01, 12.22it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:04<00:01, 12.12it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01, 12.26it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01, 12.30it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:05<00:01, 12.01it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:05<00:00, 12.04it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:05<00:00, 12.16it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:05<00:00, 12.13it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:05<00:00, 12.30it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:06<00:00, 12.33it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 12.32it/s]\n",
            "[2024-10-23 16:41:46 I] Validation loop at step 8000:\n",
            "[2024-10-23 16:41:46 I]     loss = 0.0004726204640581272\n",
            "[2024-10-23 16:41:46 I]     mse = 0.0004721945753612091\n",
            "[2024-10-23 16:41:46 I]     rmse = 0.014193023578974248\n",
            "[2024-10-23 16:41:46 I]     output_reg = 4.2589552386198186e-05\n",
            "[2024-10-23 16:41:46 I]     mae = 0.0027107817709445957\n",
            "Training epochs:  90% 562/625 [34:14<03:44,  3.57s/it][2024-10-23 16:45:28 I] Starting validation at step 9000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:05, 13.10it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:05, 12.65it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 12.71it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.58it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.48it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.43it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.62it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 12.59it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.56it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.47it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.45it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 12.22it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.32it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 12.40it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:03, 12.45it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:03, 12.03it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 12.17it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:02<00:03, 11.89it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 12.13it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 12.12it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:03, 12.17it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:02, 11.96it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:03<00:02, 12.05it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:03<00:02, 11.91it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 11.99it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 12.14it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:02, 12.29it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:04<00:01, 11.85it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:04<00:01, 12.04it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:04<00:01, 12.11it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01, 10.72it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01,  9.90it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:05<00:01,  9.74it/s]\u001b[A\n",
            "Evaluating:  85% 67/79 [00:05<00:01,  9.61it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:05<00:01,  9.67it/s]\u001b[A\n",
            "Evaluating:  87% 69/79 [00:05<00:01,  9.72it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:06<00:00,  9.51it/s]\u001b[A\n",
            "Evaluating:  90% 71/79 [00:06<00:00,  9.40it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:06<00:00,  9.09it/s]\u001b[A\n",
            "Evaluating:  92% 73/79 [00:06<00:00,  8.86it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00,  8.55it/s]\u001b[A\n",
            "Evaluating:  95% 75/79 [00:06<00:00,  8.01it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:06<00:00,  8.09it/s]\u001b[A\n",
            "Evaluating:  97% 77/79 [00:06<00:00,  7.76it/s]\u001b[A\n",
            "Evaluating:  99% 78/79 [00:07<00:00,  7.84it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 11.07it/s]\n",
            "[2024-10-23 16:45:35 I] Validation loop at step 9000:\n",
            "[2024-10-23 16:45:35 I]     loss = 0.0004749027816287709\n",
            "[2024-10-23 16:45:35 I]     mse = 0.0004745585908996873\n",
            "[2024-10-23 16:45:35 I]     rmse = 0.014405475867872459\n",
            "[2024-10-23 16:45:35 I]     output_reg = 3.441954141017051e-05\n",
            "[2024-10-23 16:45:35 I]     mae = 0.0030087437480688095\n",
            "Training epochs: 100% 625/625 [38:07<00:00,  3.66s/it]\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 10.81it/s]\n",
            "[2024-10-23 16:49:26 I] Validation loop at step 10000:\n",
            "[2024-10-23 16:49:26 I]     loss = 0.00047157945659128027\n",
            "[2024-10-23 16:49:26 I]     mse = 0.00047123588434769763\n",
            "[2024-10-23 16:49:26 I]     rmse = 0.014090019404642891\n",
            "[2024-10-23 16:49:26 I]     output_reg = 3.435731888166629e-05\n",
            "[2024-10-23 16:49:26 I]     mae = 0.0026313817318528885\n",
            "[2024-10-23 16:49:26 I] Saving model at $/content/nbody_data/experiments/nbody/gatr_10000/models/model_final.pt\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 11.96it/s]\n",
            "[2024-10-23 16:49:33 I] Ran evaluation on dataset object_generalization:\n",
            "[2024-10-23 16:49:33 I]     loss = 0.0011426678850082687\n",
            "[2024-10-23 16:49:33 I]     mse = 0.0011368825870158616\n",
            "[2024-10-23 16:49:33 I]     rmse = 0.027564153411480406\n",
            "[2024-10-23 16:49:33 I]     output_reg = 0.0005785303701180965\n",
            "[2024-10-23 16:49:33 I]     mae = 0.005509628819674256\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 10.99it/s]\n",
            "[2024-10-23 16:49:40 I] Ran evaluation on dataset eval:\n",
            "[2024-10-23 16:49:40 I]     loss = 0.0007052311233375804\n",
            "[2024-10-23 16:49:40 I]     mse = 0.0007048726417095168\n",
            "[2024-10-23 16:49:40 I]     rmse = 0.017193192778207713\n",
            "[2024-10-23 16:49:40 I]     output_reg = 3.5847411176655425e-05\n",
            "[2024-10-23 16:49:40 I]     mae = 0.002867834962531925\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 11.34it/s]\n",
            "[2024-10-23 16:49:47 I] Ran evaluation on dataset e3_generalization:\n",
            "[2024-10-23 16:49:47 I]     loss = 0.0005059769552695799\n",
            "[2024-10-23 16:49:47 I]     mse = 0.0005056203251027912\n",
            "[2024-10-23 16:49:47 I]     rmse = 0.014913851463473937\n",
            "[2024-10-23 16:49:47 I]     output_reg = 3.5662528572720476e-05\n",
            "[2024-10-23 16:49:47 I]     mae = 0.002738725776039064\n",
            "[2024-10-23 16:49:47 I] Anders nog iets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=gatr_nbody data.subsample=0.01 training.steps=50000 run_name=gatr_50000"
      ],
      "metadata": {
        "id": "Nin21142Czd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP"
      ],
      "metadata": {
        "id": "azi-DBfK-Kyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=mlp_nbody data.subsample=0.01 training.steps=5000 run_name=mlp"
      ],
      "metadata": {
        "id": "WQzQ5YeVwqg8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9185db47-5fa3-4f98-bd2b-aaed1a33678a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 15:20:53 I] Hoi.\n",
            "[2024-10-23 15:20:54 I] Set experiment nbody with ID 1, artifact location file:/content/geometric-algebra-transformer/$/content/nbody_data/tracking/artifacts\n",
            "[2024-10-23 15:20:54 I] Logger already initialized - hi again!\n",
            "[2024-10-23 15:20:54 I] Running experiment at $/content/nbody_data/experiments/nbody/mlp\n",
            "[2024-10-23 15:20:54 I] Saving config at $/content/nbody_data/experiments/nbody/mlp/config.yml\n",
            "[2024-10-23 15:20:54 I] Model has 0.16M learnable parameters\n",
            "[2024-10-23 15:20:54 I] Starting training\n",
            "[2024-10-23 15:20:55 I] Training for 5000 steps, that is, 313 epochs on a dataset of size 1000 with batchsize 64\n",
            "Training epochs:   0% 0/313 [00:00<?, ?it/s][2024-10-23 15:20:55 I] Finished first forward pass with loss 410.623291015625\n",
            "Training epochs:  19% 61/313 [00:05<00:17, 14.08it/s][2024-10-23 15:21:00 I] Starting validation at step 1000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 826.33it/s]\n",
            "[2024-10-23 15:21:00 I] Validation loop at step 1000:\n",
            "[2024-10-23 15:21:00 I]     loss = 0.11263902711868287\n",
            "[2024-10-23 15:21:00 I]     mse = 0.11263902711868287\n",
            "[2024-10-23 15:21:00 I]     rmse = 0.3354761406709269\n",
            "[2024-10-23 15:21:00 I]     output_reg = 0.0\n",
            "[2024-10-23 15:21:00 I]     mae = 0.26330237302780146\n",
            "Training epochs:  40% 125/313 [00:10<00:16, 11.57it/s][2024-10-23 15:21:05 I] Starting validation at step 2000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 563.97it/s]\n",
            "[2024-10-23 15:21:05 I] Validation loop at step 2000:\n",
            "[2024-10-23 15:21:05 I]     loss = 0.0880528565049171\n",
            "[2024-10-23 15:21:05 I]     mse = 0.0880528565049171\n",
            "[2024-10-23 15:21:05 I]     rmse = 0.2966121631139441\n",
            "[2024-10-23 15:21:05 I]     output_reg = 0.0\n",
            "[2024-10-23 15:21:05 I]     mae = 0.2330891198873519\n",
            "Training epochs:  60% 187/313 [00:15<00:09, 13.99it/s][2024-10-23 15:21:10 I] Starting validation at step 3000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 892.76it/s]\n",
            "[2024-10-23 15:21:10 I] Validation loop at step 3000:\n",
            "[2024-10-23 15:21:10 I]     loss = 0.08026772583723071\n",
            "[2024-10-23 15:21:10 I]     mse = 0.08026772583723071\n",
            "[2024-10-23 15:21:10 I]     rmse = 0.28318075883273097\n",
            "[2024-10-23 15:21:10 I]     output_reg = 0.0\n",
            "[2024-10-23 15:21:10 I]     mae = 0.22253142354488367\n",
            "Training epochs:  80% 249/313 [00:20<00:04, 14.10it/s][2024-10-23 15:21:15 I] Starting validation at step 4000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 796.69it/s]\n",
            "[2024-10-23 15:21:15 I] Validation loop at step 4000:\n",
            "[2024-10-23 15:21:15 I]     loss = 0.07795860017538074\n",
            "[2024-10-23 15:21:15 I]     mse = 0.07795860017538074\n",
            "[2024-10-23 15:21:15 I]     rmse = 0.2790861999014398\n",
            "[2024-10-23 15:21:15 I]     output_reg = 0.0\n",
            "[2024-10-23 15:21:15 I]     mae = 0.2191779772520067\n",
            "Training epochs:  99% 311/313 [00:25<00:00, 13.99it/s][2024-10-23 15:21:21 I] Starting validation at step 5000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 883.80it/s]\n",
            "[2024-10-23 15:21:21 I] Validation loop at step 5000:\n",
            "[2024-10-23 15:21:21 I]     loss = 0.07615445305109025\n",
            "[2024-10-23 15:21:21 I]     mse = 0.07615445305109025\n",
            "[2024-10-23 15:21:21 I]     rmse = 0.27583784601466355\n",
            "[2024-10-23 15:21:21 I]     output_reg = 0.0\n",
            "[2024-10-23 15:21:21 I]     mae = 0.21662995383739478\n",
            "Training epochs: 100% 313/313 [00:26<00:00, 11.96it/s]\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 881.17it/s]\n",
            "[2024-10-23 15:21:21 I] Validation loop at step 5000:\n",
            "[2024-10-23 15:21:21 I]     loss = 0.07615445305109025\n",
            "[2024-10-23 15:21:21 I]     mse = 0.07615445305109025\n",
            "[2024-10-23 15:21:21 I]     rmse = 0.27583784601466355\n",
            "[2024-10-23 15:21:21 I]     output_reg = 0.0\n",
            "[2024-10-23 15:21:21 I]     mae = 0.21662995383739478\n",
            "[2024-10-23 15:21:21 I] Saving model at $/content/nbody_data/experiments/nbody/mlp/models/model_final.pt\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 912.22it/s]\n",
            "[2024-10-23 15:21:21 I] Ran evaluation on dataset eval:\n",
            "[2024-10-23 15:21:21 I]     loss = 0.07576125494837763\n",
            "[2024-10-23 15:21:21 I]     mse = 0.07576125494837763\n",
            "[2024-10-23 15:21:21 I]     rmse = 0.27515057440192664\n",
            "[2024-10-23 15:21:21 I]     output_reg = 0.0\n",
            "[2024-10-23 15:21:21 I]     mae = 0.21609748485088348\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 870.35it/s]\n",
            "[2024-10-23 15:21:21 I] Ran evaluation on dataset e3_generalization:\n",
            "[2024-10-23 15:21:21 I]     loss = 0.8462053962707518\n",
            "[2024-10-23 15:21:21 I]     mse = 0.8462053962707518\n",
            "[2024-10-23 15:21:21 I]     rmse = 0.9195085545712879\n",
            "[2024-10-23 15:21:21 I]     output_reg = 0.0\n",
            "[2024-10-23 15:21:21 I]     mae = 0.7604604318618773\n",
            "[2024-10-23 15:21:21 I] Anders nog iets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=mlp_nbody data.subsample=0.01 training.steps=20000 run_name=mlp_20000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YVhGdC5BE-Q",
        "outputId": "f6f79e5c-1d4d-4a3b-c102-0e3e6e124f3f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 16:05:46 I] Hoi.\n",
            "[2024-10-23 16:05:47 I] Set experiment nbody with ID 1, artifact location file:/content/geometric-algebra-transformer/$/content/nbody_data/tracking/artifacts\n",
            "[2024-10-23 16:05:47 I] Logger already initialized - hi again!\n",
            "[2024-10-23 16:05:47 I] Running experiment at $/content/nbody_data/experiments/nbody/mlp_20000\n",
            "[2024-10-23 16:05:47 I] Saving config at $/content/nbody_data/experiments/nbody/mlp_20000/config.yml\n",
            "[2024-10-23 16:05:47 I] Model has 0.16M learnable parameters\n",
            "[2024-10-23 16:05:47 I] Starting training\n",
            "[2024-10-23 16:05:47 I] Training for 20000 steps, that is, 1250 epochs on a dataset of size 1000 with batchsize 64\n",
            "Training epochs:   0% 0/1250 [00:00<?, ?it/s][2024-10-23 16:05:48 I] Finished first forward pass with loss 410.623291015625\n",
            "Training epochs:   5% 61/1250 [00:04<01:22, 14.35it/s][2024-10-23 16:05:52 I] Starting validation at step 1000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 843.03it/s]\n",
            "[2024-10-23 16:05:52 I] Validation loop at step 1000:\n",
            "[2024-10-23 16:05:52 I]     loss = 0.11263902711868287\n",
            "[2024-10-23 16:05:52 I]     mse = 0.11263902711868287\n",
            "[2024-10-23 16:05:53 I]     rmse = 0.3354761406709269\n",
            "[2024-10-23 16:05:53 I]     output_reg = 0.0\n",
            "[2024-10-23 16:05:53 I]     mae = 0.26330237302780146\n",
            "Training epochs:  10% 125/1250 [00:10<01:29, 12.62it/s][2024-10-23 16:05:58 I] Starting validation at step 2000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 759.18it/s]\n",
            "[2024-10-23 16:05:58 I] Validation loop at step 2000:\n",
            "[2024-10-23 16:05:58 I]     loss = 0.0898732294678688\n",
            "[2024-10-23 16:05:58 I]     mse = 0.0898732294678688\n",
            "[2024-10-23 16:05:58 I]     rmse = 0.29964370394044515\n",
            "[2024-10-23 16:05:58 I]     output_reg = 0.0\n",
            "[2024-10-23 16:05:58 I]     mae = 0.23504380652904508\n",
            "Training epochs:  15% 187/1250 [00:15<01:12, 14.59it/s][2024-10-23 16:06:02 I] Starting validation at step 3000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 893.47it/s]\n",
            "[2024-10-23 16:06:03 I] Validation loop at step 3000:\n",
            "[2024-10-23 16:06:03 I]     loss = 0.07443870139122008\n",
            "[2024-10-23 16:06:03 I]     mse = 0.07443870139122008\n",
            "[2024-10-23 16:06:03 I]     rmse = 0.27268045892185766\n",
            "[2024-10-23 16:06:03 I]     output_reg = 0.0\n",
            "[2024-10-23 16:06:03 I]     mae = 0.21393705775737765\n",
            "Training epochs:  20% 249/1250 [00:19<01:10, 14.24it/s][2024-10-23 16:06:07 I] Starting validation at step 4000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 910.29it/s]\n",
            "[2024-10-23 16:06:07 I] Validation loop at step 4000:\n",
            "[2024-10-23 16:06:07 I]     loss = 0.06658329638838768\n",
            "[2024-10-23 16:06:07 I]     mse = 0.06658329638838768\n",
            "[2024-10-23 16:06:07 I]     rmse = 0.2578906018971328\n",
            "[2024-10-23 16:06:07 I]     output_reg = 0.0\n",
            "[2024-10-23 16:06:07 I]     mae = 0.20189782614707946\n",
            "Training epochs:  25% 311/1250 [00:25<01:05, 14.38it/s][2024-10-23 16:06:13 I] Starting validation at step 5000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 847.17it/s]\n",
            "[2024-10-23 16:06:13 I] Validation loop at step 5000:\n",
            "[2024-10-23 16:06:13 I]     loss = 0.05977242007255554\n",
            "[2024-10-23 16:06:13 I]     mse = 0.05977242007255554\n",
            "[2024-10-23 16:06:13 I]     rmse = 0.24431286984183181\n",
            "[2024-10-23 16:06:13 I]     output_reg = 0.0\n",
            "[2024-10-23 16:06:13 I]     mae = 0.191295609331131\n",
            "Training epochs:  30% 375/1250 [00:30<00:58, 14.89it/s][2024-10-23 16:06:17 I] Starting validation at step 6000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 884.66it/s]\n",
            "[2024-10-23 16:06:18 I] Validation loop at step 6000:\n",
            "[2024-10-23 16:06:18 I]     loss = 0.05628883938193319\n",
            "[2024-10-23 16:06:18 I]     mse = 0.05628883938193319\n",
            "[2024-10-23 16:06:18 I]     rmse = 0.23708351604545538\n",
            "[2024-10-23 16:06:18 I]     output_reg = 0.0\n",
            "[2024-10-23 16:06:18 I]     mae = 0.18514738883972168\n",
            "Training epochs:  35% 437/1250 [00:35<01:01, 13.18it/s][2024-10-23 16:06:23 I] Starting validation at step 7000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 884.43it/s]\n",
            "[2024-10-23 16:06:23 I] Validation loop at step 7000:\n",
            "[2024-10-23 16:06:23 I]     loss = 0.05350836533308028\n",
            "[2024-10-23 16:06:23 I]     mse = 0.05350836533308028\n",
            "[2024-10-23 16:06:23 I]     rmse = 0.23114077549042697\n",
            "[2024-10-23 16:06:23 I]     output_reg = 0.0\n",
            "[2024-10-23 16:06:23 I]     mae = 0.18024794852733617\n",
            "Training epochs:  40% 499/1250 [00:40<00:53, 14.11it/s][2024-10-23 16:06:28 I] Starting validation at step 8000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 847.80it/s]\n",
            "[2024-10-23 16:06:28 I] Validation loop at step 8000:\n",
            "[2024-10-23 16:06:28 I]     loss = 0.05087045447230339\n",
            "[2024-10-23 16:06:28 I]     mse = 0.05087045447230339\n",
            "[2024-10-23 16:06:28 I]     rmse = 0.2253539612784934\n",
            "[2024-10-23 16:06:28 I]     output_reg = 0.0\n",
            "[2024-10-23 16:06:28 I]     mae = 0.17535160446166992\n",
            "Training epochs:  45% 561/1250 [00:44<00:54, 12.62it/s][2024-10-23 16:06:33 I] Starting validation at step 9000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 661.51it/s]\n",
            "[2024-10-23 16:06:33 I] Validation loop at step 9000:\n",
            "[2024-10-23 16:06:33 I]     loss = 0.04967119476199151\n",
            "[2024-10-23 16:06:33 I]     mse = 0.04967119476199151\n",
            "[2024-10-23 16:06:33 I]     rmse = 0.22269397736235164\n",
            "[2024-10-23 16:06:33 I]     output_reg = 0.0\n",
            "[2024-10-23 16:06:33 I]     mae = 0.17336429286003113\n",
            "Training epochs:  50% 625/1250 [00:50<00:41, 14.95it/s][2024-10-23 16:06:38 I] Starting validation at step 10000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 731.85it/s]\n",
            "[2024-10-23 16:06:38 I] Validation loop at step 10000:\n",
            "[2024-10-23 16:06:38 I]     loss = 0.048815918195247665\n",
            "[2024-10-23 16:06:38 I]     mse = 0.048815918195247665\n",
            "[2024-10-23 16:06:38 I]     rmse = 0.2207527274084075\n",
            "[2024-10-23 16:06:38 I]     output_reg = 0.0\n",
            "[2024-10-23 16:06:38 I]     mae = 0.17152509222030643\n",
            "Training epochs:  55% 687/1250 [00:55<00:38, 14.55it/s][2024-10-23 16:06:43 I] Starting validation at step 11000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 896.11it/s]\n",
            "[2024-10-23 16:06:43 I] Validation loop at step 11000:\n",
            "[2024-10-23 16:06:43 I]     loss = 0.04715219113230705\n",
            "[2024-10-23 16:06:43 I]     mse = 0.04715219113230705\n",
            "[2024-10-23 16:06:43 I]     rmse = 0.2169548897281598\n",
            "[2024-10-23 16:06:43 I]     output_reg = 0.0\n",
            "[2024-10-23 16:06:43 I]     mae = 0.1682980967998505\n",
            "Training epochs:  60% 749/1250 [01:00<00:36, 13.83it/s][2024-10-23 16:06:48 I] Starting validation at step 12000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 880.70it/s]\n",
            "[2024-10-23 16:06:48 I] Validation loop at step 12000:\n",
            "[2024-10-23 16:06:48 I]     loss = 0.04680881671905518\n",
            "[2024-10-23 16:06:48 I]     mse = 0.04680881671905518\n",
            "[2024-10-23 16:06:48 I]     rmse = 0.2161654172523181\n",
            "[2024-10-23 16:06:48 I]     output_reg = 0.0\n",
            "[2024-10-23 16:06:48 I]     mae = 0.1675780822753906\n",
            "Training epochs:  65% 811/1250 [01:05<00:30, 14.45it/s][2024-10-23 16:06:53 I] Starting validation at step 13000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 860.58it/s]\n",
            "[2024-10-23 16:06:53 I] Validation loop at step 13000:\n",
            "[2024-10-23 16:06:53 I]     loss = 0.04625523419380189\n",
            "[2024-10-23 16:06:53 I]     mse = 0.04625523419380189\n",
            "[2024-10-23 16:06:53 I]     rmse = 0.21487346893599293\n",
            "[2024-10-23 16:06:53 I]     output_reg = 0.0\n",
            "[2024-10-23 16:06:53 I]     mae = 0.16637548108100886\n",
            "Training epochs:  70% 875/1250 [01:10<00:30, 12.14it/s][2024-10-23 16:06:58 I] Starting validation at step 14000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 617.24it/s]\n",
            "[2024-10-23 16:06:58 I] Validation loop at step 14000:\n",
            "[2024-10-23 16:06:58 I]     loss = 0.04590454374551772\n",
            "[2024-10-23 16:06:58 I]     mse = 0.04590454374551772\n",
            "[2024-10-23 16:06:58 I]     rmse = 0.21405029084110375\n",
            "[2024-10-23 16:06:58 I]     output_reg = 0.0\n",
            "[2024-10-23 16:06:58 I]     mae = 0.16576481616497038\n",
            "Training epochs:  75% 937/1250 [01:15<00:21, 14.25it/s][2024-10-23 16:07:03 I] Starting validation at step 15000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 874.66it/s]\n",
            "[2024-10-23 16:07:03 I] Validation loop at step 15000:\n",
            "[2024-10-23 16:07:03 I]     loss = 0.04527080981731417\n",
            "[2024-10-23 16:07:03 I]     mse = 0.04527080981731417\n",
            "[2024-10-23 16:07:03 I]     rmse = 0.21256380020729657\n",
            "[2024-10-23 16:07:03 I]     output_reg = 0.0\n",
            "[2024-10-23 16:07:03 I]     mae = 0.16448023524284375\n",
            "Training epochs:  80% 999/1250 [01:20<00:17, 14.26it/s][2024-10-23 16:07:08 I] Starting validation at step 16000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 853.39it/s]\n",
            "[2024-10-23 16:07:08 I] Validation loop at step 16000:\n",
            "[2024-10-23 16:07:08 I]     loss = 0.04517958282828331\n",
            "[2024-10-23 16:07:08 I]     mse = 0.04517958282828331\n",
            "[2024-10-23 16:07:08 I]     rmse = 0.2123471004830678\n",
            "[2024-10-23 16:07:08 I]     output_reg = 0.0\n",
            "[2024-10-23 16:07:08 I]     mae = 0.1642359261274338\n",
            "Training epochs:  85% 1061/1250 [01:25<00:13, 13.83it/s][2024-10-23 16:07:13 I] Starting validation at step 17000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 893.43it/s]\n",
            "[2024-10-23 16:07:13 I] Validation loop at step 17000:\n",
            "[2024-10-23 16:07:13 I]     loss = 0.04498826130628585\n",
            "[2024-10-23 16:07:13 I]     mse = 0.04498826130628585\n",
            "[2024-10-23 16:07:13 I]     rmse = 0.2119007870614751\n",
            "[2024-10-23 16:07:13 I]     output_reg = 0.0\n",
            "[2024-10-23 16:07:13 I]     mae = 0.1639195105314255\n",
            "Training epochs:  90% 1125/1250 [01:30<00:08, 15.10it/s][2024-10-23 16:07:18 I] Starting validation at step 18000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 811.13it/s]\n",
            "[2024-10-23 16:07:18 I] Validation loop at step 18000:\n",
            "[2024-10-23 16:07:18 I]     loss = 0.044782056754827514\n",
            "[2024-10-23 16:07:18 I]     mse = 0.044782056754827514\n",
            "[2024-10-23 16:07:18 I]     rmse = 0.211411334969678\n",
            "[2024-10-23 16:07:18 I]     output_reg = 0.0\n",
            "[2024-10-23 16:07:18 I]     mae = 0.1634582567691803\n",
            "Training epochs:  95% 1187/1250 [01:35<00:05, 10.90it/s][2024-10-23 16:07:23 I] Starting validation at step 19000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 554.94it/s]\n",
            "[2024-10-23 16:07:23 I] Validation loop at step 19000:\n",
            "[2024-10-23 16:07:23 I]     loss = 0.04454989761114122\n",
            "[2024-10-23 16:07:23 I]     mse = 0.04454989761114122\n",
            "[2024-10-23 16:07:23 I]     rmse = 0.21085974681971584\n",
            "[2024-10-23 16:07:23 I]     output_reg = 0.0\n",
            "[2024-10-23 16:07:23 I]     mae = 0.16298084516525266\n",
            "Training epochs: 100% 1250/1250 [01:40<00:00, 12.44it/s]\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 874.00it/s]\n",
            "[2024-10-23 16:07:28 I] Validation loop at step 20000:\n",
            "[2024-10-23 16:07:28 I]     loss = 0.04448447868824005\n",
            "[2024-10-23 16:07:28 I]     mse = 0.04448447868824005\n",
            "[2024-10-23 16:07:28 I]     rmse = 0.21070163648480536\n",
            "[2024-10-23 16:07:28 I]     output_reg = 0.0\n",
            "[2024-10-23 16:07:28 I]     mae = 0.16281881873607634\n",
            "[2024-10-23 16:07:28 I] Saving model at $/content/nbody_data/experiments/nbody/mlp_20000/models/model_final.pt\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 902.22it/s]\n",
            "[2024-10-23 16:07:28 I] Ran evaluation on dataset eval:\n",
            "[2024-10-23 16:07:28 I]     loss = 0.044605779516696926\n",
            "[2024-10-23 16:07:28 I]     mse = 0.044605779516696926\n",
            "[2024-10-23 16:07:28 I]     rmse = 0.2110613195073361\n",
            "[2024-10-23 16:07:28 I]     output_reg = 0.0\n",
            "[2024-10-23 16:07:28 I]     mae = 0.1631567891597748\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 897.17it/s]\n",
            "[2024-10-23 16:07:28 I] Ran evaluation on dataset e3_generalization:\n",
            "[2024-10-23 16:07:28 I]     loss = 0.5418729212760927\n",
            "[2024-10-23 16:07:28 I]     mse = 0.5418729212760927\n",
            "[2024-10-23 16:07:28 I]     rmse = 0.7356204801899157\n",
            "[2024-10-23 16:07:28 I]     output_reg = 0.0\n",
            "[2024-10-23 16:07:28 I]     mae = 0.5703221726894382\n",
            "[2024-10-23 16:07:28 I] Anders nog iets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=mlp_nbody data.subsample=0.01 training.steps=50000 run_name=mlp_50000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQwUbviI-cJ-",
        "outputId": "6d849d63-8ca7-47a0-e01e-e3313dd1982e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 15:23:49 I] Hoi.\n",
            "[2024-10-23 15:23:49 I] Set experiment nbody with ID 1, artifact location file:/content/geometric-algebra-transformer/$/content/nbody_data/tracking/artifacts\n",
            "[2024-10-23 15:23:49 I] Logger already initialized - hi again!\n",
            "[2024-10-23 15:23:49 I] Running experiment at $/content/nbody_data/experiments/nbody/mlp_50000\n",
            "[2024-10-23 15:23:49 I] Saving config at $/content/nbody_data/experiments/nbody/mlp_50000/config.yml\n",
            "[2024-10-23 15:23:50 I] Model has 0.16M learnable parameters\n",
            "[2024-10-23 15:23:50 I] Starting training\n",
            "[2024-10-23 15:23:50 I] Training for 50000 steps, that is, 3125 epochs on a dataset of size 1000 with batchsize 64\n",
            "Training epochs:   0% 0/3125 [00:00<?, ?it/s][2024-10-23 15:23:50 I] Finished first forward pass with loss 410.623291015625\n",
            "Training epochs:   2% 61/3125 [00:04<03:36, 14.17it/s][2024-10-23 15:23:55 I] Starting validation at step 1000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 852.81it/s]\n",
            "[2024-10-23 15:23:55 I] Validation loop at step 1000:\n",
            "[2024-10-23 15:23:55 I]     loss = 0.11263902711868287\n",
            "[2024-10-23 15:23:55 I]     mse = 0.11263902711868287\n",
            "[2024-10-23 15:23:55 I]     rmse = 0.3354761406709269\n",
            "[2024-10-23 15:23:55 I]     output_reg = 0.0\n",
            "[2024-10-23 15:23:55 I]     mae = 0.26330237302780146\n",
            "Training epochs:   4% 125/3125 [00:10<04:18, 11.61it/s][2024-10-23 15:24:00 I] Starting validation at step 2000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 523.65it/s]\n",
            "[2024-10-23 15:24:01 I] Validation loop at step 2000:\n",
            "[2024-10-23 15:24:01 I]     loss = 0.08986823019981381\n",
            "[2024-10-23 15:24:01 I]     mse = 0.08986823019981381\n",
            "[2024-10-23 15:24:01 I]     rmse = 0.29962792385728027\n",
            "[2024-10-23 15:24:01 I]     output_reg = 0.0\n",
            "[2024-10-23 15:24:01 I]     mae = 0.23537290122509\n",
            "Training epochs:   6% 187/3125 [00:15<03:24, 14.38it/s][2024-10-23 15:24:06 I] Starting validation at step 3000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 779.67it/s]\n",
            "[2024-10-23 15:24:06 I] Validation loop at step 3000:\n",
            "[2024-10-23 15:24:06 I]     loss = 0.08283026168346408\n",
            "[2024-10-23 15:24:06 I]     mse = 0.08283026168346408\n",
            "[2024-10-23 15:24:06 I]     rmse = 0.2876102059959435\n",
            "[2024-10-23 15:24:06 I]     output_reg = 0.0\n",
            "[2024-10-23 15:24:06 I]     mae = 0.22516404340267177\n",
            "Training epochs:   8% 249/3125 [00:20<03:24, 14.08it/s][2024-10-23 15:24:10 I] Starting validation at step 4000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 901.71it/s]\n",
            "[2024-10-23 15:24:11 I] Validation loop at step 4000:\n",
            "[2024-10-23 15:24:11 I]     loss = 0.06925759201049807\n",
            "[2024-10-23 15:24:11 I]     mse = 0.06925759201049807\n",
            "[2024-10-23 15:24:11 I]     rmse = 0.2629713809439582\n",
            "[2024-10-23 15:24:11 I]     output_reg = 0.0\n",
            "[2024-10-23 15:24:11 I]     mae = 0.2055434932470322\n",
            "Training epochs:  10% 311/3125 [00:25<03:27, 13.55it/s][2024-10-23 15:24:16 I] Starting validation at step 5000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 908.74it/s]\n",
            "[2024-10-23 15:24:16 I] Validation loop at step 5000:\n",
            "[2024-10-23 15:24:16 I]     loss = 0.0603486046075821\n",
            "[2024-10-23 15:24:16 I]     mse = 0.0603486046075821\n",
            "[2024-10-23 15:24:16 I]     rmse = 0.245482034701724\n",
            "[2024-10-23 15:24:16 I]     output_reg = 0.0\n",
            "[2024-10-23 15:24:16 I]     mae = 0.19165197710990908\n",
            "Training epochs:  12% 375/3125 [00:30<03:05, 14.80it/s][2024-10-23 15:24:21 I] Starting validation at step 6000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 872.04it/s]\n",
            "[2024-10-23 15:24:21 I] Validation loop at step 6000:\n",
            "[2024-10-23 15:24:21 I]     loss = 0.05487592697143556\n",
            "[2024-10-23 15:24:21 I]     mse = 0.05487592697143556\n",
            "[2024-10-23 15:24:21 I]     rmse = 0.2340836582061572\n",
            "[2024-10-23 15:24:21 I]     output_reg = 0.0\n",
            "[2024-10-23 15:24:21 I]     mae = 0.18253384349346155\n",
            "Training epochs:  14% 437/3125 [00:35<04:07, 10.86it/s][2024-10-23 15:24:26 I] Starting validation at step 7000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 585.18it/s]\n",
            "[2024-10-23 15:24:26 I] Validation loop at step 7000:\n",
            "[2024-10-23 15:24:26 I]     loss = 0.05302129828333856\n",
            "[2024-10-23 15:24:26 I]     mse = 0.05302129828333856\n",
            "[2024-10-23 15:24:26 I]     rmse = 0.2300772582948409\n",
            "[2024-10-23 15:24:26 I]     output_reg = 0.0\n",
            "[2024-10-23 15:24:26 I]     mae = 0.17885796275138854\n",
            "Training epochs:  16% 499/3125 [00:40<03:09, 13.89it/s][2024-10-23 15:24:31 I] Starting validation at step 8000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 882.90it/s]\n",
            "[2024-10-23 15:24:31 I] Validation loop at step 8000:\n",
            "[2024-10-23 15:24:31 I]     loss = 0.051360823965072654\n",
            "[2024-10-23 15:24:31 I]     mse = 0.051360823965072654\n",
            "[2024-10-23 15:24:31 I]     rmse = 0.2264047480391042\n",
            "[2024-10-23 15:24:31 I]     output_reg = 0.0\n",
            "[2024-10-23 15:24:31 I]     mae = 0.17546495242118837\n",
            "Training epochs:  18% 561/3125 [00:45<03:00, 14.18it/s][2024-10-23 15:24:36 I] Starting validation at step 9000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 892.91it/s]\n",
            "[2024-10-23 15:24:36 I] Validation loop at step 9000:\n",
            "[2024-10-23 15:24:36 I]     loss = 0.04679837163686754\n",
            "[2024-10-23 15:24:36 I]     mse = 0.04679837163686754\n",
            "[2024-10-23 15:24:36 I]     rmse = 0.2161104505535495\n",
            "[2024-10-23 15:24:36 I]     output_reg = 0.0\n",
            "[2024-10-23 15:24:36 I]     mae = 0.1671042303085327\n",
            "Training epochs:  20% 625/3125 [00:51<02:51, 14.56it/s][2024-10-23 15:24:41 I] Starting validation at step 10000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 891.02it/s]\n",
            "[2024-10-23 15:24:41 I] Validation loop at step 10000:\n",
            "[2024-10-23 15:24:41 I]     loss = 0.04816495901942252\n",
            "[2024-10-23 15:24:41 I]     mse = 0.04816495901942252\n",
            "[2024-10-23 15:24:41 I]     rmse = 0.2192481354170995\n",
            "[2024-10-23 15:24:41 I]     output_reg = 0.0\n",
            "[2024-10-23 15:24:41 I]     mae = 0.16973432025909418\n",
            "Training epochs:  22% 687/3125 [00:56<02:55, 13.93it/s][2024-10-23 15:24:46 I] Starting validation at step 11000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 870.56it/s]\n",
            "[2024-10-23 15:24:46 I] Validation loop at step 11000:\n",
            "[2024-10-23 15:24:46 I]     loss = 0.045496160519123065\n",
            "[2024-10-23 15:24:46 I]     mse = 0.045496160519123065\n",
            "[2024-10-23 15:24:46 I]     rmse = 0.21306465457134013\n",
            "[2024-10-23 15:24:46 I]     output_reg = 0.0\n",
            "[2024-10-23 15:24:46 I]     mae = 0.16462156028747565\n",
            "Training epochs:  24% 749/3125 [01:01<03:42, 10.68it/s][2024-10-23 15:24:52 I] Starting validation at step 12000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 489.91it/s]\n",
            "[2024-10-23 15:24:52 I] Validation loop at step 12000:\n",
            "[2024-10-23 15:24:52 I]     loss = 0.045006394040584576\n",
            "[2024-10-23 15:24:52 I]     mse = 0.045006394040584576\n",
            "[2024-10-23 15:24:52 I]     rmse = 0.2119160392973876\n",
            "[2024-10-23 15:24:52 I]     output_reg = 0.0\n",
            "[2024-10-23 15:24:52 I]     mae = 0.16319062106609356\n",
            "Training epochs:  26% 811/3125 [01:06<02:40, 14.38it/s][2024-10-23 15:24:57 I] Starting validation at step 13000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 853.20it/s]\n",
            "[2024-10-23 15:24:57 I] Validation loop at step 13000:\n",
            "[2024-10-23 15:24:57 I]     loss = 0.04430082532167435\n",
            "[2024-10-23 15:24:57 I]     mse = 0.04430082532167435\n",
            "[2024-10-23 15:24:57 I]     rmse = 0.21023083296670383\n",
            "[2024-10-23 15:24:57 I]     output_reg = 0.0\n",
            "[2024-10-23 15:24:57 I]     mae = 0.16181811447143551\n",
            "Training epochs:  28% 875/3125 [01:11<02:30, 14.93it/s][2024-10-23 15:25:01 I] Starting validation at step 14000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 894.39it/s]\n",
            "[2024-10-23 15:25:02 I] Validation loop at step 14000:\n",
            "[2024-10-23 15:25:02 I]     loss = 0.043409578150510796\n",
            "[2024-10-23 15:25:02 I]     mse = 0.043409578150510796\n",
            "[2024-10-23 15:25:02 I]     rmse = 0.2080952055102045\n",
            "[2024-10-23 15:25:02 I]     output_reg = 0.0\n",
            "[2024-10-23 15:25:02 I]     mae = 0.16007310953140264\n",
            "Training epochs:  30% 936/3125 [01:16<02:35, 14.12it/s][2024-10-23 15:25:07 I] Starting validation at step 15000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 888.54it/s]\n",
            "[2024-10-23 15:25:07 I] Validation loop at step 15000:\n",
            "[2024-10-23 15:25:07 I]     loss = 0.04339006378054622\n",
            "[2024-10-23 15:25:07 I]     mse = 0.04339006378054622\n",
            "[2024-10-23 15:25:07 I]     rmse = 0.20802063925721914\n",
            "[2024-10-23 15:25:07 I]     output_reg = 0.0\n",
            "[2024-10-23 15:25:07 I]     mae = 0.1597897595405579\n",
            "Training epochs:  32% 1000/3125 [01:21<02:24, 14.75it/s][2024-10-23 15:25:12 I] Starting validation at step 16000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 904.57it/s]\n",
            "[2024-10-23 15:25:12 I] Validation loop at step 16000:\n",
            "[2024-10-23 15:25:12 I]     loss = 0.04321346184611321\n",
            "[2024-10-23 15:25:12 I]     mse = 0.04321346184611321\n",
            "[2024-10-23 15:25:12 I]     rmse = 0.20759175420449236\n",
            "[2024-10-23 15:25:12 I]     output_reg = 0.0\n",
            "[2024-10-23 15:25:12 I]     mae = 0.15929553751945497\n",
            "Training epochs:  34% 1062/3125 [01:27<02:38, 12.99it/s][2024-10-23 15:25:17 I] Starting validation at step 17000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 838.11it/s]\n",
            "[2024-10-23 15:25:18 I] Validation loop at step 17000:\n",
            "[2024-10-23 15:25:18 I]     loss = 0.04289258791208266\n",
            "[2024-10-23 15:25:18 I]     mse = 0.04289258791208266\n",
            "[2024-10-23 15:25:18 I]     rmse = 0.20681134269560927\n",
            "[2024-10-23 15:25:18 I]     output_reg = 0.0\n",
            "[2024-10-23 15:25:18 I]     mae = 0.15874116854667664\n",
            "Training epochs:  36% 1124/3125 [01:32<02:20, 14.26it/s][2024-10-23 15:25:22 I] Starting validation at step 18000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 867.86it/s]\n",
            "[2024-10-23 15:25:22 I] Validation loop at step 18000:\n",
            "[2024-10-23 15:25:22 I]     loss = 0.04279392766952515\n",
            "[2024-10-23 15:25:22 I]     mse = 0.04279392766952515\n",
            "[2024-10-23 15:25:22 I]     rmse = 0.20657064444579445\n",
            "[2024-10-23 15:25:22 I]     output_reg = 0.0\n",
            "[2024-10-23 15:25:22 I]     mae = 0.15847882795333865\n",
            "Training epochs:  38% 1186/3125 [01:37<02:35, 12.45it/s][2024-10-23 15:25:27 I] Starting validation at step 19000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 640.79it/s]\n",
            "[2024-10-23 15:25:27 I] Validation loop at step 19000:\n",
            "[2024-10-23 15:25:27 I]     loss = 0.04181874586343766\n",
            "[2024-10-23 15:25:27 I]     mse = 0.04181874586343766\n",
            "[2024-10-23 15:25:27 I]     rmse = 0.20420203383293742\n",
            "[2024-10-23 15:25:27 I]     output_reg = 0.0\n",
            "[2024-10-23 15:25:27 I]     mae = 0.15646524634361267\n",
            "Training epochs:  40% 1250/3125 [01:42<02:02, 15.28it/s][2024-10-23 15:25:32 I] Starting validation at step 20000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 887.68it/s]\n",
            "[2024-10-23 15:25:33 I] Validation loop at step 20000:\n",
            "[2024-10-23 15:25:33 I]     loss = 0.04194826373457909\n",
            "[2024-10-23 15:25:33 I]     mse = 0.04194826373457909\n",
            "[2024-10-23 15:25:33 I]     rmse = 0.20450771399383322\n",
            "[2024-10-23 15:25:33 I]     output_reg = 0.0\n",
            "[2024-10-23 15:25:33 I]     mae = 0.1565730705738068\n",
            "Training epochs:  42% 1312/3125 [01:47<02:09, 14.00it/s][2024-10-23 15:25:37 I] Starting validation at step 21000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 882.49it/s]\n",
            "[2024-10-23 15:25:37 I] Validation loop at step 21000:\n",
            "[2024-10-23 15:25:37 I]     loss = 0.042255564868450175\n",
            "[2024-10-23 15:25:37 I]     mse = 0.042255564868450175\n",
            "[2024-10-23 15:25:37 I]     rmse = 0.20524519712385603\n",
            "[2024-10-23 15:25:37 I]     output_reg = 0.0\n",
            "[2024-10-23 15:25:37 I]     mae = 0.15709848887920375\n",
            "Training epochs:  44% 1374/3125 [01:52<02:06, 13.86it/s][2024-10-23 15:25:43 I] Starting validation at step 22000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 869.91it/s]\n",
            "[2024-10-23 15:25:43 I] Validation loop at step 22000:\n",
            "[2024-10-23 15:25:43 I]     loss = 0.04166012307405471\n",
            "[2024-10-23 15:25:43 I]     mse = 0.04166012307405471\n",
            "[2024-10-23 15:25:43 I]     rmse = 0.20378545282548502\n",
            "[2024-10-23 15:25:43 I]     output_reg = 0.0\n",
            "[2024-10-23 15:25:43 I]     mae = 0.15594289550781248\n",
            "Training epochs:  46% 1436/3125 [01:57<01:58, 14.20it/s][2024-10-23 15:25:48 I] Starting validation at step 23000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 846.18it/s]\n",
            "[2024-10-23 15:25:48 I] Validation loop at step 23000:\n",
            "[2024-10-23 15:25:48 I]     loss = 0.04191690386533736\n",
            "[2024-10-23 15:25:48 I]     mse = 0.04191690386533736\n",
            "[2024-10-23 15:25:48 I]     rmse = 0.20441337992222394\n",
            "[2024-10-23 15:25:48 I]     output_reg = 0.0\n",
            "[2024-10-23 15:25:48 I]     mae = 0.15634051508903507\n",
            "Training epochs:  48% 1500/3125 [02:02<02:13, 12.21it/s][2024-10-23 15:25:53 I] Starting validation at step 24000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 615.18it/s]\n",
            "[2024-10-23 15:25:53 I] Validation loop at step 24000:\n",
            "[2024-10-23 15:25:53 I]     loss = 0.041660510033369076\n",
            "[2024-10-23 15:25:53 I]     mse = 0.041660510033369076\n",
            "[2024-10-23 15:25:53 I]     rmse = 0.2037807004999271\n",
            "[2024-10-23 15:25:53 I]     output_reg = 0.0\n",
            "[2024-10-23 15:25:53 I]     mae = 0.15578245341777808\n",
            "Training epochs:  50% 1562/3125 [02:07<01:51, 14.06it/s][2024-10-23 15:25:58 I] Starting validation at step 25000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 865.62it/s]\n",
            "[2024-10-23 15:25:58 I] Validation loop at step 25000:\n",
            "[2024-10-23 15:25:58 I]     loss = 0.0416519301891327\n",
            "[2024-10-23 15:25:58 I]     mse = 0.0416519301891327\n",
            "[2024-10-23 15:25:58 I]     rmse = 0.20374660396904778\n",
            "[2024-10-23 15:25:58 I]     output_reg = 0.0\n",
            "[2024-10-23 15:25:58 I]     mae = 0.1556416469097138\n",
            "Training epochs:  52% 1624/3125 [02:12<01:44, 14.38it/s][2024-10-23 15:26:03 I] Starting validation at step 26000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 794.52it/s]\n",
            "[2024-10-23 15:26:03 I] Validation loop at step 26000:\n",
            "[2024-10-23 15:26:03 I]     loss = 0.04166722328066826\n",
            "[2024-10-23 15:26:03 I]     mse = 0.04166722328066826\n",
            "[2024-10-23 15:26:03 I]     rmse = 0.2037913111200971\n",
            "[2024-10-23 15:26:03 I]     output_reg = 0.0\n",
            "[2024-10-23 15:26:03 I]     mae = 0.155616772031784\n",
            "Training epochs:  54% 1686/3125 [02:17<01:43, 13.97it/s][2024-10-23 15:26:08 I] Starting validation at step 27000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 903.07it/s]\n",
            "[2024-10-23 15:26:08 I] Validation loop at step 27000:\n",
            "[2024-10-23 15:26:08 I]     loss = 0.04169920722842216\n",
            "[2024-10-23 15:26:08 I]     mse = 0.04169920722842216\n",
            "[2024-10-23 15:26:08 I]     rmse = 0.2038567327369008\n",
            "[2024-10-23 15:26:08 I]     output_reg = 0.0\n",
            "[2024-10-23 15:26:08 I]     mae = 0.1556277535200119\n",
            "Training epochs:  56% 1750/3125 [02:22<01:31, 14.99it/s][2024-10-23 15:26:13 I] Starting validation at step 28000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 892.88it/s]\n",
            "[2024-10-23 15:26:13 I] Validation loop at step 28000:\n",
            "[2024-10-23 15:26:13 I]     loss = 0.0415730416059494\n",
            "[2024-10-23 15:26:13 I]     mse = 0.0415730416059494\n",
            "[2024-10-23 15:26:13 I]     rmse = 0.2035377325928292\n",
            "[2024-10-23 15:26:13 I]     output_reg = 0.0\n",
            "[2024-10-23 15:26:13 I]     mae = 0.15534748802185064\n",
            "Training epochs:  58% 1812/3125 [02:27<01:58, 11.09it/s][2024-10-23 15:26:18 I] Starting validation at step 29000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 550.94it/s]\n",
            "[2024-10-23 15:26:18 I] Validation loop at step 29000:\n",
            "[2024-10-23 15:26:18 I]     loss = 0.04158088156580925\n",
            "[2024-10-23 15:26:18 I]     mse = 0.04158088156580925\n",
            "[2024-10-23 15:26:18 I]     rmse = 0.20355487136529854\n",
            "[2024-10-23 15:26:18 I]     output_reg = 0.0\n",
            "[2024-10-23 15:26:18 I]     mae = 0.15523461389541632\n",
            "Training epochs:  60% 1874/3125 [02:33<01:29, 13.99it/s][2024-10-23 15:26:23 I] Starting validation at step 30000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 798.73it/s]\n",
            "[2024-10-23 15:26:23 I] Validation loop at step 30000:\n",
            "[2024-10-23 15:26:23 I]     loss = 0.041523745596408854\n",
            "[2024-10-23 15:26:23 I]     mse = 0.041523745596408854\n",
            "[2024-10-23 15:26:23 I]     rmse = 0.20341242565607556\n",
            "[2024-10-23 15:26:23 I]     output_reg = 0.0\n",
            "[2024-10-23 15:26:23 I]     mae = 0.15508196249008174\n",
            "Training epochs:  62% 1936/3125 [02:37<01:24, 14.03it/s][2024-10-23 15:26:28 I] Starting validation at step 31000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 896.16it/s]\n",
            "[2024-10-23 15:26:28 I] Validation loop at step 31000:\n",
            "[2024-10-23 15:26:28 I]     loss = 0.04153050847053529\n",
            "[2024-10-23 15:26:28 I]     mse = 0.04153050847053529\n",
            "[2024-10-23 15:26:28 I]     rmse = 0.20343035339911675\n",
            "[2024-10-23 15:26:28 I]     output_reg = 0.0\n",
            "[2024-10-23 15:26:28 I]     mae = 0.15509348497390746\n",
            "Training epochs:  64% 2000/3125 [02:43<01:18, 14.27it/s][2024-10-23 15:26:34 I] Starting validation at step 32000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 865.22it/s]\n",
            "[2024-10-23 15:26:34 I] Validation loop at step 32000:\n",
            "[2024-10-23 15:26:34 I]     loss = 0.04157655696868895\n",
            "[2024-10-23 15:26:34 I]     mse = 0.04157655696868895\n",
            "[2024-10-23 15:26:34 I]     rmse = 0.2035358298928863\n",
            "[2024-10-23 15:26:34 I]     output_reg = 0.0\n",
            "[2024-10-23 15:26:34 I]     mae = 0.15510866887569422\n",
            "Training epochs:  66% 2062/3125 [02:48<01:14, 14.31it/s][2024-10-23 15:26:39 I] Starting validation at step 33000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 762.74it/s]\n",
            "[2024-10-23 15:26:39 I] Validation loop at step 33000:\n",
            "[2024-10-23 15:26:39 I]     loss = 0.04149180481433868\n",
            "[2024-10-23 15:26:39 I]     mse = 0.04149180481433868\n",
            "[2024-10-23 15:26:39 I]     rmse = 0.2033241190121206\n",
            "[2024-10-23 15:26:39 I]     output_reg = 0.0\n",
            "[2024-10-23 15:26:39 I]     mae = 0.15492347373962403\n",
            "Training epochs:  68% 2124/3125 [02:54<01:24, 11.81it/s][2024-10-23 15:26:44 I] Starting validation at step 34000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 843.18it/s]\n",
            "[2024-10-23 15:26:44 I] Validation loop at step 34000:\n",
            "[2024-10-23 15:26:44 I]     loss = 0.041550210207700715\n",
            "[2024-10-23 15:26:44 I]     mse = 0.041550210207700715\n",
            "[2024-10-23 15:26:44 I]     rmse = 0.20346503144499073\n",
            "[2024-10-23 15:26:44 I]     output_reg = 0.0\n",
            "[2024-10-23 15:26:44 I]     mae = 0.15497951066493987\n",
            "Training epochs:  70% 2186/3125 [02:58<01:08, 13.80it/s][2024-10-23 15:26:49 I] Starting validation at step 35000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 867.17it/s]\n",
            "[2024-10-23 15:26:49 I] Validation loop at step 35000:\n",
            "[2024-10-23 15:26:49 I]     loss = 0.04157468417882919\n",
            "[2024-10-23 15:26:49 I]     mse = 0.04157468417882919\n",
            "[2024-10-23 15:26:49 I]     rmse = 0.20351989583382732\n",
            "[2024-10-23 15:26:49 I]     output_reg = 0.0\n",
            "[2024-10-23 15:26:49 I]     mae = 0.15500958676338195\n",
            "Training epochs:  72% 2250/3125 [03:04<01:10, 12.45it/s][2024-10-23 15:26:54 I] Starting validation at step 36000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 641.45it/s]\n",
            "[2024-10-23 15:26:54 I] Validation loop at step 36000:\n",
            "[2024-10-23 15:26:54 I]     loss = 0.04155153800845144\n",
            "[2024-10-23 15:26:54 I]     mse = 0.04155153800845144\n",
            "[2024-10-23 15:26:54 I]     rmse = 0.2034612375991513\n",
            "[2024-10-23 15:26:54 I]     output_reg = 0.0\n",
            "[2024-10-23 15:26:54 I]     mae = 0.15491408917903898\n",
            "Training epochs:  74% 2312/3125 [03:09<00:57, 14.10it/s][2024-10-23 15:27:00 I] Starting validation at step 37000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 824.15it/s]\n",
            "[2024-10-23 15:27:00 I] Validation loop at step 37000:\n",
            "[2024-10-23 15:27:00 I]     loss = 0.04156724346876145\n",
            "[2024-10-23 15:27:00 I]     mse = 0.04156724346876145\n",
            "[2024-10-23 15:27:00 I]     rmse = 0.2034954760566553\n",
            "[2024-10-23 15:27:00 I]     output_reg = 0.0\n",
            "[2024-10-23 15:27:00 I]     mae = 0.15491007955074304\n",
            "Training epochs:  76% 2374/3125 [03:14<00:52, 14.24it/s][2024-10-23 15:27:05 I] Starting validation at step 38000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 902.63it/s]\n",
            "[2024-10-23 15:27:05 I] Validation loop at step 38000:\n",
            "[2024-10-23 15:27:05 I]     loss = 0.04155100001096726\n",
            "[2024-10-23 15:27:05 I]     mse = 0.04155100001096726\n",
            "[2024-10-23 15:27:05 I]     rmse = 0.20345492581858846\n",
            "[2024-10-23 15:27:05 I]     output_reg = 0.0\n",
            "[2024-10-23 15:27:05 I]     mae = 0.15486236104965212\n",
            "Training epochs:  78% 2436/3125 [03:19<00:50, 13.55it/s][2024-10-23 15:27:10 I] Starting validation at step 39000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 845.41it/s]\n",
            "[2024-10-23 15:27:10 I] Validation loop at step 39000:\n",
            "[2024-10-23 15:27:10 I]     loss = 0.04158914989829065\n",
            "[2024-10-23 15:27:10 I]     mse = 0.04158914989829065\n",
            "[2024-10-23 15:27:10 I]     rmse = 0.20354516833869957\n",
            "[2024-10-23 15:27:10 I]     output_reg = 0.0\n",
            "[2024-10-23 15:27:10 I]     mae = 0.1548727277755737\n",
            "Training epochs:  80% 2500/3125 [03:24<00:43, 14.50it/s][2024-10-23 15:27:15 I] Starting validation at step 40000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 794.33it/s]\n",
            "[2024-10-23 15:27:15 I] Validation loop at step 40000:\n",
            "[2024-10-23 15:27:15 I]     loss = 0.041563970631361\n",
            "[2024-10-23 15:27:15 I]     mse = 0.041563970631361\n",
            "[2024-10-23 15:27:15 I]     rmse = 0.20348058123829227\n",
            "[2024-10-23 15:27:15 I]     output_reg = 0.0\n",
            "[2024-10-23 15:27:15 I]     mae = 0.15481121737957007\n",
            "Training epochs:  82% 2562/3125 [03:30<00:50, 11.12it/s][2024-10-23 15:27:20 I] Starting validation at step 41000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 565.22it/s]\n",
            "[2024-10-23 15:27:20 I] Validation loop at step 41000:\n",
            "[2024-10-23 15:27:20 I]     loss = 0.0416175557076931\n",
            "[2024-10-23 15:27:20 I]     mse = 0.0416175557076931\n",
            "[2024-10-23 15:27:20 I]     rmse = 0.20361147941981422\n",
            "[2024-10-23 15:27:20 I]     output_reg = 0.0\n",
            "[2024-10-23 15:27:20 I]     mae = 0.15489896800518035\n",
            "Training epochs:  84% 2624/3125 [03:35<00:35, 13.93it/s][2024-10-23 15:27:25 I] Starting validation at step 42000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 851.19it/s]\n",
            "[2024-10-23 15:27:26 I] Validation loop at step 42000:\n",
            "[2024-10-23 15:27:26 I]     loss = 0.041632499730587004\n",
            "[2024-10-23 15:27:26 I]     mse = 0.041632499730587004\n",
            "[2024-10-23 15:27:26 I]     rmse = 0.2036457806804223\n",
            "[2024-10-23 15:27:26 I]     output_reg = 0.0\n",
            "[2024-10-23 15:27:26 I]     mae = 0.15487191350460056\n",
            "Training epochs:  86% 2686/3125 [03:40<00:31, 13.93it/s][2024-10-23 15:27:30 I] Starting validation at step 43000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 854.13it/s]\n",
            "[2024-10-23 15:27:30 I] Validation loop at step 43000:\n",
            "[2024-10-23 15:27:30 I]     loss = 0.041602080845832834\n",
            "[2024-10-23 15:27:30 I]     mse = 0.041602080845832834\n",
            "[2024-10-23 15:27:30 I]     rmse = 0.20357061318773442\n",
            "[2024-10-23 15:27:30 I]     output_reg = 0.0\n",
            "[2024-10-23 15:27:30 I]     mae = 0.1548120630264282\n",
            "Training epochs:  88% 2750/3125 [03:45<00:27, 13.53it/s][2024-10-23 15:27:36 I] Starting validation at step 44000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 857.26it/s]\n",
            "[2024-10-23 15:27:36 I] Validation loop at step 44000:\n",
            "[2024-10-23 15:27:36 I]     loss = 0.04162666186690331\n",
            "[2024-10-23 15:27:36 I]     mse = 0.04162666186690331\n",
            "[2024-10-23 15:27:36 I]     rmse = 0.20362726659131866\n",
            "[2024-10-23 15:27:36 I]     output_reg = 0.0\n",
            "[2024-10-23 15:27:36 I]     mae = 0.15486894264221196\n",
            "Training epochs:  90% 2812/3125 [03:51<00:22, 13.89it/s][2024-10-23 15:27:42 I] Starting validation at step 45000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 828.37it/s]\n",
            "[2024-10-23 15:27:42 I] Validation loop at step 45000:\n",
            "[2024-10-23 15:27:42 I]     loss = 0.04162179135680198\n",
            "[2024-10-23 15:27:42 I]     mse = 0.04162179135680198\n",
            "[2024-10-23 15:27:42 I]     rmse = 0.20361504877001868\n",
            "[2024-10-23 15:27:42 I]     output_reg = 0.0\n",
            "[2024-10-23 15:27:42 I]     mae = 0.15482329044342036\n",
            "Training epochs:  92% 2874/3125 [03:57<00:18, 13.32it/s][2024-10-23 15:27:48 I] Starting validation at step 46000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 805.00it/s]\n",
            "[2024-10-23 15:27:48 I] Validation loop at step 46000:\n",
            "[2024-10-23 15:27:48 I]     loss = 0.04162009966373444\n",
            "[2024-10-23 15:27:48 I]     mse = 0.04162009966373444\n",
            "[2024-10-23 15:27:48 I]     rmse = 0.2036099490107286\n",
            "[2024-10-23 15:27:48 I]     output_reg = 0.0\n",
            "[2024-10-23 15:27:48 I]     mae = 0.15481163947582235\n",
            "Training epochs:  94% 2936/3125 [04:02<00:15, 12.30it/s][2024-10-23 15:27:53 I] Starting validation at step 47000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 691.39it/s]\n",
            "[2024-10-23 15:27:53 I] Validation loop at step 47000:\n",
            "[2024-10-23 15:27:53 I]     loss = 0.04165626637339593\n",
            "[2024-10-23 15:27:53 I]     mse = 0.04165626637339593\n",
            "[2024-10-23 15:27:53 I]     rmse = 0.20369854251790906\n",
            "[2024-10-23 15:27:53 I]     output_reg = 0.0\n",
            "[2024-10-23 15:27:53 I]     mae = 0.1548514385938644\n",
            "Training epochs:  96% 3000/3125 [04:08<00:11, 11.32it/s][2024-10-23 15:27:58 I] Starting validation at step 48000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 574.07it/s]\n",
            "[2024-10-23 15:27:58 I] Validation loop at step 48000:\n",
            "[2024-10-23 15:27:58 I]     loss = 0.041624980688095094\n",
            "[2024-10-23 15:27:58 I]     mse = 0.041624980688095094\n",
            "[2024-10-23 15:27:58 I]     rmse = 0.20361865421243208\n",
            "[2024-10-23 15:27:58 I]     output_reg = 0.0\n",
            "[2024-10-23 15:27:58 I]     mae = 0.15476849093437192\n",
            "Training epochs:  98% 3062/3125 [04:13<00:04, 13.77it/s][2024-10-23 15:28:03 I] Starting validation at step 49000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 767.96it/s]\n",
            "[2024-10-23 15:28:03 I] Validation loop at step 49000:\n",
            "[2024-10-23 15:28:04 I]     loss = 0.04167915544509888\n",
            "[2024-10-23 15:28:04 I]     mse = 0.04167915544509888\n",
            "[2024-10-23 15:28:04 I]     rmse = 0.20375061059012134\n",
            "[2024-10-23 15:28:04 I]     output_reg = 0.0\n",
            "[2024-10-23 15:28:04 I]     mae = 0.15485441389083857\n",
            "Training epochs: 100% 3125/3125 [04:18<00:00, 12.09it/s]\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 886.43it/s]\n",
            "[2024-10-23 15:28:09 I] Validation loop at step 50000:\n",
            "[2024-10-23 15:28:09 I]     loss = 0.04164799069166184\n",
            "[2024-10-23 15:28:09 I]     mse = 0.04164799069166184\n",
            "[2024-10-23 15:28:09 I]     rmse = 0.20367308114447602\n",
            "[2024-10-23 15:28:09 I]     output_reg = 0.0\n",
            "[2024-10-23 15:28:09 I]     mae = 0.1547979464530945\n",
            "[2024-10-23 15:28:09 I] Early stopping after step 33000 with validation loss 0.04149180481433868\n",
            "[2024-10-23 15:28:09 I] Saving model at $/content/nbody_data/experiments/nbody/mlp_50000/models/model_final.pt\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 813.83it/s]\n",
            "[2024-10-23 15:28:09 I] Ran evaluation on dataset e3_generalization:\n",
            "[2024-10-23 15:28:09 I]     loss = 0.36357055664062493\n",
            "[2024-10-23 15:28:09 I]     mse = 0.36357055664062493\n",
            "[2024-10-23 15:28:09 I]     rmse = 0.6026470568956843\n",
            "[2024-10-23 15:28:09 I]     output_reg = 0.0\n",
            "[2024-10-23 15:28:09 I]     mae = 0.4657669799804688\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 854.71it/s]\n",
            "[2024-10-23 15:28:09 I] Ran evaluation on dataset eval:\n",
            "[2024-10-23 15:28:09 I]     loss = 0.04141477018594743\n",
            "[2024-10-23 15:28:09 I]     mse = 0.04141477018594743\n",
            "[2024-10-23 15:28:09 I]     rmse = 0.2032669574393472\n",
            "[2024-10-23 15:28:09 I]     output_reg = 0.0\n",
            "[2024-10-23 15:28:09 I]     mae = 0.1543530879020691\n",
            "[2024-10-23 15:28:09 I] Anders nog iets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ordinary transformer"
      ],
      "metadata": {
        "id": "Z58d0goz_YgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=transformer_nbody data.subsample=0.01 training.steps=5000 run_name=transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_6FSaB_-fhQ",
        "outputId": "5e0bd151-db75-47c9-c9ab-caa319c3458c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 15:30:35 I] Hoi.\n",
            "[2024-10-23 15:30:35 I] Set experiment nbody with ID 1, artifact location file:/content/geometric-algebra-transformer/$/content/nbody_data/tracking/artifacts\n",
            "[2024-10-23 15:30:35 I] Logger already initialized - hi again!\n",
            "[2024-10-23 15:30:35 I] Running experiment at $/content/nbody_data/experiments/nbody/transformer\n",
            "[2024-10-23 15:30:35 I] Saving config at $/content/nbody_data/experiments/nbody/transformer/config.yml\n",
            "[2024-10-23 15:30:36 I] Model has 11.83M learnable parameters\n",
            "[2024-10-23 15:30:36 I] Starting training\n",
            "[2024-10-23 15:30:36 I] Training for 5000 steps, that is, 313 epochs on a dataset of size 1000 with batchsize 64\n",
            "Training epochs:   0% 0/313 [00:00<?, ?it/s][2024-10-23 15:30:37 I] Finished first forward pass with loss 396.880126953125\n",
            "Training epochs:  20% 62/313 [00:26<01:36,  2.60it/s][2024-10-23 15:31:03 I] Starting validation at step 1000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 114.51it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 117.55it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 116.76it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 117.56it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 117.26it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.87it/s]\n",
            "[2024-10-23 15:31:04 I] Validation loop at step 1000:\n",
            "[2024-10-23 15:31:04 I]     loss = 0.02419117076396942\n",
            "[2024-10-23 15:31:04 I]     mse = 0.02419117076396942\n",
            "[2024-10-23 15:31:04 I]     rmse = 0.15357492230196063\n",
            "[2024-10-23 15:31:04 I]     output_reg = 0.0\n",
            "[2024-10-23 15:31:04 I]     mae = 0.11255703284740447\n",
            "Training epochs:  40% 125/313 [00:53<01:11,  2.62it/s][2024-10-23 15:31:30 I] Starting validation at step 2000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:00, 76.84it/s]\u001b[A\n",
            "Evaluating:  22% 17/79 [00:00<00:00, 82.21it/s]\u001b[A\n",
            "Evaluating:  34% 27/79 [00:00<00:00, 86.42it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 88.25it/s]\u001b[A\n",
            "Evaluating:  59% 47/79 [00:00<00:00, 89.26it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:00<00:00, 85.66it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:00<00:00, 85.39it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 86.74it/s]\n",
            "[2024-10-23 15:31:31 I] Validation loop at step 2000:\n",
            "[2024-10-23 15:31:31 I]     loss = 0.009887031087279324\n",
            "[2024-10-23 15:31:31 I]     mse = 0.009887031087279324\n",
            "[2024-10-23 15:31:31 I]     rmse = 0.09705725124086097\n",
            "[2024-10-23 15:31:31 I]     output_reg = 0.0\n",
            "[2024-10-23 15:31:31 I]     mae = 0.06823981394767763\n",
            "Training epochs:  60% 187/313 [01:20<01:03,  1.98it/s][2024-10-23 15:31:57 I] Starting validation at step 3000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:01, 70.86it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:00<00:00, 84.53it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:00<00:00, 98.34it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:00<00:00, 105.62it/s]\u001b[A\n",
            "Evaluating:  67% 53/79 [00:00<00:00, 104.08it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 105.75it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 103.02it/s]\n",
            "[2024-10-23 15:31:58 I] Validation loop at step 3000:\n",
            "[2024-10-23 15:31:58 I]     loss = 0.00576916720569134\n",
            "[2024-10-23 15:31:58 I]     mse = 0.00576916720569134\n",
            "[2024-10-23 15:31:58 I]     rmse = 0.07324682611198347\n",
            "[2024-10-23 15:31:58 I]     output_reg = 0.0\n",
            "[2024-10-23 15:31:58 I]     mae = 0.0432604037284851\n",
            "Training epochs:  80% 250/313 [01:48<00:30,  2.09it/s][2024-10-23 15:32:25 I] Starting validation at step 4000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 121.53it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 119.68it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 120.53it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:00<00:00, 120.20it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:00<00:00, 118.75it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 118.77it/s]\n",
            "[2024-10-23 15:32:26 I] Validation loop at step 4000:\n",
            "[2024-10-23 15:32:26 I]     loss = 0.0052106206327676785\n",
            "[2024-10-23 15:32:26 I]     mse = 0.0052106206327676785\n",
            "[2024-10-23 15:32:26 I]     rmse = 0.06936322494343758\n",
            "[2024-10-23 15:32:26 I]     output_reg = 0.0\n",
            "[2024-10-23 15:32:26 I]     mae = 0.03803061507940291\n",
            "Training epochs: 100% 312/313 [02:16<00:00,  2.52it/s][2024-10-23 15:32:53 I] Starting validation at step 5000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  14% 11/79 [00:00<00:00, 105.13it/s]\u001b[A\n",
            "Evaluating:  29% 23/79 [00:00<00:00, 110.87it/s]\u001b[A\n",
            "Evaluating:  44% 35/79 [00:00<00:00, 113.51it/s]\u001b[A\n",
            "Evaluating:  59% 47/79 [00:00<00:00, 114.07it/s]\u001b[A\n",
            "Evaluating:  75% 59/79 [00:00<00:00, 114.12it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.67it/s]\n",
            "[2024-10-23 15:32:53 I] Validation loop at step 5000:\n",
            "[2024-10-23 15:32:53 I]     loss = 0.005096202720329166\n",
            "[2024-10-23 15:32:53 I]     mse = 0.005096202720329166\n",
            "[2024-10-23 15:32:53 I]     rmse = 0.06858057410337404\n",
            "[2024-10-23 15:32:54 I]     output_reg = 0.0\n",
            "[2024-10-23 15:32:54 I]     mae = 0.036872980761528014\n",
            "Training epochs: 100% 313/313 [02:17<00:00,  2.28it/s]\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 113.38it/s]\n",
            "[2024-10-23 15:32:54 I] Validation loop at step 5000:\n",
            "[2024-10-23 15:32:54 I]     loss = 0.005096202720329166\n",
            "[2024-10-23 15:32:54 I]     mse = 0.005096202720329166\n",
            "[2024-10-23 15:32:54 I]     rmse = 0.06858057410337404\n",
            "[2024-10-23 15:32:54 I]     output_reg = 0.0\n",
            "[2024-10-23 15:32:54 I]     mae = 0.036872980761528014\n",
            "[2024-10-23 15:32:54 I] Saving model at $/content/nbody_data/experiments/nbody/transformer/models/model_final.pt\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 112.97it/s]\n",
            "[2024-10-23 15:32:55 I] Ran evaluation on dataset object_generalization:\n",
            "[2024-10-23 15:32:55 I]     loss = 0.005322465253248811\n",
            "[2024-10-23 15:32:55 I]     mse = 0.005322465253248811\n",
            "[2024-10-23 15:32:55 I]     rmse = 0.07210445477489125\n",
            "[2024-10-23 15:32:55 I]     output_reg = 0.0\n",
            "[2024-10-23 15:32:55 I]     mae = 0.0405603210926056\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.72it/s]\n",
            "[2024-10-23 15:32:56 I] Ran evaluation on dataset eval:\n",
            "[2024-10-23 15:32:56 I]     loss = 0.0045795121580362325\n",
            "[2024-10-23 15:32:56 I]     mse = 0.0045795121580362325\n",
            "[2024-10-23 15:32:56 I]     rmse = 0.06651891689910651\n",
            "[2024-10-23 15:32:56 I]     output_reg = 0.0\n",
            "[2024-10-23 15:32:56 I]     mae = 0.036450349068641676\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 111.43it/s]\n",
            "[2024-10-23 15:32:57 I] Ran evaluation on dataset e3_generalization:\n",
            "[2024-10-23 15:32:57 I]     loss = 184.0531524658204\n",
            "[2024-10-23 15:32:57 I]     mse = 184.0531524658204\n",
            "[2024-10-23 15:32:57 I]     rmse = 13.561968893145115\n",
            "[2024-10-23 15:32:57 I]     output_reg = 0.0\n",
            "[2024-10-23 15:32:57 I]     mae = 10.40671163940429\n",
            "[2024-10-23 15:32:57 I] Anders nog iets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=transformer_nbody data.subsample=0.01 training.steps=20000 run_name=transformer_20000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYaA3PU8AdZ1",
        "outputId": "e44a9c84-e6a7-46bd-8900-adda02d0865e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 15:33:44 I] Hoi.\n",
            "[2024-10-23 15:33:44 I] Set experiment nbody with ID 1, artifact location file:/content/geometric-algebra-transformer/$/content/nbody_data/tracking/artifacts\n",
            "[2024-10-23 15:33:44 I] Logger already initialized - hi again!\n",
            "[2024-10-23 15:33:44 I] Running experiment at $/content/nbody_data/experiments/nbody/transformer_20000\n",
            "[2024-10-23 15:33:44 I] Saving config at $/content/nbody_data/experiments/nbody/transformer_20000/config.yml\n",
            "[2024-10-23 15:33:45 I] Model has 11.83M learnable parameters\n",
            "[2024-10-23 15:33:45 I] Starting training\n",
            "[2024-10-23 15:33:45 I] Training for 20000 steps, that is, 1250 epochs on a dataset of size 1000 with batchsize 64\n",
            "Training epochs:   0% 0/1250 [00:00<?, ?it/s][2024-10-23 15:33:46 I] Finished first forward pass with loss 396.880126953125\n",
            "Training epochs:   5% 62/1250 [00:27<09:46,  2.03it/s][2024-10-23 15:34:12 I] Starting validation at step 1000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   9% 7/79 [00:00<00:01, 64.55it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:00<00:01, 61.02it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 79.20it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 92.67it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 97.28it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 101.92it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 96.85it/s] \n",
            "[2024-10-23 15:34:13 I] Validation loop at step 1000:\n",
            "[2024-10-23 15:34:13 I]     loss = 0.02419117076396942\n",
            "[2024-10-23 15:34:13 I]     mse = 0.02419117076396942\n",
            "[2024-10-23 15:34:13 I]     rmse = 0.15357492230196063\n",
            "[2024-10-23 15:34:13 I]     output_reg = 0.0\n",
            "[2024-10-23 15:34:13 I]     mae = 0.11255703284740447\n",
            "Training epochs:  10% 125/1250 [00:54<07:45,  2.41it/s][2024-10-23 15:34:40 I] Starting validation at step 2000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 115.32it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 111.34it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 111.91it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 113.50it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 112.80it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 113.94it/s]\n",
            "[2024-10-23 15:34:40 I] Validation loop at step 2000:\n",
            "[2024-10-23 15:34:40 I]     loss = 0.006841438661515715\n",
            "[2024-10-23 15:34:40 I]     mse = 0.006841438661515715\n",
            "[2024-10-23 15:34:40 I]     rmse = 0.0800617822593256\n",
            "[2024-10-23 15:34:40 I]     output_reg = 0.0\n",
            "[2024-10-23 15:34:40 I]     mae = 0.05066228060126302\n",
            "Training epochs:  15% 187/1250 [01:22<09:24,  1.88it/s][2024-10-23 15:35:08 I] Starting validation at step 3000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 117.29it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 117.04it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 110.67it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 112.28it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 113.24it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 113.19it/s]\n",
            "[2024-10-23 15:35:09 I] Validation loop at step 3000:\n",
            "[2024-10-23 15:35:09 I]     loss = 0.00717923160791397\n",
            "[2024-10-23 15:35:09 I]     mse = 0.00717923160791397\n",
            "[2024-10-23 15:35:09 I]     rmse = 0.08313493093651902\n",
            "[2024-10-23 15:35:09 I]     output_reg = 0.0\n",
            "[2024-10-23 15:35:09 I]     mae = 0.05611108760833741\n",
            "Training epochs:  20% 250/1250 [01:49<06:26,  2.59it/s][2024-10-23 15:35:35 I] Starting validation at step 4000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 116.68it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 118.97it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 117.22it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 117.01it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 115.00it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 112.89it/s]\n",
            "[2024-10-23 15:35:36 I] Validation loop at step 4000:\n",
            "[2024-10-23 15:35:36 I]     loss = 0.006542416585981847\n",
            "[2024-10-23 15:35:36 I]     mse = 0.006542416585981847\n",
            "[2024-10-23 15:35:36 I]     rmse = 0.07928513239143485\n",
            "[2024-10-23 15:35:36 I]     output_reg = 0.0\n",
            "[2024-10-23 15:35:36 I]     mae = 0.051450468146801\n",
            "Training epochs:  25% 312/1250 [02:16<06:05,  2.57it/s][2024-10-23 15:36:02 I] Starting validation at step 5000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 118.44it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 119.04it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 116.95it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 117.86it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 115.65it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 113.94it/s]\n",
            "[2024-10-23 15:36:03 I] Validation loop at step 5000:\n",
            "[2024-10-23 15:36:03 I]     loss = 0.006251880019903182\n",
            "[2024-10-23 15:36:03 I]     mse = 0.006251880019903182\n",
            "[2024-10-23 15:36:03 I]     rmse = 0.07818840741197255\n",
            "[2024-10-23 15:36:03 I]     output_reg = 0.0\n",
            "[2024-10-23 15:36:03 I]     mae = 0.05252064484357835\n",
            "Training epochs:  30% 375/1250 [02:44<06:22,  2.29it/s][2024-10-23 15:36:30 I] Starting validation at step 6000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:00, 88.96it/s]\u001b[A\n",
            "Evaluating:  24% 19/79 [00:00<00:00, 87.61it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:00<00:00, 80.82it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 78.13it/s]\u001b[A\n",
            "Evaluating:  57% 45/79 [00:00<00:00, 78.34it/s]\u001b[A\n",
            "Evaluating:  67% 53/79 [00:00<00:00, 76.92it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 74.17it/s]\u001b[A\n",
            "Evaluating:  87% 69/79 [00:00<00:00, 70.49it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:01<00:00, 75.49it/s]\n",
            "[2024-10-23 15:36:31 I] Validation loop at step 6000:\n",
            "[2024-10-23 15:36:31 I]     loss = 0.004892373391985894\n",
            "[2024-10-23 15:36:31 I]     mse = 0.004892373391985894\n",
            "[2024-10-23 15:36:31 I]     rmse = 0.06894262622807439\n",
            "[2024-10-23 15:36:31 I]     output_reg = 0.0\n",
            "[2024-10-23 15:36:31 I]     mae = 0.040245115351676936\n",
            "Training epochs:  35% 437/1250 [03:12<06:21,  2.13it/s][2024-10-23 15:36:57 I] Starting validation at step 7000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 119.30it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 117.06it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 115.65it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 116.39it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 112.24it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.12it/s]\n",
            "[2024-10-23 15:36:58 I] Validation loop at step 7000:\n",
            "[2024-10-23 15:36:58 I]     loss = 0.005920159915089608\n",
            "[2024-10-23 15:36:58 I]     mse = 0.005920159915089608\n",
            "[2024-10-23 15:36:58 I]     rmse = 0.07601834046512151\n",
            "[2024-10-23 15:36:58 I]     output_reg = 0.0\n",
            "[2024-10-23 15:36:58 I]     mae = 0.04686533874273299\n",
            "Training epochs:  40% 500/1250 [03:39<05:03,  2.47it/s][2024-10-23 15:37:25 I] Starting validation at step 8000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 119.88it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 112.30it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 113.54it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 112.69it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 113.73it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 108.70it/s]\n",
            "[2024-10-23 15:37:25 I] Validation loop at step 8000:\n",
            "[2024-10-23 15:37:25 I]     loss = 0.006295007403194906\n",
            "[2024-10-23 15:37:25 I]     mse = 0.006295007403194906\n",
            "[2024-10-23 15:37:25 I]     rmse = 0.07845078812674153\n",
            "[2024-10-23 15:37:25 I]     output_reg = 0.0\n",
            "[2024-10-23 15:37:25 I]     mae = 0.0500282003760338\n",
            "Training epochs:  45% 562/1250 [04:06<04:29,  2.55it/s][2024-10-23 15:37:52 I] Starting validation at step 9000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 118.18it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 115.33it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 114.64it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 109.35it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 112.41it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 113.16it/s]\n",
            "[2024-10-23 15:37:52 I] Validation loop at step 9000:\n",
            "[2024-10-23 15:37:52 I]     loss = 0.005477894778549673\n",
            "[2024-10-23 15:37:52 I]     mse = 0.005477894778549673\n",
            "[2024-10-23 15:37:52 I]     rmse = 0.07310736023900018\n",
            "[2024-10-23 15:37:52 I]     output_reg = 0.0\n",
            "[2024-10-23 15:37:52 I]     mae = 0.04304238247871398\n",
            "Training epochs:  50% 625/1250 [04:33<04:00,  2.60it/s][2024-10-23 15:38:19 I] Starting validation at step 10000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  14% 11/79 [00:00<00:00, 103.27it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:00<00:00, 106.01it/s]\u001b[A\n",
            "Evaluating:  42% 33/79 [00:00<00:00, 106.54it/s]\u001b[A\n",
            "Evaluating:  57% 45/79 [00:00<00:00, 110.55it/s]\u001b[A\n",
            "Evaluating:  72% 57/79 [00:00<00:00, 111.23it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 111.16it/s]\n",
            "[2024-10-23 15:38:19 I] Validation loop at step 10000:\n",
            "[2024-10-23 15:38:19 I]     loss = 0.0055734415292739885\n",
            "[2024-10-23 15:38:19 I]     mse = 0.0055734415292739885\n",
            "[2024-10-23 15:38:19 I]     rmse = 0.07372911796386826\n",
            "[2024-10-23 15:38:19 I]     output_reg = 0.0\n",
            "[2024-10-23 15:38:19 I]     mae = 0.04287756802439689\n",
            "Training epochs:  55% 687/1250 [05:00<03:39,  2.57it/s][2024-10-23 15:38:46 I] Starting validation at step 11000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 117.31it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 117.20it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 115.15it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 113.52it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 107.94it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 110.87it/s]\n",
            "[2024-10-23 15:38:47 I] Validation loop at step 11000:\n",
            "[2024-10-23 15:38:47 I]     loss = 0.005542643944919111\n",
            "[2024-10-23 15:38:47 I]     mse = 0.005542643944919111\n",
            "[2024-10-23 15:38:47 I]     rmse = 0.07357197898621821\n",
            "[2024-10-23 15:38:47 I]     output_reg = 0.0\n",
            "[2024-10-23 15:38:47 I]     mae = 0.04213973472118379\n",
            "Training epochs:  60% 750/1250 [05:29<04:43,  1.76it/s][2024-10-23 15:39:15 I] Starting validation at step 12000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:01, 69.90it/s]\u001b[A\n",
            "Evaluating:  19% 15/79 [00:00<00:00, 67.90it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 81.65it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:00<00:00, 73.28it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:00<00:00, 72.34it/s]\u001b[A\n",
            "Evaluating:  67% 53/79 [00:00<00:00, 83.00it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:00<00:00, 92.79it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 85.55it/s]\n",
            "[2024-10-23 15:39:15 I] Validation loop at step 12000:\n",
            "[2024-10-23 15:39:15 I]     loss = 0.005775870707631111\n",
            "[2024-10-23 15:39:15 I]     mse = 0.005775870707631111\n",
            "[2024-10-23 15:39:15 I]     rmse = 0.07514507248062868\n",
            "[2024-10-23 15:39:15 I]     output_reg = 0.0\n",
            "[2024-10-23 15:39:16 I]     mae = 0.043644179886579516\n",
            "Training epochs:  65% 812/1250 [05:56<02:57,  2.46it/s][2024-10-23 15:39:42 I] Starting validation at step 13000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  14% 11/79 [00:00<00:00, 102.15it/s]\u001b[A\n",
            "Evaluating:  29% 23/79 [00:00<00:00, 110.85it/s]\u001b[A\n",
            "Evaluating:  44% 35/79 [00:00<00:00, 112.73it/s]\u001b[A\n",
            "Evaluating:  59% 47/79 [00:00<00:00, 115.05it/s]\u001b[A\n",
            "Evaluating:  75% 59/79 [00:00<00:00, 113.42it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 112.88it/s]\n",
            "[2024-10-23 15:39:43 I] Validation loop at step 13000:\n",
            "[2024-10-23 15:39:43 I]     loss = 0.005820167919248343\n",
            "[2024-10-23 15:39:43 I]     mse = 0.005820167919248343\n",
            "[2024-10-23 15:39:43 I]     rmse = 0.07542257141871798\n",
            "[2024-10-23 15:39:43 I]     output_reg = 0.0\n",
            "[2024-10-23 15:39:43 I]     mae = 0.043029494583606706\n",
            "Training epochs:  70% 875/1250 [06:24<02:30,  2.49it/s][2024-10-23 15:40:10 I] Starting validation at step 14000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 117.46it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 109.45it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 110.37it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 109.93it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 110.18it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 111.68it/s]\n",
            "[2024-10-23 15:40:11 I] Validation loop at step 14000:\n",
            "[2024-10-23 15:40:11 I]     loss = 0.005983086358755827\n",
            "[2024-10-23 15:40:11 I]     mse = 0.005983086358755827\n",
            "[2024-10-23 15:40:11 I]     rmse = 0.07646357197714587\n",
            "[2024-10-23 15:40:11 I]     output_reg = 0.0\n",
            "[2024-10-23 15:40:11 I]     mae = 0.04387150300741195\n",
            "Training epochs:  75% 937/1250 [06:51<02:02,  2.56it/s][2024-10-23 15:40:37 I] Starting validation at step 15000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 120.26it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 119.03it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 115.38it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 116.32it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 116.59it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.02it/s]\n",
            "[2024-10-23 15:40:38 I] Validation loop at step 15000:\n",
            "[2024-10-23 15:40:38 I]     loss = 0.005996173935383559\n",
            "[2024-10-23 15:40:38 I]     mse = 0.005996173935383559\n",
            "[2024-10-23 15:40:38 I]     rmse = 0.07653438734232113\n",
            "[2024-10-23 15:40:38 I]     output_reg = 0.0\n",
            "[2024-10-23 15:40:38 I]     mae = 0.04320225628614426\n",
            "Training epochs:  80% 1000/1250 [07:19<01:37,  2.56it/s][2024-10-23 15:41:04 I] Starting validation at step 16000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 118.00it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 117.75it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 115.27it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 117.03it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 111.07it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.64it/s]\n",
            "[2024-10-23 15:41:05 I] Validation loop at step 16000:\n",
            "[2024-10-23 15:41:05 I]     loss = 0.006113019697368143\n",
            "[2024-10-23 15:41:05 I]     mse = 0.006113019697368143\n",
            "[2024-10-23 15:41:05 I]     rmse = 0.07728737595820526\n",
            "[2024-10-23 15:41:05 I]     output_reg = 0.0\n",
            "[2024-10-23 15:41:05 I]     mae = 0.043414529556036016\n",
            "Training epochs:  85% 1062/1250 [07:46<01:20,  2.33it/s][2024-10-23 15:41:32 I] Starting validation at step 17000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  11% 9/79 [00:00<00:00, 84.30it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:00<00:00, 86.31it/s]\u001b[A\n",
            "Evaluating:  34% 27/79 [00:00<00:00, 80.09it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 76.73it/s]\u001b[A\n",
            "Evaluating:  57% 45/79 [00:00<00:00, 79.36it/s]\u001b[A\n",
            "Evaluating:  67% 53/79 [00:00<00:00, 77.18it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 77.07it/s]\u001b[A\n",
            "Evaluating:  87% 69/79 [00:00<00:00, 75.99it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:01<00:00, 76.72it/s]\n",
            "[2024-10-23 15:41:33 I] Validation loop at step 17000:\n",
            "[2024-10-23 15:41:33 I]     loss = 0.0062495796762406805\n",
            "[2024-10-23 15:41:33 I]     mse = 0.0062495796762406805\n",
            "[2024-10-23 15:41:33 I]     rmse = 0.07817169225531458\n",
            "[2024-10-23 15:41:33 I]     output_reg = 0.0\n",
            "[2024-10-23 15:41:33 I]     mae = 0.044236828410625456\n",
            "Training epochs:  90% 1125/1250 [08:14<00:56,  2.22it/s][2024-10-23 15:41:59 I] Starting validation at step 18000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 116.92it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 112.08it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 113.39it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 114.86it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 112.27it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 112.94it/s]\n",
            "[2024-10-23 15:42:00 I] Validation loop at step 18000:\n",
            "[2024-10-23 15:42:00 I]     loss = 0.006320311202853918\n",
            "[2024-10-23 15:42:00 I]     mse = 0.006320311202853918\n",
            "[2024-10-23 15:42:00 I]     rmse = 0.07860630516026475\n",
            "[2024-10-23 15:42:00 I]     output_reg = 0.0\n",
            "[2024-10-23 15:42:00 I]     mae = 0.044292162024974824\n",
            "Training epochs:  95% 1187/1250 [08:43<00:33,  1.90it/s][2024-10-23 15:42:29 I] Starting validation at step 19000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 115.44it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 117.24it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 114.87it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 110.10it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 110.78it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 110.21it/s]\n",
            "[2024-10-23 15:42:30 I] Validation loop at step 19000:\n",
            "[2024-10-23 15:42:30 I]     loss = 0.0063663403257727645\n",
            "[2024-10-23 15:42:30 I]     mse = 0.0063663403257727645\n",
            "[2024-10-23 15:42:30 I]     rmse = 0.0788935751666354\n",
            "[2024-10-23 15:42:30 I]     output_reg = 0.0\n",
            "[2024-10-23 15:42:30 I]     mae = 0.044093135708570486\n",
            "Training epochs: 100% 1250/1250 [09:13<00:00,  2.26it/s]\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 96.80it/s]\n",
            "[2024-10-23 15:43:00 I] Validation loop at step 20000:\n",
            "[2024-10-23 15:43:00 I]     loss = 0.006443155187368394\n",
            "[2024-10-23 15:43:00 I]     mse = 0.006443155187368394\n",
            "[2024-10-23 15:43:00 I]     rmse = 0.07937520378929355\n",
            "[2024-10-23 15:43:00 I]     output_reg = 0.0\n",
            "[2024-10-23 15:43:00 I]     mae = 0.04455672482252121\n",
            "[2024-10-23 15:43:00 I] Early stopping after step 6000 with validation loss 0.004892373391985894\n",
            "[2024-10-23 15:43:00 I] Saving model at $/content/nbody_data/experiments/nbody/transformer_20000/models/model_final.pt\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 82.67it/s]\n",
            "[2024-10-23 15:43:01 I] Ran evaluation on dataset object_generalization:\n",
            "[2024-10-23 15:43:01 I]     loss = 0.00788285303376615\n",
            "[2024-10-23 15:43:01 I]     mse = 0.00788285303376615\n",
            "[2024-10-23 15:43:01 I]     rmse = 0.08789525189927841\n",
            "[2024-10-23 15:43:01 I]     output_reg = 0.0\n",
            "[2024-10-23 15:43:01 I]     mae = 0.04997094364762307\n",
            "Evaluating: 100% 79/79 [00:01<00:00, 73.17it/s]\n",
            "[2024-10-23 15:43:02 I] Ran evaluation on dataset e3_generalization:\n",
            "[2024-10-23 15:43:02 I]     loss = 74.70596340332034\n",
            "[2024-10-23 15:43:02 I]     mse = 74.70596340332034\n",
            "[2024-10-23 15:43:02 I]     rmse = 8.639557075350446\n",
            "[2024-10-23 15:43:02 I]     output_reg = 0.0\n",
            "[2024-10-23 15:43:02 I]     mae = 6.664652668762205\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 101.12it/s]\n",
            "[2024-10-23 15:43:03 I] Ran evaluation on dataset eval:\n",
            "[2024-10-23 15:43:03 I]     loss = 0.006087430907413361\n",
            "[2024-10-23 15:43:03 I]     mse = 0.006087430907413361\n",
            "[2024-10-23 15:43:03 I]     rmse = 0.0771123011970445\n",
            "[2024-10-23 15:43:03 I]     output_reg = 0.0\n",
            "[2024-10-23 15:43:03 I]     mae = 0.043780329126119615\n",
            "[2024-10-23 15:43:03 I] Anders nog iets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=transformer_nbody data.subsample=0.01 training.steps=50000 run_name=transformer_50000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O88Plla2Aoo3",
        "outputId": "96d8a514-4687-4ed9-ce22-e0e493af2333"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 15:43:10 I] Hoi.\n",
            "[2024-10-23 15:43:11 I] Set experiment nbody with ID 1, artifact location file:/content/geometric-algebra-transformer/$/content/nbody_data/tracking/artifacts\n",
            "[2024-10-23 15:43:11 I] Logger already initialized - hi again!\n",
            "[2024-10-23 15:43:11 I] Running experiment at $/content/nbody_data/experiments/nbody/transformer_50000\n",
            "[2024-10-23 15:43:11 I] Saving config at $/content/nbody_data/experiments/nbody/transformer_50000/config.yml\n",
            "[2024-10-23 15:43:11 I] Model has 11.83M learnable parameters\n",
            "[2024-10-23 15:43:11 I] Starting training\n",
            "[2024-10-23 15:43:12 I] Training for 50000 steps, that is, 3125 epochs on a dataset of size 1000 with batchsize 64\n",
            "Training epochs:   0% 0/3125 [00:00<?, ?it/s][2024-10-23 15:43:12 I] Finished first forward pass with loss 396.880126953125\n",
            "Training epochs:   2% 62/3125 [00:26<22:24,  2.28it/s][2024-10-23 15:43:39 I] Starting validation at step 1000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:00, 73.56it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:00<00:00, 74.65it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 75.10it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:00<00:00, 74.87it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:00<00:00, 69.98it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 72.15it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:00<00:00, 73.55it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 72.51it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:01<00:00, 74.15it/s]\n",
            "[2024-10-23 15:43:40 I] Validation loop at step 1000:\n",
            "[2024-10-23 15:43:40 I]     loss = 0.02419117076396942\n",
            "[2024-10-23 15:43:40 I]     mse = 0.02419117076396942\n",
            "[2024-10-23 15:43:40 I]     rmse = 0.15357492230196063\n",
            "[2024-10-23 15:43:40 I]     output_reg = 0.0\n",
            "[2024-10-23 15:43:40 I]     mae = 0.11255703284740447\n",
            "Training epochs:   4% 125/3125 [00:54<22:26,  2.23it/s][2024-10-23 15:44:06 I] Starting validation at step 2000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 118.46it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 118.29it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 118.01it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 119.15it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 116.51it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.03it/s]\n",
            "[2024-10-23 15:44:07 I] Validation loop at step 2000:\n",
            "[2024-10-23 15:44:07 I]     loss = 0.009737981197237965\n",
            "[2024-10-23 15:44:07 I]     mse = 0.009737981197237965\n",
            "[2024-10-23 15:44:07 I]     rmse = 0.09693424680051553\n",
            "[2024-10-23 15:44:07 I]     output_reg = 0.0\n",
            "[2024-10-23 15:44:07 I]     mae = 0.06901939886808398\n",
            "Training epochs:   6% 187/3125 [01:21<19:39,  2.49it/s][2024-10-23 15:44:33 I] Starting validation at step 3000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 122.83it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 122.06it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 121.07it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:00<00:00, 120.38it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:00<00:00, 118.35it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 119.08it/s]\n",
            "[2024-10-23 15:44:34 I] Validation loop at step 3000:\n",
            "[2024-10-23 15:44:34 I]     loss = 0.008044677059352396\n",
            "[2024-10-23 15:44:34 I]     mse = 0.008044677059352396\n",
            "[2024-10-23 15:44:34 I]     rmse = 0.08869861837862257\n",
            "[2024-10-23 15:44:34 I]     output_reg = 0.0\n",
            "[2024-10-23 15:44:34 I]     mae = 0.06260831739902498\n",
            "Training epochs:   8% 250/3125 [01:48<18:49,  2.55it/s][2024-10-23 15:45:00 I] Starting validation at step 4000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 119.95it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 121.12it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 120.10it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:00<00:00, 111.10it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 108.61it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 113.52it/s]\n",
            "[2024-10-23 15:45:01 I] Validation loop at step 4000:\n",
            "[2024-10-23 15:45:01 I]     loss = 0.005568149496614932\n",
            "[2024-10-23 15:45:01 I]     mse = 0.005568149496614932\n",
            "[2024-10-23 15:45:01 I]     rmse = 0.07359479558895919\n",
            "[2024-10-23 15:45:01 I]     output_reg = 0.0\n",
            "[2024-10-23 15:45:01 I]     mae = 0.04607584799528122\n",
            "Training epochs:  10% 312/3125 [02:16<18:21,  2.55it/s][2024-10-23 15:45:28 I] Starting validation at step 5000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 112.13it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 113.64it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 114.04it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 109.27it/s]\u001b[A\n",
            "Evaluating:  75% 59/79 [00:00<00:00, 105.83it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 109.46it/s]\n",
            "[2024-10-23 15:45:29 I] Validation loop at step 5000:\n",
            "[2024-10-23 15:45:29 I]     loss = 0.00563628769740462\n",
            "[2024-10-23 15:45:29 I]     mse = 0.00563628769740462\n",
            "[2024-10-23 15:45:29 I]     rmse = 0.07442739165895232\n",
            "[2024-10-23 15:45:29 I]     output_reg = 0.0\n",
            "[2024-10-23 15:45:29 I]     mae = 0.04759740360975268\n",
            "Training epochs:  12% 375/3125 [02:43<17:35,  2.60it/s][2024-10-23 15:45:56 I] Starting validation at step 6000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 121.42it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 116.74it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 117.22it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 117.54it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 112.27it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 113.53it/s]\n",
            "[2024-10-23 15:45:57 I] Validation loop at step 6000:\n",
            "[2024-10-23 15:45:57 I]     loss = 0.005165458939969539\n",
            "[2024-10-23 15:45:57 I]     mse = 0.005165458939969539\n",
            "[2024-10-23 15:45:57 I]     rmse = 0.07133020090395428\n",
            "[2024-10-23 15:45:57 I]     output_reg = 0.0\n",
            "[2024-10-23 15:45:57 I]     mae = 0.045375522583723085\n",
            "Training epochs:  14% 437/3125 [03:10<17:28,  2.56it/s][2024-10-23 15:46:23 I] Starting validation at step 7000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  11% 9/79 [00:00<00:00, 89.95it/s]\u001b[A\n",
            "Evaluating:  24% 19/79 [00:00<00:00, 90.98it/s]\u001b[A\n",
            "Evaluating:  37% 29/79 [00:00<00:00, 90.29it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 84.93it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 86.97it/s]\u001b[A\n",
            "Evaluating:  75% 59/79 [00:00<00:00, 88.71it/s]\u001b[A\n",
            "Evaluating:  87% 69/79 [00:00<00:00, 90.12it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 87.10it/s]\n",
            "[2024-10-23 15:46:24 I] Validation loop at step 7000:\n",
            "[2024-10-23 15:46:24 I]     loss = 0.004884711456298829\n",
            "[2024-10-23 15:46:24 I]     mse = 0.004884711456298829\n",
            "[2024-10-23 15:46:24 I]     rmse = 0.06928547958497595\n",
            "[2024-10-23 15:46:24 I]     output_reg = 0.0\n",
            "[2024-10-23 15:46:24 I]     mae = 0.04165889049768448\n",
            "Training epochs:  16% 500/3125 [03:38<21:31,  2.03it/s][2024-10-23 15:46:50 I] Starting validation at step 8000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 119.43it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 120.95it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 116.76it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 115.62it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 116.14it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.49it/s]\n",
            "[2024-10-23 15:46:51 I] Validation loop at step 8000:\n",
            "[2024-10-23 15:46:51 I]     loss = 0.005436825528740885\n",
            "[2024-10-23 15:46:51 I]     mse = 0.005436825528740885\n",
            "[2024-10-23 15:46:51 I]     rmse = 0.07324628113909695\n",
            "[2024-10-23 15:46:51 I]     output_reg = 0.0\n",
            "[2024-10-23 15:46:51 I]     mae = 0.04721000905036928\n",
            "Training epochs:  18% 562/3125 [04:04<17:47,  2.40it/s][2024-10-23 15:47:17 I] Starting validation at step 9000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 122.36it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 121.50it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 119.55it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:00<00:00, 118.33it/s]\u001b[A\n",
            "Evaluating:  80% 63/79 [00:00<00:00, 116.74it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 117.96it/s]\n",
            "[2024-10-23 15:47:18 I] Validation loop at step 9000:\n",
            "[2024-10-23 15:47:18 I]     loss = 0.006197806343436238\n",
            "[2024-10-23 15:47:18 I]     mse = 0.006197806343436238\n",
            "[2024-10-23 15:47:18 I]     rmse = 0.07832919135309616\n",
            "[2024-10-23 15:47:18 I]     output_reg = 0.0\n",
            "[2024-10-23 15:47:18 I]     mae = 0.053740317314863215\n",
            "Training epochs:  20% 625/3125 [04:32<16:06,  2.59it/s][2024-10-23 15:47:44 I] Starting validation at step 10000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 116.99it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 116.00it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 112.64it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 106.94it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 108.35it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 112.48it/s]\n",
            "[2024-10-23 15:47:45 I] Validation loop at step 10000:\n",
            "[2024-10-23 15:47:45 I]     loss = 0.004796282504498959\n",
            "[2024-10-23 15:47:45 I]     mse = 0.004796282504498959\n",
            "[2024-10-23 15:47:45 I]     rmse = 0.06868379891457377\n",
            "[2024-10-23 15:47:45 I]     output_reg = 0.0\n",
            "[2024-10-23 15:47:45 I]     mae = 0.03996142371892929\n",
            "Training epochs:  22% 687/3125 [04:59<15:39,  2.59it/s][2024-10-23 15:48:11 I] Starting validation at step 11000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 122.81it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 122.03it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 120.59it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:00<00:00, 116.41it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 116.87it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 117.37it/s]\n",
            "[2024-10-23 15:48:12 I] Validation loop at step 11000:\n",
            "[2024-10-23 15:48:12 I]     loss = 0.005811879202723502\n",
            "[2024-10-23 15:48:12 I]     mse = 0.005811879202723502\n",
            "[2024-10-23 15:48:12 I]     rmse = 0.07576546206885927\n",
            "[2024-10-23 15:48:12 I]     output_reg = 0.0\n",
            "[2024-10-23 15:48:12 I]     mae = 0.048717925727367384\n",
            "Training epochs:  24% 750/3125 [05:26<15:01,  2.64it/s][2024-10-23 15:48:38 I] Starting validation at step 12000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 118.33it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 116.33it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 112.24it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 113.39it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 112.64it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.26it/s]\n",
            "[2024-10-23 15:48:39 I] Validation loop at step 12000:\n",
            "[2024-10-23 15:48:39 I]     loss = 0.005297242628782987\n",
            "[2024-10-23 15:48:39 I]     mse = 0.005297242628782987\n",
            "[2024-10-23 15:48:39 I]     rmse = 0.07220047932337864\n",
            "[2024-10-23 15:48:39 I]     output_reg = 0.0\n",
            "[2024-10-23 15:48:39 I]     mae = 0.04480211039781571\n",
            "Training epochs:  26% 812/3125 [05:52<14:55,  2.58it/s][2024-10-23 15:49:05 I] Starting validation at step 13000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 118.23it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 102.41it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 108.55it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 112.52it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 113.33it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 112.55it/s]\n",
            "[2024-10-23 15:49:05 I] Validation loop at step 13000:\n",
            "[2024-10-23 15:49:05 I]     loss = 0.005748979076743125\n",
            "[2024-10-23 15:49:05 I]     mse = 0.005748979076743125\n",
            "[2024-10-23 15:49:05 I]     rmse = 0.07532020923492855\n",
            "[2024-10-23 15:49:05 I]     output_reg = 0.0\n",
            "[2024-10-23 15:49:06 I]     mae = 0.04783730778694152\n",
            "Training epochs:  28% 875/3125 [06:19<14:17,  2.62it/s][2024-10-23 15:49:31 I] Starting validation at step 14000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 117.14it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 118.11it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 103.39it/s]\u001b[A\n",
            "Evaluating:  59% 47/79 [00:00<00:00, 92.28it/s] \u001b[A\n",
            "Evaluating:  72% 57/79 [00:00<00:00, 88.17it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:00<00:00, 86.68it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 92.91it/s]\n",
            "[2024-10-23 15:49:32 I] Validation loop at step 14000:\n",
            "[2024-10-23 15:49:32 I]     loss = 0.005125998626649381\n",
            "[2024-10-23 15:49:32 I]     mse = 0.005125998626649381\n",
            "[2024-10-23 15:49:32 I]     rmse = 0.07106788921813693\n",
            "[2024-10-23 15:49:32 I]     output_reg = 0.0\n",
            "[2024-10-23 15:49:32 I]     mae = 0.042839729022979736\n",
            "Training epochs:  30% 937/3125 [06:46<17:02,  2.14it/s][2024-10-23 15:49:59 I] Starting validation at step 15000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:00, 77.72it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:00<00:00, 78.95it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 77.95it/s]\u001b[A\n",
            "Evaluating:  42% 33/79 [00:00<00:00, 80.15it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:00<00:00, 80.57it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:00<00:00, 79.86it/s]\u001b[A\n",
            "Evaluating:  75% 59/79 [00:00<00:00, 78.05it/s]\u001b[A\n",
            "Evaluating:  85% 67/79 [00:00<00:00, 73.43it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 80.52it/s]\n",
            "[2024-10-23 15:50:00 I] Validation loop at step 15000:\n",
            "[2024-10-23 15:50:00 I]     loss = 0.0053640811786055545\n",
            "[2024-10-23 15:50:00 I]     mse = 0.0053640811786055545\n",
            "[2024-10-23 15:50:00 I]     rmse = 0.07273487646899876\n",
            "[2024-10-23 15:50:00 I]     output_reg = 0.0\n",
            "[2024-10-23 15:50:00 I]     mae = 0.04414491931200027\n",
            "Training epochs:  32% 1000/3125 [07:13<16:08,  2.19it/s][2024-10-23 15:50:26 I] Starting validation at step 16000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 118.59it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 118.11it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 119.24it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 118.37it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 112.16it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 112.68it/s]\n",
            "[2024-10-23 15:50:27 I] Validation loop at step 16000:\n",
            "[2024-10-23 15:50:27 I]     loss = 0.005204095984995367\n",
            "[2024-10-23 15:50:27 I]     mse = 0.005204095984995367\n",
            "[2024-10-23 15:50:27 I]     rmse = 0.07163979064822361\n",
            "[2024-10-23 15:50:27 I]     output_reg = 0.0\n",
            "[2024-10-23 15:50:27 I]     mae = 0.04187689476013183\n",
            "Training epochs:  34% 1062/3125 [07:40<14:02,  2.45it/s][2024-10-23 15:50:53 I] Starting validation at step 17000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 121.97it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 118.81it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 118.40it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 118.04it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 116.95it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.55it/s]\n",
            "[2024-10-23 15:50:53 I] Validation loop at step 17000:\n",
            "[2024-10-23 15:50:53 I]     loss = 0.005101432989537715\n",
            "[2024-10-23 15:50:53 I]     mse = 0.005101432989537715\n",
            "[2024-10-23 15:50:53 I]     rmse = 0.07090513946331395\n",
            "[2024-10-23 15:50:53 I]     output_reg = 0.0\n",
            "[2024-10-23 15:50:53 I]     mae = 0.04072246972322463\n",
            "Training epochs:  36% 1125/3125 [08:07<13:03,  2.55it/s][2024-10-23 15:51:19 I] Starting validation at step 18000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 119.39it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 119.58it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 119.75it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 115.78it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 111.93it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.73it/s]\n",
            "[2024-10-23 15:51:20 I] Validation loop at step 18000:\n",
            "[2024-10-23 15:51:20 I]     loss = 0.005209198588132859\n",
            "[2024-10-23 15:51:20 I]     mse = 0.005209198588132859\n",
            "[2024-10-23 15:51:20 I]     rmse = 0.07167062129059441\n",
            "[2024-10-23 15:51:20 I]     output_reg = 0.0\n",
            "[2024-10-23 15:51:20 I]     mae = 0.04157394094467163\n",
            "Training epochs:  38% 1187/3125 [08:33<12:21,  2.61it/s][2024-10-23 15:51:46 I] Starting validation at step 19000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 119.25it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 118.73it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 117.80it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 118.61it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 118.63it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.67it/s]\n",
            "[2024-10-23 15:51:47 I] Validation loop at step 19000:\n",
            "[2024-10-23 15:51:47 I]     loss = 0.0051049596965312945\n",
            "[2024-10-23 15:51:47 I]     mse = 0.0051049596965312945\n",
            "[2024-10-23 15:51:47 I]     rmse = 0.07091900557222462\n",
            "[2024-10-23 15:51:47 I]     output_reg = 0.0\n",
            "[2024-10-23 15:51:47 I]     mae = 0.040212686842679986\n",
            "Training epochs:  40% 1250/3125 [09:00<11:59,  2.61it/s][2024-10-23 15:52:13 I] Starting validation at step 20000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 116.33it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 117.09it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 118.83it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 116.01it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 116.03it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 113.87it/s]\n",
            "[2024-10-23 15:52:14 I] Validation loop at step 20000:\n",
            "[2024-10-23 15:52:14 I]     loss = 0.005304526609182356\n",
            "[2024-10-23 15:52:14 I]     mse = 0.005304526609182356\n",
            "[2024-10-23 15:52:14 I]     rmse = 0.0723284732923655\n",
            "[2024-10-23 15:52:14 I]     output_reg = 0.0\n",
            "[2024-10-23 15:52:14 I]     mae = 0.04196192353963851\n",
            "Training epochs:  42% 1312/3125 [09:27<11:36,  2.60it/s][2024-10-23 15:52:40 I] Starting validation at step 21000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 117.02it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 117.28it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 118.46it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 118.93it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 115.39it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.39it/s]\n",
            "[2024-10-23 15:52:40 I] Validation loop at step 21000:\n",
            "[2024-10-23 15:52:40 I]     loss = 0.005401232558488848\n",
            "[2024-10-23 15:52:40 I]     mse = 0.005401232558488848\n",
            "[2024-10-23 15:52:40 I]     rmse = 0.07298431528108924\n",
            "[2024-10-23 15:52:40 I]     output_reg = 0.0\n",
            "[2024-10-23 15:52:40 I]     mae = 0.041864325320720666\n",
            "Training epochs:  44% 1375/3125 [09:54<11:07,  2.62it/s][2024-10-23 15:53:06 I] Starting validation at step 22000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 120.30it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 121.76it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 121.30it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:00<00:00, 118.54it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 105.20it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 102.92it/s]\n",
            "[2024-10-23 15:53:07 I] Validation loop at step 22000:\n",
            "[2024-10-23 15:53:07 I]     loss = 0.005364885927736761\n",
            "[2024-10-23 15:53:07 I]     mse = 0.005364885927736761\n",
            "[2024-10-23 15:53:07 I]     rmse = 0.07273166885510746\n",
            "[2024-10-23 15:53:07 I]     output_reg = 0.0\n",
            "[2024-10-23 15:53:07 I]     mae = 0.041171031391620636\n",
            "Training epochs:  46% 1437/3125 [10:21<12:28,  2.26it/s][2024-10-23 15:53:33 I] Starting validation at step 23000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  11% 9/79 [00:00<00:00, 80.43it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:00<00:00, 79.16it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 77.38it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:00<00:00, 73.57it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:00<00:00, 75.68it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 76.99it/s]\u001b[A\n",
            "Evaluating:  75% 59/79 [00:00<00:00, 78.53it/s]\u001b[A\n",
            "Evaluating:  85% 67/79 [00:00<00:00, 78.14it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:01<00:00, 77.92it/s]\n",
            "[2024-10-23 15:53:34 I] Validation loop at step 23000:\n",
            "[2024-10-23 15:53:34 I]     loss = 0.005437878352403642\n",
            "[2024-10-23 15:53:34 I]     mse = 0.005437878352403642\n",
            "[2024-10-23 15:53:34 I]     rmse = 0.07321908507425849\n",
            "[2024-10-23 15:53:34 I]     output_reg = 0.0\n",
            "[2024-10-23 15:53:34 I]     mae = 0.041041395014524466\n",
            "Training epochs:  48% 1500/3125 [10:48<12:23,  2.19it/s][2024-10-23 15:54:01 I] Starting validation at step 24000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 115.68it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 116.92it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 118.95it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 119.04it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 118.70it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 118.46it/s]\n",
            "[2024-10-23 15:54:01 I] Validation loop at step 24000:\n",
            "[2024-10-23 15:54:01 I]     loss = 0.005581953874230383\n",
            "[2024-10-23 15:54:01 I]     mse = 0.005581953874230383\n",
            "[2024-10-23 15:54:01 I]     rmse = 0.074213630841206\n",
            "[2024-10-23 15:54:01 I]     output_reg = 0.0\n",
            "[2024-10-23 15:54:01 I]     mae = 0.04227390389442444\n",
            "Training epochs:  50% 1562/3125 [11:15<10:18,  2.53it/s][2024-10-23 15:54:27 I] Starting validation at step 25000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 119.81it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 118.14it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 115.46it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 114.39it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 115.09it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.99it/s]\n",
            "[2024-10-23 15:54:28 I] Validation loop at step 25000:\n",
            "[2024-10-23 15:54:28 I]     loss = 0.005586190849542617\n",
            "[2024-10-23 15:54:28 I]     mse = 0.005586190849542617\n",
            "[2024-10-23 15:54:28 I]     rmse = 0.07423914306723714\n",
            "[2024-10-23 15:54:28 I]     output_reg = 0.0\n",
            "[2024-10-23 15:54:28 I]     mae = 0.04218602174520493\n",
            "Training epochs:  52% 1625/3125 [11:42<09:35,  2.60it/s][2024-10-23 15:54:54 I] Starting validation at step 26000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  14% 11/79 [00:00<00:00, 105.78it/s]\u001b[A\n",
            "Evaluating:  29% 23/79 [00:00<00:00, 111.43it/s]\u001b[A\n",
            "Evaluating:  44% 35/79 [00:00<00:00, 114.37it/s]\u001b[A\n",
            "Evaluating:  59% 47/79 [00:00<00:00, 114.61it/s]\u001b[A\n",
            "Evaluating:  75% 59/79 [00:00<00:00, 115.17it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.09it/s]\n",
            "[2024-10-23 15:54:55 I] Validation loop at step 26000:\n",
            "[2024-10-23 15:54:55 I]     loss = 0.005629664734005927\n",
            "[2024-10-23 15:54:55 I]     mse = 0.005629664734005927\n",
            "[2024-10-23 15:54:55 I]     rmse = 0.07448075120698759\n",
            "[2024-10-23 15:54:55 I]     output_reg = 0.0\n",
            "[2024-10-23 15:54:55 I]     mae = 0.0415306476533413\n",
            "Training epochs:  54% 1687/3125 [12:08<09:09,  2.62it/s][2024-10-23 15:55:21 I] Starting validation at step 27000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 122.99it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 118.95it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 119.05it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 118.56it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 117.79it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 118.44it/s]\n",
            "[2024-10-23 15:55:22 I] Validation loop at step 27000:\n",
            "[2024-10-23 15:55:22 I]     loss = 0.0056872147411108015\n",
            "[2024-10-23 15:55:22 I]     mse = 0.0056872147411108015\n",
            "[2024-10-23 15:55:22 I]     rmse = 0.07485661465220315\n",
            "[2024-10-23 15:55:22 I]     output_reg = 0.0\n",
            "[2024-10-23 15:55:22 I]     mae = 0.041638279581069935\n",
            "Training epochs:  56% 1750/3125 [12:35<08:42,  2.63it/s][2024-10-23 15:55:48 I] Starting validation at step 28000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 117.21it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 118.34it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 116.71it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 116.01it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 117.29it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.72it/s]\n",
            "[2024-10-23 15:55:48 I] Validation loop at step 28000:\n",
            "[2024-10-23 15:55:48 I]     loss = 0.005788224713504315\n",
            "[2024-10-23 15:55:48 I]     mse = 0.005788224713504315\n",
            "[2024-10-23 15:55:48 I]     rmse = 0.0755313553326625\n",
            "[2024-10-23 15:55:48 I]     output_reg = 0.0\n",
            "[2024-10-23 15:55:48 I]     mae = 0.043052318733930596\n",
            "Training epochs:  58% 1812/3125 [13:02<08:12,  2.66it/s][2024-10-23 15:56:14 I] Starting validation at step 29000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 123.48it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 123.39it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 120.88it/s]\u001b[A\n",
            "Training epochs:  60% 1875/3125 [13:29<07:55,  2.63it/s][2024-10-23 15:56:41 I] Starting validation at step 30000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:00, 74.31it/s]\u001b[A\n",
            "Evaluating:  22% 17/79 [00:00<00:00, 78.62it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 82.25it/s]\u001b[A\n",
            "Evaluating:  44% 35/79 [00:00<00:00, 84.78it/s]\u001b[A\n",
            "Evaluating:  57% 45/79 [00:00<00:00, 87.59it/s]\u001b[A\n",
            "Evaluating:  70% 55/79 [00:00<00:00, 87.50it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:00<00:00, 90.00it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 86.67it/s]\n",
            "[2024-10-23 15:56:42 I] Validation loop at step 30000:\n",
            "[2024-10-23 15:56:42 I]     loss = 0.005800952591001989\n",
            "[2024-10-23 15:56:42 I]     mse = 0.005800952591001989\n",
            "[2024-10-23 15:56:42 I]     rmse = 0.07559125778485552\n",
            "[2024-10-23 15:56:42 I]     output_reg = 0.0\n",
            "[2024-10-23 15:56:42 I]     mae = 0.041735091608762744\n",
            "Training epochs:  62% 1937/3125 [13:55<09:27,  2.09it/s][2024-10-23 15:57:08 I] Starting validation at step 31000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:00, 72.43it/s]\u001b[A\n",
            "Evaluating:  22% 17/79 [00:00<00:00, 79.28it/s]\u001b[A\n",
            "Evaluating:  37% 29/79 [00:00<00:00, 95.48it/s]\u001b[A\n",
            "Evaluating:  52% 41/79 [00:00<00:00, 103.69it/s]\u001b[A\n",
            "Evaluating:  67% 53/79 [00:00<00:00, 108.43it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:00<00:00, 110.35it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 104.86it/s]\n",
            "[2024-10-23 15:57:09 I] Validation loop at step 31000:\n",
            "[2024-10-23 15:57:09 I]     loss = 0.005907870817184452\n",
            "[2024-10-23 15:57:09 I]     mse = 0.005907870817184452\n",
            "[2024-10-23 15:57:09 I]     rmse = 0.07628762058698774\n",
            "[2024-10-23 15:57:09 I]     output_reg = 0.0\n",
            "[2024-10-23 15:57:09 I]     mae = 0.042601723289489746\n",
            "Training epochs:  64% 2000/3125 [14:22<07:46,  2.41it/s][2024-10-23 15:57:35 I] Starting validation at step 32000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 119.54it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 119.14it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 118.74it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 117.78it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 117.38it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 117.79it/s]\n",
            "[2024-10-23 15:57:35 I] Validation loop at step 32000:\n",
            "[2024-10-23 15:57:35 I]     loss = 0.005979851241409779\n",
            "[2024-10-23 15:57:35 I]     mse = 0.005979851241409779\n",
            "[2024-10-23 15:57:35 I]     rmse = 0.07673589866032887\n",
            "[2024-10-23 15:57:35 I]     output_reg = 0.0\n",
            "[2024-10-23 15:57:35 I]     mae = 0.04269315055608749\n",
            "Training epochs:  66% 2062/3125 [14:49<06:53,  2.57it/s][2024-10-23 15:58:01 I] Starting validation at step 33000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 122.73it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 113.49it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 117.53it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:00<00:00, 119.46it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 116.68it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.94it/s]\n",
            "[2024-10-23 15:58:02 I] Validation loop at step 33000:\n",
            "[2024-10-23 15:58:02 I]     loss = 0.006072429978847505\n",
            "[2024-10-23 15:58:02 I]     mse = 0.006072429978847505\n",
            "[2024-10-23 15:58:02 I]     rmse = 0.077281146805026\n",
            "[2024-10-23 15:58:02 I]     output_reg = 0.0\n",
            "[2024-10-23 15:58:02 I]     mae = 0.04279437533617019\n",
            "Training epochs:  68% 2125/3125 [15:15<06:22,  2.61it/s][2024-10-23 15:58:28 I] Starting validation at step 34000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 122.90it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 114.66it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 107.42it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 107.65it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 106.63it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 111.11it/s]\n",
            "[2024-10-23 15:58:28 I] Validation loop at step 34000:\n",
            "[2024-10-23 15:58:28 I]     loss = 0.00610067069530487\n",
            "[2024-10-23 15:58:28 I]     mse = 0.00610067069530487\n",
            "[2024-10-23 15:58:28 I]     rmse = 0.0774463731500639\n",
            "[2024-10-23 15:58:28 I]     output_reg = 0.0\n",
            "[2024-10-23 15:58:28 I]     mae = 0.04271191126704218\n",
            "Training epochs:  70% 2187/3125 [15:42<06:01,  2.59it/s][2024-10-23 15:58:54 I] Starting validation at step 35000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 119.07it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 119.74it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 117.42it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 117.03it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 117.54it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.82it/s]\n",
            "[2024-10-23 15:58:55 I] Validation loop at step 35000:\n",
            "[2024-10-23 15:58:55 I]     loss = 0.006152873507142067\n",
            "[2024-10-23 15:58:55 I]     mse = 0.006152873507142067\n",
            "[2024-10-23 15:58:55 I]     rmse = 0.07776766246959442\n",
            "[2024-10-23 15:58:55 I]     output_reg = 0.0\n",
            "[2024-10-23 15:58:55 I]     mae = 0.042857373249530796\n",
            "Training epochs:  72% 2250/3125 [16:09<05:44,  2.54it/s][2024-10-23 15:59:21 I] Starting validation at step 36000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 122.86it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 116.07it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 114.16it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 114.96it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 114.99it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 111.36it/s]\n",
            "[2024-10-23 15:59:22 I] Validation loop at step 36000:\n",
            "[2024-10-23 15:59:22 I]     loss = 0.006249475803971292\n",
            "[2024-10-23 15:59:22 I]     mse = 0.006249475803971292\n",
            "[2024-10-23 15:59:22 I]     rmse = 0.07838981531671482\n",
            "[2024-10-23 15:59:22 I]     output_reg = 0.0\n",
            "[2024-10-23 15:59:22 I]     mae = 0.0434855485200882\n",
            "Training epochs:  74% 2312/3125 [16:35<05:10,  2.62it/s][2024-10-23 15:59:48 I] Starting validation at step 37000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 118.27it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 120.42it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 119.72it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:00<00:00, 120.78it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 119.66it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 117.21it/s]\n",
            "[2024-10-23 15:59:48 I] Validation loop at step 37000:\n",
            "[2024-10-23 15:59:48 I]     loss = 0.006296174597740176\n",
            "[2024-10-23 15:59:48 I]     mse = 0.006296174597740176\n",
            "[2024-10-23 15:59:48 I]     rmse = 0.07866965335363775\n",
            "[2024-10-23 15:59:48 I]     output_reg = 0.0\n",
            "[2024-10-23 15:59:48 I]     mae = 0.04338483788371087\n",
            "Training epochs:  76% 2375/3125 [17:02<04:50,  2.58it/s][2024-10-23 16:00:14 I] Starting validation at step 38000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 123.20it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 95.31it/s] \u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 88.54it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:00<00:00, 89.61it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:00<00:00, 87.25it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:00<00:00, 87.20it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 88.54it/s]\n",
            "[2024-10-23 16:00:15 I] Validation loop at step 38000:\n",
            "[2024-10-23 16:00:15 I]     loss = 0.006345289354026318\n",
            "[2024-10-23 16:00:15 I]     mse = 0.006345289354026318\n",
            "[2024-10-23 16:00:15 I]     rmse = 0.07898194347888342\n",
            "[2024-10-23 16:00:15 I]     output_reg = 0.0\n",
            "[2024-10-23 16:00:15 I]     mae = 0.04356246360540387\n",
            "Training epochs:  78% 2437/3125 [17:28<05:05,  2.25it/s][2024-10-23 16:00:41 I] Starting validation at step 39000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:00, 77.65it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:00<00:00, 75.70it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 76.63it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:00<00:00, 77.15it/s]\u001b[A\n",
            "Evaluating:  52% 41/79 [00:00<00:00, 78.80it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 79.14it/s]\u001b[A\n",
            "Evaluating:  72% 57/79 [00:00<00:00, 73.44it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:00<00:00, 74.39it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:01<00:00, 76.64it/s]\n",
            "[2024-10-23 16:00:42 I] Validation loop at step 39000:\n",
            "[2024-10-23 16:00:42 I]     loss = 0.006402188542485235\n",
            "[2024-10-23 16:00:42 I]     mse = 0.006402188542485235\n",
            "[2024-10-23 16:00:42 I]     rmse = 0.07934043604948979\n",
            "[2024-10-23 16:00:42 I]     output_reg = 0.0\n",
            "[2024-10-23 16:00:42 I]     mae = 0.04365197720527649\n",
            "Training epochs:  80% 2500/3125 [17:56<04:51,  2.14it/s][2024-10-23 16:01:08 I] Starting validation at step 40000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 119.48it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 120.55it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 114.05it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:00<00:00, 115.36it/s]\u001b[A\n",
            "Evaluating:  80% 63/79 [00:00<00:00, 115.60it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.75it/s]\n",
            "[2024-10-23 16:01:09 I] Validation loop at step 40000:\n",
            "[2024-10-23 16:01:09 I]     loss = 0.006462357953190806\n",
            "[2024-10-23 16:01:09 I]     mse = 0.006462357953190806\n",
            "[2024-10-23 16:01:09 I]     rmse = 0.07971455963905845\n",
            "[2024-10-23 16:01:09 I]     output_reg = 0.0\n",
            "[2024-10-23 16:01:09 I]     mae = 0.04387539743185043\n",
            "Training epochs:  82% 2562/3125 [18:22<03:48,  2.46it/s][2024-10-23 16:01:35 I] Starting validation at step 41000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 123.85it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 120.80it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 116.50it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:00<00:00, 117.19it/s]\u001b[A\n",
            "Evaluating:  80% 63/79 [00:00<00:00, 117.56it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.50it/s]\n",
            "[2024-10-23 16:01:35 I] Validation loop at step 41000:\n",
            "[2024-10-23 16:01:35 I]     loss = 0.0065007611572742464\n",
            "[2024-10-23 16:01:35 I]     mse = 0.0065007611572742464\n",
            "[2024-10-23 16:01:35 I]     rmse = 0.07995025671706703\n",
            "[2024-10-23 16:01:35 I]     output_reg = 0.0\n",
            "[2024-10-23 16:01:35 I]     mae = 0.04398945612311362\n",
            "Training epochs:  84% 2625/3125 [18:49<03:14,  2.58it/s][2024-10-23 16:02:01 I] Starting validation at step 42000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 121.68it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 120.53it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 118.29it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:00<00:00, 118.28it/s]\u001b[A\n",
            "Evaluating:  80% 63/79 [00:00<00:00, 117.19it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 117.65it/s]\n",
            "[2024-10-23 16:02:02 I] Validation loop at step 42000:\n",
            "[2024-10-23 16:02:02 I]     loss = 0.006574490383267403\n",
            "[2024-10-23 16:02:02 I]     mse = 0.006574490383267403\n",
            "[2024-10-23 16:02:02 I]     rmse = 0.08041578331322811\n",
            "[2024-10-23 16:02:02 I]     output_reg = 0.0\n",
            "[2024-10-23 16:02:02 I]     mae = 0.04420734909772873\n",
            "Training epochs:  86% 2687/3125 [19:15<02:46,  2.62it/s][2024-10-23 16:02:28 I] Starting validation at step 43000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 121.47it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 119.51it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 118.29it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 113.69it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 114.98it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.88it/s]\n",
            "[2024-10-23 16:02:29 I] Validation loop at step 43000:\n",
            "[2024-10-23 16:02:29 I]     loss = 0.006614123636484145\n",
            "[2024-10-23 16:02:29 I]     mse = 0.006614123636484145\n",
            "[2024-10-23 16:02:29 I]     rmse = 0.0806661159820884\n",
            "[2024-10-23 16:02:29 I]     output_reg = 0.0\n",
            "[2024-10-23 16:02:29 I]     mae = 0.044393461048603075\n",
            "Training epochs:  88% 2750/3125 [19:42<02:21,  2.65it/s][2024-10-23 16:02:54 I] Starting validation at step 44000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 123.70it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 114.67it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 115.90it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 114.97it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 115.87it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.70it/s]\n",
            "[2024-10-23 16:02:55 I] Validation loop at step 44000:\n",
            "[2024-10-23 16:02:55 I]     loss = 0.006679316726326944\n",
            "[2024-10-23 16:02:55 I]     mse = 0.006679316726326944\n",
            "[2024-10-23 16:02:55 I]     rmse = 0.08107262489926136\n",
            "[2024-10-23 16:02:55 I]     output_reg = 0.0\n",
            "[2024-10-23 16:02:55 I]     mae = 0.04467236127853395\n",
            "Training epochs:  90% 2812/3125 [20:08<02:00,  2.61it/s][2024-10-23 16:03:21 I] Starting validation at step 45000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 124.48it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 122.73it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 121.26it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:00<00:00, 117.52it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 115.55it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 113.45it/s]\n",
            "[2024-10-23 16:03:22 I] Validation loop at step 45000:\n",
            "[2024-10-23 16:03:22 I]     loss = 0.006707717856764792\n",
            "[2024-10-23 16:03:22 I]     mse = 0.006707717856764792\n",
            "[2024-10-23 16:03:22 I]     rmse = 0.08124946316986828\n",
            "[2024-10-23 16:03:22 I]     output_reg = 0.0\n",
            "[2024-10-23 16:03:22 I]     mae = 0.04474701154232025\n",
            "Training epochs:  92% 2875/3125 [20:35<01:34,  2.64it/s][2024-10-23 16:03:48 I] Starting validation at step 46000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 116.21it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 116.26it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 114.31it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 108.53it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 110.05it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 112.64it/s]\n",
            "[2024-10-23 16:03:48 I] Validation loop at step 46000:\n",
            "[2024-10-23 16:03:48 I]     loss = 0.0067756478786468516\n",
            "[2024-10-23 16:03:48 I]     mse = 0.0067756478786468516\n",
            "[2024-10-23 16:03:48 I]     rmse = 0.08166605391173642\n",
            "[2024-10-23 16:03:48 I]     output_reg = 0.0\n",
            "[2024-10-23 16:03:48 I]     mae = 0.04498826999664308\n",
            "Training epochs:  94% 2937/3125 [21:02<01:14,  2.51it/s][2024-10-23 16:04:14 I] Starting validation at step 47000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  11% 9/79 [00:00<00:00, 87.68it/s]\u001b[A\n",
            "Evaluating:  24% 19/79 [00:00<00:00, 89.01it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:00<00:00, 87.67it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 89.77it/s]\u001b[A\n",
            "Evaluating:  59% 47/79 [00:00<00:00, 88.96it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:00<00:00, 85.65it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:00<00:00, 85.47it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 84.73it/s]\n",
            "[2024-10-23 16:04:15 I] Validation loop at step 47000:\n",
            "[2024-10-23 16:04:15 I]     loss = 0.006807866068184377\n",
            "[2024-10-23 16:04:15 I]     mse = 0.006807866068184377\n",
            "[2024-10-23 16:04:15 I]     rmse = 0.08186637560760913\n",
            "[2024-10-23 16:04:15 I]     output_reg = 0.0\n",
            "[2024-10-23 16:04:15 I]     mae = 0.045147320890426654\n",
            "Training epochs:  96% 3000/3125 [21:29<01:00,  2.06it/s][2024-10-23 16:04:42 I] Starting validation at step 48000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   9% 7/79 [00:00<00:01, 66.05it/s]\u001b[A\n",
            "Evaluating:  19% 15/79 [00:00<00:00, 72.31it/s]\u001b[A\n",
            "Evaluating:  34% 27/79 [00:00<00:00, 92.99it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 103.29it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:00<00:00, 108.02it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 112.92it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 105.71it/s]\n",
            "[2024-10-23 16:04:42 I] Validation loop at step 48000:\n",
            "[2024-10-23 16:04:42 I]     loss = 0.006869435939192773\n",
            "[2024-10-23 16:04:42 I]     mse = 0.006869435939192773\n",
            "[2024-10-23 16:04:42 I]     rmse = 0.08223952139827016\n",
            "[2024-10-23 16:04:42 I]     output_reg = 0.0\n",
            "[2024-10-23 16:04:42 I]     mae = 0.0453703266620636\n",
            "Training epochs:  98% 3062/3125 [21:56<00:27,  2.28it/s][2024-10-23 16:05:08 I] Starting validation at step 49000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 111.41it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 118.33it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 115.71it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 113.46it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 116.16it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.40it/s]\n",
            "[2024-10-23 16:05:09 I] Validation loop at step 49000:\n",
            "[2024-10-23 16:05:09 I]     loss = 0.006892750380933285\n",
            "[2024-10-23 16:05:09 I]     mse = 0.006892750380933285\n",
            "[2024-10-23 16:05:09 I]     rmse = 0.08238244547109567\n",
            "[2024-10-23 16:05:09 I]     output_reg = 0.0\n",
            "[2024-10-23 16:05:09 I]     mae = 0.04542364940643311\n",
            "Training epochs: 100% 3125/3125 [22:23<00:00,  2.33it/s]\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.83it/s]\n",
            "[2024-10-23 16:05:35 I] Validation loop at step 50000:\n",
            "[2024-10-23 16:05:35 I]     loss = 0.006923348778486253\n",
            "[2024-10-23 16:05:35 I]     mse = 0.006923348778486253\n",
            "[2024-10-23 16:05:35 I]     rmse = 0.08256634359743457\n",
            "[2024-10-23 16:05:35 I]     output_reg = 0.0\n",
            "[2024-10-23 16:05:35 I]     mae = 0.04554709534645082\n",
            "[2024-10-23 16:05:35 I] Early stopping after step 10000 with validation loss 0.004796282504498959\n",
            "[2024-10-23 16:05:35 I] Saving model at $/content/nbody_data/experiments/nbody/transformer_50000/models/model_final.pt\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 112.55it/s]\n",
            "[2024-10-23 16:05:36 I] Ran evaluation on dataset object_generalization:\n",
            "[2024-10-23 16:05:36 I]     loss = 0.009792486090213059\n",
            "[2024-10-23 16:05:36 I]     mse = 0.009792486090213059\n",
            "[2024-10-23 16:05:36 I]     rmse = 0.09820541984169263\n",
            "[2024-10-23 16:05:36 I]     output_reg = 0.0\n",
            "[2024-10-23 16:05:36 I]     mae = 0.054643529644608495\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.32it/s]\n",
            "[2024-10-23 16:05:37 I] Ran evaluation on dataset eval:\n",
            "[2024-10-23 16:05:37 I]     loss = 0.0071281964018940925\n",
            "[2024-10-23 16:05:37 I]     mse = 0.0071281964018940925\n",
            "[2024-10-23 16:05:37 I]     rmse = 0.083536898891767\n",
            "[2024-10-23 16:05:37 I]     output_reg = 0.0\n",
            "[2024-10-23 16:05:37 I]     mae = 0.04577494590282441\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.86it/s]\n",
            "[2024-10-23 16:05:38 I] Ran evaluation on dataset e3_generalization:\n",
            "[2024-10-23 16:05:38 I]     loss = 16.37430008239746\n",
            "[2024-10-23 16:05:38 I]     mse = 16.37430008239746\n",
            "[2024-10-23 16:05:38 I]     rmse = 4.044431091517092\n",
            "[2024-10-23 16:05:38 I]     output_reg = 0.0\n",
            "[2024-10-23 16:05:38 I]     mae = 2.9885512718200675\n",
            "[2024-10-23 16:05:38 I] Anders nog iets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 100 training samples"
      ],
      "metadata": {
        "id": "fp0abgg7OwcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GATr"
      ],
      "metadata": {
        "id": "XaLLIMY8O7Tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=gatr_nbody data.subsample=0.001 training.steps=5000 run_name=gatr100_5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfebbf10-413b-4989-d063-53afbd17e169",
        "id": "Qr7_mOgXO7Tc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 16:54:41 I] Hoi.\n",
            "[2024-10-23 16:54:41 I] Set experiment nbody with ID 1, artifact location file:/content/geometric-algebra-transformer/$/content/nbody_data/tracking/artifacts\n",
            "[2024-10-23 16:54:41 I] Logger already initialized - hi again!\n",
            "[2024-10-23 16:54:41 I] Running experiment at $/content/nbody_data/experiments/nbody/gatr100_5000\n",
            "[2024-10-23 16:54:41 I] Saving config at $/content/nbody_data/experiments/nbody/gatr100_5000/config.yml\n",
            "[2024-10-23 16:54:42 I] Model has 2.21M learnable parameters\n",
            "[2024-10-23 16:54:42 I] Starting training\n",
            "[2024-10-23 16:54:42 I] Training for 5000 steps, that is, 2500 epochs on a dataset of size 100 with batchsize 64\n",
            "Training epochs:   0% 0/2500 [00:00<?, ?it/s]/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 16:54:44 I] Finished first forward pass with loss 0.05588771402835846\n",
            "Training epochs:  20% 500/2500 [03:50<13:57,  2.39it/s][2024-10-23 16:58:33 I] Starting validation at step 1000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:07, 10.70it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:06, 12.02it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 12.43it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.51it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.58it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.56it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 11.11it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:06,  9.92it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:06,  9.75it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:06,  9.71it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:02<00:05,  9.80it/s]\u001b[A\n",
            "Evaluating:  29% 23/79 [00:02<00:05,  9.70it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:02<00:05,  9.39it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:02<00:06,  8.90it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:06,  8.83it/s]\u001b[A\n",
            "Evaluating:  34% 27/79 [00:02<00:06,  8.56it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:06,  8.46it/s]\u001b[A\n",
            "Evaluating:  37% 29/79 [00:02<00:05,  8.43it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:03<00:05,  8.42it/s]\u001b[A\n",
            "Evaluating:  39% 31/79 [00:03<00:05,  8.39it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:03<00:05,  8.10it/s]\u001b[A\n",
            "Evaluating:  42% 33/79 [00:03<00:05,  8.11it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:03<00:05,  8.32it/s]\u001b[A\n",
            "Evaluating:  44% 35/79 [00:03<00:05,  8.21it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:03<00:05,  8.34it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:04,  9.87it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:04<00:03, 10.67it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:04<00:03, 11.30it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:04<00:03, 11.34it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:04<00:02, 11.69it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:04<00:02, 11.96it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 12.16it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:05<00:02, 12.13it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:05<00:02, 12.28it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:05<00:01, 12.05it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:05<00:01, 12.10it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:05<00:01, 12.24it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01, 12.35it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:06<00:01, 12.27it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:06<00:01, 12.22it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:06<00:00, 11.96it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:06<00:00, 11.98it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:06<00:00, 12.12it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00, 12.23it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:07<00:00, 12.24it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 10.87it/s]\n",
            "[2024-10-23 16:58:41 I] Validation loop at step 1000:\n",
            "[2024-10-23 16:58:41 I]     loss = 0.0007287400824017823\n",
            "[2024-10-23 16:58:41 I]     mse = 0.0007160871655680242\n",
            "[2024-10-23 16:58:41 I]     rmse = 0.023540627645119463\n",
            "[2024-10-23 16:58:41 I]     output_reg = 0.0012652919251471759\n",
            "[2024-10-23 16:58:41 I]     mae = 0.008626843708753586\n",
            "Training epochs:  40% 1000/2500 [07:46<10:43,  2.33it/s][2024-10-23 17:02:29 I] Starting validation at step 2000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:05, 13.40it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:05, 12.86it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 12.56it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.52it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.53it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.53it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.61it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 12.58it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.39it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.47it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.56it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 12.48it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.59it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 12.34it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:04, 12.14it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:03, 12.30it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 12.43it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:02<00:03, 12.44it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 12.50it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 12.54it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:02, 12.51it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:02, 12.30it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:03<00:02, 12.38it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:03<00:02, 12.31it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 10.60it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 10.14it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:02,  9.88it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:04<00:02,  9.83it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:04<00:02,  9.85it/s]\u001b[A\n",
            "Evaluating:  75% 59/79 [00:05<00:02,  9.60it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:05<00:02,  9.19it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:05<00:01,  9.16it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01,  8.71it/s]\u001b[A\n",
            "Evaluating:  80% 63/79 [00:05<00:01,  8.37it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01,  8.06it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:05<00:01,  8.04it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:05<00:01,  8.24it/s]\u001b[A\n",
            "Evaluating:  85% 67/79 [00:06<00:01,  8.27it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:06<00:01,  8.33it/s]\u001b[A\n",
            "Evaluating:  87% 69/79 [00:06<00:01,  8.17it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:06<00:01,  8.22it/s]\u001b[A\n",
            "Evaluating:  90% 71/79 [00:06<00:00,  8.02it/s]\u001b[A\n",
            "Evaluating:  92% 73/79 [00:06<00:00,  9.39it/s]\u001b[A\n",
            "Evaluating:  95% 75/79 [00:06<00:00, 10.36it/s]\u001b[A\n",
            "Evaluating:  97% 77/79 [00:07<00:00, 11.00it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 10.96it/s]\n",
            "[2024-10-23 17:02:36 I] Validation loop at step 2000:\n",
            "[2024-10-23 17:02:36 I]     loss = 0.0010409170005470515\n",
            "[2024-10-23 17:02:36 I]     mse = 0.0010321953143924477\n",
            "[2024-10-23 17:02:36 I]     rmse = 0.02850963285532828\n",
            "[2024-10-23 17:02:36 I]     output_reg = 0.0008721690813079475\n",
            "[2024-10-23 17:02:36 I]     mae = 0.008979060862958434\n",
            "Training epochs:  60% 1500/2500 [11:43<07:24,  2.25it/s][2024-10-23 17:06:26 I] Starting validation at step 3000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:05, 12.86it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:05, 12.77it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 12.72it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.78it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.65it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.42it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.34it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 12.31it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.44it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.51it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.66it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 12.32it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.39it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 12.26it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:03, 12.32it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:03, 12.41it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 12.48it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:02<00:03, 12.24it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 12.41it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 12.31it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:02, 12.41it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:02, 12.27it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:03<00:02, 11.94it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:03<00:02, 11.77it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 11.85it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 11.90it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:02, 12.02it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:04<00:01, 12.11it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:04<00:01, 12.25it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:04<00:01, 12.32it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01, 12.10it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01, 12.05it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:05<00:01, 12.15it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:05<00:00, 12.25it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:05<00:00, 12.34it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:05<00:00, 12.39it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00, 12.12it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:06<00:00, 12.03it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 12.27it/s]\n",
            "[2024-10-23 17:06:32 I] Validation loop at step 3000:\n",
            "[2024-10-23 17:06:32 I]     loss = 0.0015903299013152717\n",
            "[2024-10-23 17:06:32 I]     mse = 0.0015830778857693075\n",
            "[2024-10-23 17:06:32 I]     rmse = 0.03677173225707441\n",
            "[2024-10-23 17:06:32 I]     output_reg = 0.000725201812013984\n",
            "[2024-10-23 17:06:32 I]     mae = 0.010672256444394589\n",
            "Training epochs:  80% 2000/2500 [15:39<04:37,  1.80it/s][2024-10-23 17:10:22 I] Starting validation at step 4000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   1% 1/79 [00:00<00:09,  8.23it/s]\u001b[A\n",
            "Evaluating:   4% 3/79 [00:00<00:07, 10.33it/s]\u001b[A\n",
            "Evaluating:   6% 5/79 [00:00<00:06, 11.55it/s]\u001b[A\n",
            "Evaluating:   9% 7/79 [00:00<00:06, 11.68it/s]\u001b[A\n",
            "Evaluating:  11% 9/79 [00:00<00:05, 12.20it/s]\u001b[A\n",
            "Evaluating:  14% 11/79 [00:00<00:05, 12.39it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:01<00:05, 12.56it/s]\u001b[A\n",
            "Evaluating:  19% 15/79 [00:01<00:05, 12.62it/s]\u001b[A\n",
            "Evaluating:  22% 17/79 [00:01<00:04, 12.77it/s]\u001b[A\n",
            "Evaluating:  24% 19/79 [00:01<00:04, 12.69it/s]\u001b[A\n",
            "Evaluating:  27% 21/79 [00:01<00:04, 12.40it/s]\u001b[A\n",
            "Evaluating:  29% 23/79 [00:01<00:04, 12.37it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:02<00:04, 12.54it/s]\u001b[A\n",
            "Evaluating:  34% 27/79 [00:02<00:04, 12.56it/s]\u001b[A\n",
            "Evaluating:  37% 29/79 [00:02<00:03, 12.66it/s]\u001b[A\n",
            "Evaluating:  39% 31/79 [00:02<00:03, 12.65it/s]\u001b[A\n",
            "Evaluating:  42% 33/79 [00:02<00:03, 12.37it/s]\u001b[A\n",
            "Evaluating:  44% 35/79 [00:02<00:03, 12.48it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:02<00:03, 12.50it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:03<00:03, 12.42it/s]\u001b[A\n",
            "Evaluating:  52% 41/79 [00:03<00:03, 12.48it/s]\u001b[A\n",
            "Evaluating:  54% 43/79 [00:03<00:02, 12.52it/s]\u001b[A\n",
            "Evaluating:  57% 45/79 [00:03<00:02, 12.38it/s]\u001b[A\n",
            "Evaluating:  59% 47/79 [00:03<00:02, 12.46it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:03<00:02, 12.49it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:04<00:02, 12.43it/s]\u001b[A\n",
            "Evaluating:  67% 53/79 [00:04<00:02, 12.42it/s]\u001b[A\n",
            "Evaluating:  70% 55/79 [00:04<00:01, 12.42it/s]\u001b[A\n",
            "Evaluating:  72% 57/79 [00:04<00:01, 11.73it/s]\u001b[A\n",
            "Evaluating:  75% 59/79 [00:04<00:01, 11.62it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:04<00:01, 11.81it/s]\u001b[A\n",
            "Evaluating:  80% 63/79 [00:05<00:01, 11.98it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:05<00:01, 12.14it/s]\u001b[A\n",
            "Evaluating:  85% 67/79 [00:05<00:00, 12.23it/s]\u001b[A\n",
            "Evaluating:  87% 69/79 [00:05<00:00, 12.34it/s]\u001b[A\n",
            "Evaluating:  90% 71/79 [00:05<00:00, 12.14it/s]\u001b[A\n",
            "Evaluating:  92% 73/79 [00:05<00:00, 12.22it/s]\u001b[A\n",
            "Evaluating:  95% 75/79 [00:06<00:00, 12.15it/s]\u001b[A\n",
            "Evaluating:  97% 77/79 [00:06<00:00, 12.26it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 12.27it/s]\n",
            "[2024-10-23 17:10:28 I] Validation loop at step 4000:\n",
            "[2024-10-23 17:10:28 I]     loss = 0.0011577507826499643\n",
            "[2024-10-23 17:10:28 I]     mse = 0.001151976206805557\n",
            "[2024-10-23 17:10:28 I]     rmse = 0.03117139873038078\n",
            "[2024-10-23 17:10:28 I]     output_reg = 0.0005774574036709963\n",
            "[2024-10-23 17:10:28 I]     mae = 0.009872818279266357\n",
            "Training epochs: 100% 2500/2500 [19:35<00:00,  2.13it/s]\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 11.03it/s]\n",
            "[2024-10-23 17:14:24 I] Validation loop at step 5000:\n",
            "[2024-10-23 17:14:24 I]     loss = 0.0010929010182619099\n",
            "[2024-10-23 17:14:24 I]     mse = 0.0010881146359257399\n",
            "[2024-10-23 17:14:24 I]     rmse = 0.030093639651007042\n",
            "[2024-10-23 17:14:24 I]     output_reg = 0.00047863854682072984\n",
            "[2024-10-23 17:14:24 I]     mae = 0.009478920307755474\n",
            "[2024-10-23 17:14:24 I] Early stopping after step 1000 with validation loss 0.0007287400824017823\n",
            "[2024-10-23 17:14:25 I] Saving model at $/content/nbody_data/experiments/nbody/gatr100_5000/models/model_final.pt\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 12.16it/s]\n",
            "[2024-10-23 17:14:31 I] Ran evaluation on dataset object_generalization:\n",
            "[2024-10-23 17:14:31 I]     loss = 0.0015935990514233717\n",
            "[2024-10-23 17:14:31 I]     mse = 0.0015807522150687882\n",
            "[2024-10-23 17:14:31 I]     rmse = 0.03646775116168792\n",
            "[2024-10-23 17:14:31 I]     output_reg = 0.0012846839960664515\n",
            "[2024-10-23 17:14:31 I]     mae = 0.013195218151807792\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 10.90it/s]\n",
            "[2024-10-23 17:14:38 I] Ran evaluation on dataset eval:\n",
            "[2024-10-23 17:14:38 I]     loss = 0.0012818447092198765\n",
            "[2024-10-23 17:14:38 I]     mse = 0.0012771263770177035\n",
            "[2024-10-23 17:14:38 I]     rmse = 0.031643583185997526\n",
            "[2024-10-23 17:14:38 I]     output_reg = 0.0004718335391022264\n",
            "[2024-10-23 17:14:38 I]     mae = 0.00949856353625655\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 12.36it/s]\n",
            "[2024-10-23 17:14:45 I] Ran evaluation on dataset e3_generalization:\n",
            "[2024-10-23 17:14:45 I]     loss = 0.001117236917279661\n",
            "[2024-10-23 17:14:45 I]     mse = 0.0011124380625085906\n",
            "[2024-10-23 17:14:45 I]     rmse = 0.03036653051558827\n",
            "[2024-10-23 17:14:45 I]     output_reg = 0.00047988498019985865\n",
            "[2024-10-23 17:14:45 I]     mae = 0.009643781894445423\n",
            "[2024-10-23 17:14:45 I] Anders nog iets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=gatr_nbody data.subsample=0.001 training.steps=10000 run_name=gatr100_10000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b5afd6-3878-4f15-92d8-2f74d6fe9db9",
        "id": "yp7S0EvfO7Tc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 18:12:34 I] Hoi.\n",
            "[2024-10-23 18:12:35 I] Set experiment nbody with ID 1, artifact location file:/content/geometric-algebra-transformer/$/content/nbody_data/tracking/artifacts\n",
            "[2024-10-23 18:12:35 I] Logger already initialized - hi again!\n",
            "[2024-10-23 18:12:35 I] Running experiment at $/content/nbody_data/experiments/nbody/gatr100_10000\n",
            "[2024-10-23 18:12:35 I] Saving config at $/content/nbody_data/experiments/nbody/gatr100_10000/config.yml\n",
            "[2024-10-23 18:12:36 I] Model has 2.21M learnable parameters\n",
            "[2024-10-23 18:12:36 I] Starting training\n",
            "[2024-10-23 18:12:36 I] Training for 10000 steps, that is, 5000 epochs on a dataset of size 100 with batchsize 64\n",
            "Training epochs:   0% 0/5000 [00:00<?, ?it/s]/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 18:12:38 I] Finished first forward pass with loss 0.05588771402835846\n",
            "Training epochs:  10% 500/5000 [04:02<33:23,  2.25it/s][2024-10-23 18:16:38 I] Starting validation at step 1000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:07, 10.80it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:06, 11.49it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:06, 11.84it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.12it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 11.99it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:01<00:05, 12.19it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.25it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 12.24it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.41it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.18it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.21it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 11.94it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.07it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 12.08it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:04, 12.06it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:03, 11.98it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 12.16it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:02<00:03, 11.96it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 11.86it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 11.83it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:03, 11.11it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:03,  9.89it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:04<00:03,  9.51it/s]\u001b[A\n",
            "Evaluating:  59% 47/79 [00:04<00:03,  9.54it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:04<00:03,  9.41it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:04<00:03,  9.46it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:03,  9.56it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:04<00:02,  9.47it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02,  9.33it/s]\u001b[A\n",
            "Evaluating:  67% 53/79 [00:04<00:02,  8.70it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:02,  8.39it/s]\u001b[A\n",
            "Evaluating:  70% 55/79 [00:05<00:03,  7.93it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:05<00:02,  7.85it/s]\u001b[A\n",
            "Evaluating:  72% 57/79 [00:05<00:02,  7.79it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:05<00:02,  7.57it/s]\u001b[A\n",
            "Evaluating:  75% 59/79 [00:05<00:02,  6.86it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:05<00:02,  6.93it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:05<00:02,  7.08it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:06<00:02,  7.02it/s]\u001b[A\n",
            "Evaluating:  80% 63/79 [00:06<00:02,  7.10it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:06<00:02,  7.39it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:06<00:01,  7.44it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:06<00:01,  7.65it/s]\u001b[A\n",
            "Evaluating:  85% 67/79 [00:06<00:01,  7.90it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:06<00:01,  7.76it/s]\u001b[A\n",
            "Evaluating:  87% 69/79 [00:06<00:01,  7.66it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:07<00:01,  6.76it/s]\u001b[A\n",
            "Evaluating:  90% 71/79 [00:07<00:01,  6.66it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:07<00:00,  7.15it/s]\u001b[A\n",
            "Evaluating:  92% 73/79 [00:07<00:00,  7.54it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:07<00:00,  7.73it/s]\u001b[A\n",
            "Evaluating:  95% 75/79 [00:07<00:00,  7.45it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:07<00:00,  7.74it/s]\u001b[A\n",
            "Evaluating:  97% 77/79 [00:08<00:00,  7.64it/s]\u001b[A\n",
            "Evaluating:  99% 78/79 [00:08<00:00,  7.81it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:08<00:00,  9.49it/s]\n",
            "[2024-10-23 18:16:47 I] Validation loop at step 1000:\n",
            "[2024-10-23 18:16:47 I]     loss = 0.0007287400824017823\n",
            "[2024-10-23 18:16:47 I]     mse = 0.0007160871655680242\n",
            "[2024-10-23 18:16:47 I]     rmse = 0.023540627645119463\n",
            "[2024-10-23 18:16:47 I]     output_reg = 0.0012652919251471759\n",
            "[2024-10-23 18:16:47 I]     mae = 0.008626843708753586\n",
            "Training epochs:  20% 1000/5000 [08:11<29:57,  2.22it/s][2024-10-23 18:20:48 I] Starting validation at step 2000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:05, 13.12it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:06, 12.35it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 12.35it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.22it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.33it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.19it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.26it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 12.11it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.30it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.42it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.14it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 12.19it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.02it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 11.88it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:04, 11.62it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:04, 11.67it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 11.97it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:02<00:03, 12.19it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 12.01it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 11.99it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:03, 11.83it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:02, 11.68it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:03<00:02, 11.78it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:03<00:02, 11.81it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 11.80it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 10.98it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:02,  9.97it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:04<00:02,  9.67it/s]\u001b[A\n",
            "Evaluating:  72% 57/79 [00:04<00:02,  9.61it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:05<00:02,  9.51it/s]\u001b[A\n",
            "Evaluating:  75% 59/79 [00:05<00:02,  9.50it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:05<00:01,  9.50it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:05<00:01,  9.51it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01,  9.04it/s]\u001b[A\n",
            "Evaluating:  80% 63/79 [00:05<00:01,  8.65it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01,  8.47it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:05<00:01,  8.25it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:06<00:01,  8.20it/s]\u001b[A\n",
            "Evaluating:  85% 67/79 [00:06<00:01,  7.62it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:06<00:01,  7.86it/s]\u001b[A\n",
            "Evaluating:  87% 69/79 [00:06<00:01,  8.00it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:06<00:01,  7.99it/s]\u001b[A\n",
            "Evaluating:  90% 71/79 [00:06<00:00,  8.21it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:06<00:00,  8.26it/s]\u001b[A\n",
            "Evaluating:  92% 73/79 [00:06<00:00,  8.37it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00,  8.36it/s]\u001b[A\n",
            "Evaluating:  95% 75/79 [00:07<00:00,  8.05it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:07<00:00,  7.91it/s]\u001b[A\n",
            "Evaluating:  97% 77/79 [00:07<00:00,  7.70it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 10.41it/s]\n",
            "[2024-10-23 18:20:55 I] Validation loop at step 2000:\n",
            "[2024-10-23 18:20:55 I]     loss = 0.0010463797120377422\n",
            "[2024-10-23 18:20:55 I]     mse = 0.001040442806761712\n",
            "[2024-10-23 18:20:55 I]     rmse = 0.029114353916952863\n",
            "[2024-10-23 18:20:55 I]     output_reg = 0.0005936903474852445\n",
            "[2024-10-23 18:20:55 I]     mae = 0.00954661602973938\n",
            "Training epochs:  30% 1500/5000 [12:18<25:38,  2.28it/s][2024-10-23 18:24:54 I] Starting validation at step 3000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:06, 12.18it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:06, 11.65it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:06, 12.04it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.40it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.13it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.03it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.31it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 12.08it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:05, 12.18it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 11.98it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.08it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 11.84it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 11.93it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 11.56it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:04, 11.76it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:04, 10.12it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:04,  9.72it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:03<00:04,  9.48it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:03<00:04,  9.38it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:04,  9.24it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:03<00:04,  9.06it/s]\u001b[A\n",
            "Evaluating:  52% 41/79 [00:03<00:04,  9.00it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:04,  8.72it/s]\u001b[A\n",
            "Evaluating:  54% 43/79 [00:04<00:04,  8.77it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:04<00:04,  8.34it/s]\u001b[A\n",
            "Evaluating:  57% 45/79 [00:04<00:04,  8.04it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:04<00:04,  7.93it/s]\u001b[A\n",
            "Evaluating:  59% 47/79 [00:04<00:03,  8.05it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:04<00:03,  8.20it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:04<00:03,  8.31it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:03,  8.44it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:05<00:03,  8.51it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:05<00:03,  8.24it/s]\u001b[A\n",
            "Evaluating:  67% 53/79 [00:05<00:03,  7.92it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:05<00:03,  7.87it/s]\u001b[A\n",
            "Evaluating:  70% 55/79 [00:05<00:03,  7.58it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:05<00:03,  7.64it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:05<00:02,  9.01it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:06<00:01, 10.06it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:06<00:01, 10.58it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:06<00:01, 10.87it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:06<00:01, 10.87it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:06<00:00, 11.35it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:06<00:00, 11.22it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:07<00:00, 11.31it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:07<00:00, 11.08it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:07<00:00, 11.08it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 10.28it/s]\n",
            "[2024-10-23 18:25:02 I] Validation loop at step 3000:\n",
            "[2024-10-23 18:25:02 I]     loss = 0.0008452067707665264\n",
            "[2024-10-23 18:25:02 I]     mse = 0.0008153283976018431\n",
            "[2024-10-23 18:25:02 I]     rmse = 0.026200694336625946\n",
            "[2024-10-23 18:25:02 I]     output_reg = 0.0029878371357917786\n",
            "[2024-10-23 18:25:02 I]     mae = 0.010574542121589184\n",
            "Training epochs:  40% 2000/5000 [16:18<21:27,  2.33it/s][2024-10-23 18:28:55 I] Starting validation at step 4000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:05, 13.65it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:05, 13.40it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 13.22it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.78it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 13.00it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.59it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.72it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:04, 12.73it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.63it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.21it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.19it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 12.23it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.39it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 12.48it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:03, 12.58it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:03, 12.06it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 12.17it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:02<00:03, 12.25it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 12.41it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 12.56it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:02, 12.70it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:02, 12.53it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:03<00:02, 12.27it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:03<00:02, 12.40it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:03<00:02, 12.50it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 12.56it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:01, 12.67it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:04<00:01, 12.44it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:04<00:01, 12.20it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:04<00:01, 12.24it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:04<00:01, 12.36it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01, 12.36it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:05<00:01, 12.45it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:05<00:00, 11.16it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:05<00:00, 10.11it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:05<00:00,  9.91it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00,  9.73it/s]\u001b[A\n",
            "Evaluating:  95% 75/79 [00:06<00:00,  9.73it/s]\u001b[A\n",
            "Evaluating:  97% 77/79 [00:06<00:00,  9.72it/s]\u001b[A\n",
            "Evaluating:  99% 78/79 [00:06<00:00,  9.23it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 11.70it/s]\n",
            "[2024-10-23 18:29:02 I] Validation loop at step 4000:\n",
            "[2024-10-23 18:29:02 I]     loss = 0.0009771431798115376\n",
            "[2024-10-23 18:29:02 I]     mse = 0.0009717590459622445\n",
            "[2024-10-23 18:29:02 I]     rmse = 0.028049624478024046\n",
            "[2024-10-23 18:29:02 I]     output_reg = 0.0005384133392944928\n",
            "[2024-10-23 18:29:02 I]     mae = 0.008210133287310604\n",
            "Training epochs:  50% 2500/5000 [20:15<18:12,  2.29it/s][2024-10-23 18:32:52 I] Starting validation at step 5000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:05, 13.28it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:05, 12.77it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 12.95it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.73it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.64it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.51it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.64it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:04, 12.71it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.80it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.86it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.48it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 12.39it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.49it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 12.57it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:03, 12.64it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:03, 12.68it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 12.50it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:02<00:03, 12.42it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 12.43it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 12.49it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:02, 12.46it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:02, 12.53it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:03<00:02, 12.64it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:03<00:02, 12.28it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:03<00:02, 12.42it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 12.48it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:01, 12.59it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:04<00:01, 12.53it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:04<00:01, 12.54it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:04<00:01, 12.16it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:04<00:01, 12.06it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01, 12.12it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:05<00:01, 12.24it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:05<00:00, 12.25it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:05<00:00, 12.33it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:05<00:00, 12.10it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:05<00:00, 12.16it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:06<00:00, 12.25it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 12.46it/s]\n",
            "[2024-10-23 18:32:58 I] Validation loop at step 5000:\n",
            "[2024-10-23 18:32:58 I]     loss = 0.0010371324115432798\n",
            "[2024-10-23 18:32:58 I]     mse = 0.0010338410508818924\n",
            "[2024-10-23 18:32:58 I]     rmse = 0.028880059474350205\n",
            "[2024-10-23 18:32:58 I]     output_reg = 0.0003291361004579811\n",
            "[2024-10-23 18:32:58 I]     mae = 0.00788830390870571\n",
            "Training epochs:  60% 3000/5000 [24:11<15:54,  2.10it/s][2024-10-23 18:36:47 I] Starting validation at step 6000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:05, 13.53it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:05, 13.05it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 13.00it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.99it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.70it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.74it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.78it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:04, 12.71it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.64it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.70it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.79it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 12.52it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.65it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 12.60it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:03, 12.65it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:03, 12.21it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 12.31it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:02<00:03, 12.15it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 12.26it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 12.35it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:03, 12.05it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:02, 12.18it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:03<00:02, 12.37it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:03<00:02, 12.22it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:03<00:02, 12.39it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 12.29it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:02, 12.23it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:04<00:01, 12.29it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:04<00:01, 12.26it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:04<00:01, 12.15it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:04<00:01, 12.34it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01, 12.25it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:05<00:01, 12.16it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:05<00:00, 11.99it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:05<00:00, 12.17it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:05<00:00, 12.28it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:05<00:00, 12.18it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:06<00:00, 12.36it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 12.41it/s]\n",
            "[2024-10-23 18:36:54 I] Validation loop at step 6000:\n",
            "[2024-10-23 18:36:54 I]     loss = 0.001045775447692722\n",
            "[2024-10-23 18:36:54 I]     mse = 0.0010429849507287143\n",
            "[2024-10-23 18:36:54 I]     rmse = 0.028997782045973024\n",
            "[2024-10-23 18:36:54 I]     output_reg = 0.00027904931162484\n",
            "[2024-10-23 18:36:54 I]     mae = 0.00786020998954773\n",
            "Training epochs:  70% 3500/5000 [28:09<13:12,  1.89it/s][2024-10-23 18:40:46 I] Starting validation at step 7000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:06, 12.58it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:05, 12.70it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 12.91it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.60it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.54it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 11.90it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.00it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 12.14it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:04, 12.21it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:04, 12.30it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:04, 12.50it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:01<00:04, 12.17it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 12.12it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:04, 12.04it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:03, 12.27it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:02<00:03, 12.33it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:02<00:03, 12.53it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:02<00:03, 12.28it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 12.26it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 12.37it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:03<00:02, 12.53it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:03<00:02, 12.56it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:03<00:02, 12.66it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:03<00:02, 11.83it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 11.83it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 12.02it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:04<00:02, 12.21it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:04<00:01, 12.30it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:04<00:01, 12.47it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:04<00:01, 12.46it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01, 12.09it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01, 12.20it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:05<00:01, 12.38it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:05<00:00, 12.41it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:05<00:00, 12.55it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:05<00:00, 12.48it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00, 12.32it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:06<00:00, 12.30it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 12.31it/s]\n",
            "[2024-10-23 18:40:52 I] Validation loop at step 7000:\n",
            "[2024-10-23 18:40:52 I]     loss = 0.0010344157664105298\n",
            "[2024-10-23 18:40:52 I]     mse = 0.0010318272678181528\n",
            "[2024-10-23 18:40:52 I]     rmse = 0.028841044754637293\n",
            "[2024-10-23 18:40:52 I]     output_reg = 0.00025884987059980635\n",
            "[2024-10-23 18:40:52 I]     mae = 0.007789828324317932\n",
            "Training epochs:  80% 4000/5000 [32:06<07:04,  2.36it/s][2024-10-23 18:44:43 I] Starting validation at step 8000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:08,  9.38it/s]\u001b[A\n",
            "Evaluating:   4% 3/79 [00:00<00:08,  9.36it/s]\u001b[A\n",
            "Evaluating:   6% 5/79 [00:00<00:07,  9.76it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:07,  9.53it/s]\u001b[A\n",
            "Evaluating:   9% 7/79 [00:00<00:07,  9.24it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:07,  9.18it/s]\u001b[A\n",
            "Evaluating:  11% 9/79 [00:00<00:08,  8.53it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:01<00:08,  8.47it/s]\u001b[A\n",
            "Evaluating:  14% 11/79 [00:01<00:08,  8.16it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:01<00:08,  8.31it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:01<00:07,  8.42it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:07,  8.58it/s]\u001b[A\n",
            "Evaluating:  19% 15/79 [00:01<00:07,  8.66it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:07,  8.77it/s]\u001b[A\n",
            "Evaluating:  22% 17/79 [00:01<00:07,  8.85it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:02<00:07,  8.70it/s]\u001b[A\n",
            "Evaluating:  24% 19/79 [00:02<00:07,  8.13it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:02<00:07,  7.78it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:02<00:06,  9.00it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:02<00:05,  9.90it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:04, 10.74it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:03<00:04, 11.10it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:03<00:04, 11.48it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:03<00:03, 11.83it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:03<00:03, 12.12it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:03<00:03, 12.28it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:03, 12.45it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 12.42it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:04<00:03, 12.17it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:04<00:02, 12.24it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:04<00:02, 11.81it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:04<00:02, 11.93it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 12.19it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 12.30it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:05<00:02, 12.18it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:05<00:01, 12.36it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:05<00:01, 12.46it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:05<00:01, 12.48it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01, 12.41it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01, 12.28it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:06<00:01, 12.08it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:06<00:00, 12.15it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:06<00:00, 12.25it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:06<00:00, 12.28it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00, 12.41it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:06<00:00, 12.39it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 11.04it/s]\n",
            "[2024-10-23 18:44:50 I] Validation loop at step 8000:\n",
            "[2024-10-23 18:44:50 I]     loss = 0.0010231708997860548\n",
            "[2024-10-23 18:44:50 I]     mse = 0.0010207355128601192\n",
            "[2024-10-23 18:44:50 I]     rmse = 0.028690568956096126\n",
            "[2024-10-23 18:44:50 I]     output_reg = 0.00024353764420375232\n",
            "[2024-10-23 18:44:50 I]     mae = 0.007772917038202289\n",
            "Training epochs:  90% 4500/5000 [36:02<03:29,  2.38it/s][2024-10-23 18:48:38 I] Starting validation at step 9000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   3% 2/79 [00:00<00:05, 13.64it/s]\u001b[A\n",
            "Evaluating:   5% 4/79 [00:00<00:05, 13.02it/s]\u001b[A\n",
            "Evaluating:   8% 6/79 [00:00<00:05, 13.14it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:05, 12.86it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:05, 12.97it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:05, 12.68it/s]\u001b[A\n",
            "Evaluating:  18% 14/79 [00:01<00:05, 12.82it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:01<00:05, 10.89it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:01<00:05, 10.30it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:01<00:05, 10.04it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:01<00:05,  9.96it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:02<00:05,  9.96it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:02<00:05,  9.46it/s]\u001b[A\n",
            "Evaluating:  34% 27/79 [00:02<00:05,  9.12it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:02<00:05,  8.88it/s]\u001b[A\n",
            "Evaluating:  37% 29/79 [00:02<00:05,  8.81it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:02<00:05,  8.76it/s]\u001b[A\n",
            "Evaluating:  39% 31/79 [00:03<00:05,  8.48it/s]\u001b[A\n",
            "Evaluating:  41% 32/79 [00:03<00:05,  8.60it/s]\u001b[A\n",
            "Evaluating:  42% 33/79 [00:03<00:05,  8.64it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:03<00:05,  8.65it/s]\u001b[A\n",
            "Evaluating:  44% 35/79 [00:03<00:05,  8.57it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:03<00:05,  8.38it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:03<00:04,  9.66it/s]\u001b[A\n",
            "Evaluating:  51% 40/79 [00:03<00:03, 10.63it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:04<00:03, 11.12it/s]\u001b[A\n",
            "Evaluating:  56% 44/79 [00:04<00:03, 11.44it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:04<00:02, 11.89it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:04<00:02, 12.13it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:04<00:02, 12.34it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:04<00:02, 12.48it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:05<00:02, 12.37it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:05<00:01, 12.40it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:05<00:01, 12.38it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:05<00:01, 12.44it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:05<00:01, 12.53it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:05<00:01, 12.55it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:06<00:01, 12.44it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:06<00:00, 12.41it/s]\u001b[A\n",
            "Evaluating:  89% 70/79 [00:06<00:00, 12.35it/s]\u001b[A\n",
            "Evaluating:  91% 72/79 [00:06<00:00, 12.27it/s]\u001b[A\n",
            "Evaluating:  94% 74/79 [00:06<00:00, 12.40it/s]\u001b[A\n",
            "Evaluating:  96% 76/79 [00:06<00:00, 12.45it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 11.19it/s]\n",
            "[2024-10-23 18:48:45 I] Validation loop at step 9000:\n",
            "[2024-10-23 18:48:45 I]     loss = 0.0010334077413193883\n",
            "[2024-10-23 18:48:46 I]     mse = 0.0010310388199053706\n",
            "[2024-10-23 18:48:46 I]     rmse = 0.028907132163554082\n",
            "[2024-10-23 18:48:46 I]     output_reg = 0.00023689172526355834\n",
            "[2024-10-23 18:48:46 I]     mae = 0.007860121253132818\n",
            "Training epochs: 100% 5000/5000 [39:56<00:00,  2.09it/s]\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 11.03it/s]\n",
            "[2024-10-23 18:52:40 I] Validation loop at step 10000:\n",
            "[2024-10-23 18:52:40 I]     loss = 0.001026971218921244\n",
            "[2024-10-23 18:52:40 I]     mse = 0.0010246748410165309\n",
            "[2024-10-23 18:52:40 I]     rmse = 0.028837353931104828\n",
            "[2024-10-23 18:52:40 I]     output_reg = 0.00022963848039507864\n",
            "[2024-10-23 18:52:40 I]     mae = 0.007858484253287312\n",
            "[2024-10-23 18:52:40 I] Early stopping after step 1000 with validation loss 0.0007287400824017823\n",
            "[2024-10-23 18:52:40 I] Saving model at $/content/nbody_data/experiments/nbody/gatr100_10000/models/model_final.pt\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 12.37it/s]\n",
            "[2024-10-23 18:52:46 I] Ran evaluation on dataset eval:\n",
            "[2024-10-23 18:52:46 I]     loss = 0.001139143755414989\n",
            "[2024-10-23 18:52:46 I]     mse = 0.0011370235681009944\n",
            "[2024-10-23 18:52:46 I]     rmse = 0.029237604577747125\n",
            "[2024-10-23 18:52:46 I]     output_reg = 0.00021201906795031403\n",
            "[2024-10-23 18:52:46 I]     mae = 0.007806229482218623\n",
            "Evaluating: 100% 79/79 [00:07<00:00, 10.97it/s]\n",
            "[2024-10-23 18:52:54 I] Ran evaluation on dataset e3_generalization:\n",
            "[2024-10-23 18:52:54 I]     loss = 0.0009816338673816064\n",
            "[2024-10-23 18:52:54 I]     mse = 0.0009793961340328677\n",
            "[2024-10-23 18:52:54 I]     rmse = 0.02822901190306633\n",
            "[2024-10-23 18:52:54 I]     output_reg = 0.00022377368509769442\n",
            "[2024-10-23 18:52:54 I]     mae = 0.007860929577052594\n",
            "Evaluating: 100% 79/79 [00:06<00:00, 11.82it/s]\n",
            "[2024-10-23 18:53:00 I] Ran evaluation on dataset object_generalization:\n",
            "[2024-10-23 18:53:00 I]     loss = 0.0019738009524531666\n",
            "[2024-10-23 18:53:00 I]     mse = 0.001966404023952782\n",
            "[2024-10-23 18:53:00 I]     rmse = 0.04139920655515933\n",
            "[2024-10-23 18:53:00 I]     output_reg = 0.0007396928569301963\n",
            "[2024-10-23 18:53:00 I]     mae = 0.01362880729809404\n",
            "[2024-10-23 18:53:00 I] Anders nog iets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=gatr_nbody data.subsample=0.001 training.steps=50000 run_name=gatr100_50000"
      ],
      "metadata": {
        "id": "Gs7a-VIoPhqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP"
      ],
      "metadata": {
        "id": "76wquyA3O7Td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=mlp_nbody data.subsample=0.001 training.steps=5000 run_name=mlp100_5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c39d96-d911-4506-f775-9e02cd842ddd",
        "id": "dddgcCBuO7Td"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 17:15:53 I] Hoi.\n",
            "[2024-10-23 17:15:53 I] Set experiment nbody with ID 1, artifact location file:/content/geometric-algebra-transformer/$/content/nbody_data/tracking/artifacts\n",
            "[2024-10-23 17:15:53 I] Logger already initialized - hi again!\n",
            "[2024-10-23 17:15:53 I] Running experiment at $/content/nbody_data/experiments/nbody/mlp100_5000\n",
            "[2024-10-23 17:15:53 I] Saving config at $/content/nbody_data/experiments/nbody/mlp100_5000/config.yml\n",
            "[2024-10-23 17:15:54 I] Model has 0.16M learnable parameters\n",
            "[2024-10-23 17:15:54 I] Starting training\n",
            "[2024-10-23 17:15:54 I] Training for 5000 steps, that is, 2500 epochs on a dataset of size 100 with batchsize 64\n",
            "Training epochs:   0% 0/2500 [00:00<?, ?it/s][2024-10-23 17:15:55 I] Finished first forward pass with loss 359.9129333496094\n",
            "Training epochs:  20% 499/2500 [00:09<00:33, 58.92it/s][2024-10-23 17:16:04 I] Starting validation at step 1000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 858.08it/s]\n",
            "[2024-10-23 17:16:04 I] Validation loop at step 1000:\n",
            "[2024-10-23 17:16:04 I]     loss = 0.24362177646160127\n",
            "[2024-10-23 17:16:04 I]     mse = 0.24362177646160127\n",
            "[2024-10-23 17:16:04 I]     rmse = 0.4932428104726286\n",
            "[2024-10-23 17:16:04 I]     output_reg = 0.0\n",
            "[2024-10-23 17:16:04 I]     mae = 0.38475706896781925\n",
            "Training epochs:  40% 995/2500 [00:19<00:24, 60.76it/s][2024-10-23 17:16:14 I] Starting validation at step 2000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 855.98it/s]\n",
            "[2024-10-23 17:16:14 I] Validation loop at step 2000:\n",
            "[2024-10-23 17:16:14 I]     loss = 0.24816370825767523\n",
            "[2024-10-23 17:16:14 I]     mse = 0.24816370825767523\n",
            "[2024-10-23 17:16:14 I]     rmse = 0.4978062511872546\n",
            "[2024-10-23 17:16:14 I]     output_reg = 0.0\n",
            "[2024-10-23 17:16:14 I]     mae = 0.3882308705329894\n",
            "Training epochs:  60% 1494/2500 [00:29<00:17, 58.07it/s][2024-10-23 17:16:23 I] Starting validation at step 3000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 873.16it/s]\n",
            "[2024-10-23 17:16:23 I] Validation loop at step 3000:\n",
            "[2024-10-23 17:16:23 I]     loss = 0.24935502707958232\n",
            "[2024-10-23 17:16:23 I]     mse = 0.24935502707958232\n",
            "[2024-10-23 17:16:23 I]     rmse = 0.4989973990109516\n",
            "[2024-10-23 17:16:23 I]     output_reg = 0.0\n",
            "[2024-10-23 17:16:23 I]     mae = 0.3892653640747071\n",
            "Training epochs:  80% 1995/2500 [00:38<00:10, 49.20it/s][2024-10-23 17:16:33 I] Starting validation at step 4000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 894.95it/s]\n",
            "[2024-10-23 17:16:33 I] Validation loop at step 4000:\n",
            "[2024-10-23 17:16:33 I]     loss = 0.24967630066871646\n",
            "[2024-10-23 17:16:33 I]     mse = 0.24967630066871646\n",
            "[2024-10-23 17:16:33 I]     rmse = 0.49931792475971\n",
            "[2024-10-23 17:16:33 I]     output_reg = 0.0\n",
            "[2024-10-23 17:16:33 I]     mae = 0.389541083431244\n",
            "Training epochs: 100% 2500/2500 [00:48<00:00, 52.04it/s]\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 894.45it/s]\n",
            "[2024-10-23 17:16:42 I] Validation loop at step 5000:\n",
            "[2024-10-23 17:16:42 I]     loss = 0.2498770473003387\n",
            "[2024-10-23 17:16:42 I]     mse = 0.2498770473003387\n",
            "[2024-10-23 17:16:42 I]     rmse = 0.4995181658406249\n",
            "[2024-10-23 17:16:42 I]     output_reg = 0.0\n",
            "[2024-10-23 17:16:42 I]     mae = 0.38971285047531135\n",
            "[2024-10-23 17:16:42 I] Early stopping after step 1000 with validation loss 0.24362177646160127\n",
            "[2024-10-23 17:16:42 I] Saving model at $/content/nbody_data/experiments/nbody/mlp100_5000/models/model_final.pt\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 876.10it/s]\n",
            "[2024-10-23 17:16:42 I] Ran evaluation on dataset e3_generalization:\n",
            "[2024-10-23 17:16:42 I]     loss = 3.802013324737549\n",
            "[2024-10-23 17:16:42 I]     mse = 3.802013324737549\n",
            "[2024-10-23 17:16:42 I]     rmse = 1.9495711068954888\n",
            "[2024-10-23 17:16:42 I]     output_reg = 0.0\n",
            "[2024-10-23 17:16:42 I]     mae = 1.6296432910919187\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 876.70it/s]\n",
            "[2024-10-23 17:16:42 I] Ran evaluation on dataset eval:\n",
            "[2024-10-23 17:16:42 I]     loss = 0.24463987302780146\n",
            "[2024-10-23 17:16:42 I]     mse = 0.24463987302780146\n",
            "[2024-10-23 17:16:42 I]     rmse = 0.49418280448452495\n",
            "[2024-10-23 17:16:42 I]     output_reg = 0.0\n",
            "[2024-10-23 17:16:42 I]     mae = 0.3846726242065431\n",
            "[2024-10-23 17:16:43 I] Anders nog iets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=mlp_nbody data.subsample=0.001 training.steps=20000 run_name=mlp100_20000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d229d7d-92e2-4f42-c971-8e6f324d3ad4",
        "id": "2hx2yuphO7Td"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 17:16:50 I] Hoi.\n",
            "[2024-10-23 17:16:51 I] Set experiment nbody with ID 1, artifact location file:/content/geometric-algebra-transformer/$/content/nbody_data/tracking/artifacts\n",
            "[2024-10-23 17:16:51 I] Logger already initialized - hi again!\n",
            "[2024-10-23 17:16:51 I] Running experiment at $/content/nbody_data/experiments/nbody/mlp100_20000\n",
            "[2024-10-23 17:16:51 I] Saving config at $/content/nbody_data/experiments/nbody/mlp100_20000/config.yml\n",
            "[2024-10-23 17:16:51 I] Model has 0.16M learnable parameters\n",
            "[2024-10-23 17:16:51 I] Starting training\n",
            "[2024-10-23 17:16:51 I] Training for 20000 steps, that is, 10000 epochs on a dataset of size 100 with batchsize 64\n",
            "Training epochs:   0% 0/10000 [00:00<?, ?it/s][2024-10-23 17:16:52 I] Finished first forward pass with loss 359.9129333496094\n",
            "Training epochs:   5% 494/10000 [00:09<02:41, 59.04it/s][2024-10-23 17:17:01 I] Starting validation at step 1000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 828.42it/s]\n",
            "[2024-10-23 17:17:02 I] Validation loop at step 1000:\n",
            "[2024-10-23 17:17:02 I]     loss = 0.24362177646160127\n",
            "[2024-10-23 17:17:02 I]     mse = 0.24362177646160127\n",
            "[2024-10-23 17:17:02 I]     rmse = 0.4932428104726286\n",
            "[2024-10-23 17:17:02 I]     output_reg = 0.0\n",
            "[2024-10-23 17:17:02 I]     mae = 0.38475706896781925\n",
            "Training epochs:  10% 996/10000 [00:19<02:34, 58.39it/s][2024-10-23 17:17:11 I] Starting validation at step 2000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 745.57it/s]\n",
            "[2024-10-23 17:17:11 I] Validation loop at step 2000:\n",
            "[2024-10-23 17:17:11 I]     loss = 0.2610536409139633\n",
            "[2024-10-23 17:17:11 I]     mse = 0.2610536409139633\n",
            "[2024-10-23 17:17:11 I]     rmse = 0.5105581532477073\n",
            "[2024-10-23 17:17:11 I]     output_reg = 0.0\n",
            "[2024-10-23 17:17:11 I]     mae = 0.3976192090511323\n",
            "Training epochs:  15% 1500/10000 [00:28<02:48, 50.37it/s][2024-10-23 17:17:21 I] Starting validation at step 3000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 579.13it/s]\n",
            "[2024-10-23 17:17:21 I] Validation loop at step 3000:\n",
            "[2024-10-23 17:17:21 I]     loss = 0.2511579170227051\n",
            "[2024-10-23 17:17:21 I]     mse = 0.2511579170227051\n",
            "[2024-10-23 17:17:21 I]     rmse = 0.5008270468241744\n",
            "[2024-10-23 17:17:21 I]     output_reg = 0.0\n",
            "[2024-10-23 17:17:21 I]     mae = 0.39133188781738276\n",
            "Training epochs:  20% 1999/10000 [00:38<02:13, 59.75it/s][2024-10-23 17:17:30 I] Starting validation at step 4000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 838.39it/s]\n",
            "[2024-10-23 17:17:30 I] Validation loop at step 4000:\n",
            "[2024-10-23 17:17:30 I]     loss = 0.25335300741195677\n",
            "[2024-10-23 17:17:30 I]     mse = 0.25335300741195677\n",
            "[2024-10-23 17:17:30 I]     rmse = 0.502981910696742\n",
            "[2024-10-23 17:17:30 I]     output_reg = 0.0\n",
            "[2024-10-23 17:17:30 I]     mae = 0.39237979278564455\n",
            "Training epochs:  25% 2500/10000 [00:47<02:04, 60.37it/s][2024-10-23 17:17:39 I] Starting validation at step 5000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 912.65it/s]\n",
            "[2024-10-23 17:17:40 I] Validation loop at step 5000:\n",
            "[2024-10-23 17:17:40 I]     loss = 0.24688876254558562\n",
            "[2024-10-23 17:17:40 I]     mse = 0.24688876254558562\n",
            "[2024-10-23 17:17:40 I]     rmse = 0.49652972793865724\n",
            "[2024-10-23 17:17:40 I]     output_reg = 0.0\n",
            "[2024-10-23 17:17:40 I]     mae = 0.3876136703491211\n",
            "Training epochs:  30% 2995/10000 [00:57<01:52, 62.01it/s][2024-10-23 17:17:49 I] Starting validation at step 6000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 890.55it/s]\n",
            "[2024-10-23 17:17:49 I] Validation loop at step 6000:\n",
            "[2024-10-23 17:17:49 I]     loss = 0.2474079833507539\n",
            "[2024-10-23 17:17:49 I]     mse = 0.2474079833507539\n",
            "[2024-10-23 17:17:49 I]     rmse = 0.49705059484470043\n",
            "[2024-10-23 17:17:49 I]     output_reg = 0.0\n",
            "[2024-10-23 17:17:49 I]     mae = 0.3879724528789521\n",
            "Training epochs:  35% 3499/10000 [01:06<02:18, 47.03it/s][2024-10-23 17:17:58 I] Starting validation at step 7000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 879.81it/s]\n",
            "[2024-10-23 17:17:59 I] Validation loop at step 7000:\n",
            "[2024-10-23 17:17:59 I]     loss = 0.2465048070430756\n",
            "[2024-10-23 17:17:59 I]     mse = 0.2465048070430756\n",
            "[2024-10-23 17:17:59 I]     rmse = 0.4961430622170156\n",
            "[2024-10-23 17:17:59 I]     output_reg = 0.0\n",
            "[2024-10-23 17:17:59 I]     mae = 0.387342435359955\n",
            "Training epochs:  40% 3999/10000 [01:15<01:39, 60.11it/s][2024-10-23 17:18:08 I] Starting validation at step 8000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 812.67it/s]\n",
            "[2024-10-23 17:18:08 I] Validation loop at step 8000:\n",
            "[2024-10-23 17:18:08 I]     loss = 0.24566830430030825\n",
            "[2024-10-23 17:18:08 I]     mse = 0.24566830430030825\n",
            "[2024-10-23 17:18:08 I]     rmse = 0.4953003752372648\n",
            "[2024-10-23 17:18:08 I]     output_reg = 0.0\n",
            "[2024-10-23 17:18:08 I]     mae = 0.38676220684051527\n",
            "Training epochs:  45% 4498/10000 [01:25<01:31, 59.81it/s][2024-10-23 17:18:17 I] Starting validation at step 9000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 907.22it/s]\n",
            "[2024-10-23 17:18:17 I] Validation loop at step 9000:\n",
            "[2024-10-23 17:18:17 I]     loss = 0.24618753926754003\n",
            "[2024-10-23 17:18:17 I]     mse = 0.24618753926754003\n",
            "[2024-10-23 17:18:17 I]     rmse = 0.49582241836477026\n",
            "[2024-10-23 17:18:17 I]     output_reg = 0.0\n",
            "[2024-10-23 17:18:17 I]     mae = 0.3871203736782075\n",
            "Training epochs:  50% 5000/10000 [01:35<01:23, 60.18it/s][2024-10-23 17:18:27 I] Starting validation at step 10000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 885.61it/s]\n",
            "[2024-10-23 17:18:27 I] Validation loop at step 10000:\n",
            "[2024-10-23 17:18:27 I]     loss = 0.2461827409744263\n",
            "[2024-10-23 17:18:27 I]     mse = 0.2461827409744263\n",
            "[2024-10-23 17:18:27 I]     rmse = 0.4958180433723568\n",
            "[2024-10-23 17:18:27 I]     output_reg = 0.0\n",
            "[2024-10-23 17:18:27 I]     mae = 0.38712574400901795\n",
            "Training epochs:  55% 5495/10000 [01:44<01:15, 59.94it/s][2024-10-23 17:18:37 I] Starting validation at step 11000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 858.50it/s]\n",
            "[2024-10-23 17:18:37 I] Validation loop at step 11000:\n",
            "[2024-10-23 17:18:37 I]     loss = 0.24587381465435026\n",
            "[2024-10-23 17:18:37 I]     mse = 0.24587381465435026\n",
            "[2024-10-23 17:18:37 I]     rmse = 0.49550788167084264\n",
            "[2024-10-23 17:18:37 I]     output_reg = 0.0\n",
            "[2024-10-23 17:18:37 I]     mae = 0.3868930837631223\n",
            "Training epochs:  60% 5995/10000 [01:54<01:19, 50.19it/s][2024-10-23 17:18:46 I] Starting validation at step 12000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 673.66it/s]\n",
            "[2024-10-23 17:18:46 I] Validation loop at step 12000:\n",
            "[2024-10-23 17:18:46 I]     loss = 0.2460581005573273\n",
            "[2024-10-23 17:18:46 I]     mse = 0.2460581005573273\n",
            "[2024-10-23 17:18:46 I]     rmse = 0.495692925827231\n",
            "[2024-10-23 17:18:46 I]     output_reg = 0.0\n",
            "[2024-10-23 17:18:46 I]     mae = 0.3870192130088806\n",
            "Training epochs:  65% 6498/10000 [02:03<00:58, 59.40it/s][2024-10-23 17:18:55 I] Starting validation at step 13000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 898.51it/s]\n",
            "[2024-10-23 17:18:55 I] Validation loop at step 13000:\n",
            "[2024-10-23 17:18:55 I]     loss = 0.2460200022459029\n",
            "[2024-10-23 17:18:55 I]     mse = 0.2460200022459029\n",
            "[2024-10-23 17:18:56 I]     rmse = 0.49565459463450423\n",
            "[2024-10-23 17:18:56 I]     output_reg = 0.0\n",
            "[2024-10-23 17:18:56 I]     mae = 0.3869922737121584\n",
            "Training epochs:  70% 6995/10000 [02:13<00:51, 58.12it/s][2024-10-23 17:19:05 I] Starting validation at step 14000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 876.71it/s]\n",
            "[2024-10-23 17:19:05 I] Validation loop at step 14000:\n",
            "[2024-10-23 17:19:05 I]     loss = 0.2460429941892624\n",
            "[2024-10-23 17:19:05 I]     mse = 0.2460429941892624\n",
            "[2024-10-23 17:19:05 I]     rmse = 0.4956776724760279\n",
            "[2024-10-23 17:19:05 I]     output_reg = 0.0\n",
            "[2024-10-23 17:19:05 I]     mae = 0.3870098414421082\n",
            "Training epochs:  75% 7498/10000 [02:23<00:42, 59.00it/s][2024-10-23 17:19:15 I] Starting validation at step 15000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 852.47it/s]\n",
            "[2024-10-23 17:19:15 I] Validation loop at step 15000:\n",
            "[2024-10-23 17:19:15 I]     loss = 0.2460557703971863\n",
            "[2024-10-23 17:19:15 I]     mse = 0.2460557703971863\n",
            "[2024-10-23 17:19:15 I]     rmse = 0.4956903548816841\n",
            "[2024-10-23 17:19:15 I]     output_reg = 0.0\n",
            "[2024-10-23 17:19:15 I]     mae = 0.387021069431305\n",
            "Training epochs:  80% 8000/10000 [02:32<00:33, 59.07it/s][2024-10-23 17:19:24 I] Starting validation at step 16000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 778.94it/s]\n",
            "[2024-10-23 17:19:24 I] Validation loop at step 16000:\n",
            "[2024-10-23 17:19:24 I]     loss = 0.24610369982719424\n",
            "[2024-10-23 17:19:24 I]     mse = 0.24610369982719424\n",
            "[2024-10-23 17:19:24 I]     rmse = 0.49573849362474504\n",
            "[2024-10-23 17:19:24 I]     output_reg = 0.0\n",
            "[2024-10-23 17:19:24 I]     mae = 0.38706492109298707\n",
            "Training epochs:  85% 8497/10000 [02:41<00:25, 59.76it/s][2024-10-23 17:19:34 I] Starting validation at step 17000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 638.06it/s]\n",
            "[2024-10-23 17:19:34 I] Validation loop at step 17000:\n",
            "[2024-10-23 17:19:34 I]     loss = 0.246020297908783\n",
            "[2024-10-23 17:19:34 I]     mse = 0.246020297908783\n",
            "[2024-10-23 17:19:34 I]     rmse = 0.4956549162122125\n",
            "[2024-10-23 17:19:34 I]     output_reg = 0.0\n",
            "[2024-10-23 17:19:34 I]     mae = 0.3869927803039551\n",
            "Training epochs:  90% 8995/10000 [02:51<00:17, 58.43it/s][2024-10-23 17:19:43 I] Starting validation at step 18000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 888.36it/s]\n",
            "[2024-10-23 17:19:43 I] Validation loop at step 18000:\n",
            "[2024-10-23 17:19:43 I]     loss = 0.24602014234066014\n",
            "[2024-10-23 17:19:43 I]     mse = 0.24602014234066014\n",
            "[2024-10-23 17:19:43 I]     rmse = 0.49565476068051606\n",
            "[2024-10-23 17:19:43 I]     output_reg = 0.0\n",
            "[2024-10-23 17:19:43 I]     mae = 0.3869926864147185\n",
            "Training epochs:  95% 9500/10000 [03:01<00:08, 59.13it/s][2024-10-23 17:19:53 I] Starting validation at step 19000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 855.69it/s]\n",
            "[2024-10-23 17:19:53 I] Validation loop at step 19000:\n",
            "[2024-10-23 17:19:53 I]     loss = 0.24600644996166232\n",
            "[2024-10-23 17:19:53 I]     mse = 0.24600644996166232\n",
            "[2024-10-23 17:19:53 I]     rmse = 0.4956410230611973\n",
            "[2024-10-23 17:19:53 I]     output_reg = 0.0\n",
            "[2024-10-23 17:19:53 I]     mae = 0.38698012342453003\n",
            "Training epochs: 100% 10000/10000 [03:11<00:00, 52.35it/s]\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 850.77it/s]\n",
            "[2024-10-23 17:20:03 I] Validation loop at step 20000:\n",
            "[2024-10-23 17:20:03 I]     loss = 0.2460189826488495\n",
            "[2024-10-23 17:20:03 I]     mse = 0.2460189826488495\n",
            "[2024-10-23 17:20:03 I]     rmse = 0.49565358895762235\n",
            "[2024-10-23 17:20:03 I]     output_reg = 0.0\n",
            "[2024-10-23 17:20:03 I]     mae = 0.3869919774055482\n",
            "[2024-10-23 17:20:03 I] Early stopping after step 1000 with validation loss 0.24362177646160127\n",
            "[2024-10-23 17:20:03 I] Saving model at $/content/nbody_data/experiments/nbody/mlp100_20000/models/model_final.pt\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 849.98it/s]\n",
            "[2024-10-23 17:20:03 I] Ran evaluation on dataset e3_generalization:\n",
            "[2024-10-23 17:20:03 I]     loss = 3.7648974163055406\n",
            "[2024-10-23 17:20:03 I]     mse = 3.7648974163055406\n",
            "[2024-10-23 17:20:03 I]     rmse = 1.9400161592564975\n",
            "[2024-10-23 17:20:03 I]     output_reg = 0.0\n",
            "[2024-10-23 17:20:03 I]     mae = 1.5861194931030282\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 901.58it/s]\n",
            "[2024-10-23 17:20:03 I] Ran evaluation on dataset eval:\n",
            "[2024-10-23 17:20:03 I]     loss = 0.2408346940040589\n",
            "[2024-10-23 17:20:03 I]     mse = 0.2408346940040589\n",
            "[2024-10-23 17:20:03 I]     rmse = 0.4903265398433759\n",
            "[2024-10-23 17:20:03 I]     output_reg = 0.0\n",
            "[2024-10-23 17:20:03 I]     mae = 0.38185408401489257\n",
            "[2024-10-23 17:20:03 I] Anders nog iets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=mlp_nbody data.subsample=0.001 training.steps=50000 run_name=mlp100_50000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "195adcbe-faaf-4bac-bb86-e122c8356649",
        "id": "P2HEDNNnO7Td"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 17:20:11 I] Hoi.\n",
            "[2024-10-23 17:20:11 I] Set experiment nbody with ID 1, artifact location file:/content/geometric-algebra-transformer/$/content/nbody_data/tracking/artifacts\n",
            "[2024-10-23 17:20:11 I] Logger already initialized - hi again!\n",
            "[2024-10-23 17:20:11 I] Running experiment at $/content/nbody_data/experiments/nbody/mlp100_50000\n",
            "[2024-10-23 17:20:11 I] Saving config at $/content/nbody_data/experiments/nbody/mlp100_50000/config.yml\n",
            "[2024-10-23 17:20:12 I] Model has 0.16M learnable parameters\n",
            "[2024-10-23 17:20:12 I] Starting training\n",
            "[2024-10-23 17:20:12 I] Training for 50000 steps, that is, 25000 epochs on a dataset of size 100 with batchsize 64\n",
            "Training epochs:   0% 0/25000 [00:00<?, ?it/s][2024-10-23 17:20:12 I] Finished first forward pass with loss 359.9129333496094\n",
            "Training epochs:   2% 496/25000 [00:09<06:56, 58.79it/s][2024-10-23 17:20:22 I] Starting validation at step 1000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 819.56it/s]\n",
            "[2024-10-23 17:20:22 I] Validation loop at step 1000:\n",
            "[2024-10-23 17:20:22 I]     loss = 0.24362177646160127\n",
            "[2024-10-23 17:20:22 I]     mse = 0.24362177646160127\n",
            "[2024-10-23 17:20:22 I]     rmse = 0.4932428104726286\n",
            "[2024-10-23 17:20:22 I]     output_reg = 0.0\n",
            "[2024-10-23 17:20:22 I]     mae = 0.38475706896781925\n",
            "Training epochs:   4% 995/25000 [00:19<06:56, 57.66it/s][2024-10-23 17:20:31 I] Starting validation at step 2000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 903.60it/s]\n",
            "[2024-10-23 17:20:32 I] Validation loop at step 2000:\n",
            "[2024-10-23 17:20:32 I]     loss = 0.2868283799648285\n",
            "[2024-10-23 17:20:32 I]     mse = 0.2868283799648285\n",
            "[2024-10-23 17:20:32 I]     rmse = 0.5351196368774049\n",
            "[2024-10-23 17:20:32 I]     output_reg = 0.0\n",
            "[2024-10-23 17:20:32 I]     mae = 0.41758589859008777\n",
            "Training epochs:   6% 1495/25000 [00:28<06:42, 58.44it/s][2024-10-23 17:20:41 I] Starting validation at step 3000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 844.28it/s]\n",
            "[2024-10-23 17:20:41 I] Validation loop at step 3000:\n",
            "[2024-10-23 17:20:41 I]     loss = 0.2658909883260727\n",
            "[2024-10-23 17:20:41 I]     mse = 0.2658909883260727\n",
            "[2024-10-23 17:20:41 I]     rmse = 0.5152685663699982\n",
            "[2024-10-23 17:20:41 I]     output_reg = 0.0\n",
            "[2024-10-23 17:20:41 I]     mae = 0.4015566485404969\n",
            "Training epochs:   8% 1999/25000 [00:38<06:26, 59.56it/s][2024-10-23 17:20:51 I] Starting validation at step 4000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 905.61it/s]\n",
            "[2024-10-23 17:20:51 I] Validation loop at step 4000:\n",
            "[2024-10-23 17:20:51 I]     loss = 0.24856192500591284\n",
            "[2024-10-23 17:20:51 I]     mse = 0.24856192500591284\n",
            "[2024-10-23 17:20:51 I]     rmse = 0.4982009828241924\n",
            "[2024-10-23 17:20:51 I]     output_reg = 0.0\n",
            "[2024-10-23 17:20:51 I]     mae = 0.38881900100708017\n",
            "Training epochs:  10% 2498/25000 [00:48<07:44, 48.45it/s][2024-10-23 17:21:01 I] Starting validation at step 5000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 878.06it/s]\n",
            "[2024-10-23 17:21:01 I] Validation loop at step 5000:\n",
            "[2024-10-23 17:21:01 I]     loss = 0.24402537851333622\n",
            "[2024-10-23 17:21:01 I]     mse = 0.24402537851333622\n",
            "[2024-10-23 17:21:01 I]     rmse = 0.4936500816710844\n",
            "[2024-10-23 17:21:01 I]     output_reg = 0.0\n",
            "[2024-10-23 17:21:01 I]     mae = 0.38582063703536984\n",
            "Training epochs:  12% 2995/25000 [00:57<06:08, 59.70it/s][2024-10-23 17:21:10 I] Starting validation at step 6000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 875.45it/s]\n",
            "[2024-10-23 17:21:10 I] Validation loop at step 6000:\n",
            "[2024-10-23 17:21:10 I]     loss = 0.24654737324714662\n",
            "[2024-10-23 17:21:10 I]     mse = 0.24654737324714662\n",
            "[2024-10-23 17:21:10 I]     rmse = 0.4961987461912862\n",
            "[2024-10-23 17:21:10 I]     output_reg = 0.0\n",
            "[2024-10-23 17:21:10 I]     mae = 0.3875956721782685\n",
            "Training epochs:  14% 3495/25000 [01:07<06:04, 58.92it/s][2024-10-23 17:21:19 I] Starting validation at step 7000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 897.38it/s]\n",
            "[2024-10-23 17:21:19 I] Validation loop at step 7000:\n",
            "[2024-10-23 17:21:19 I]     loss = 0.24391277441978457\n",
            "[2024-10-23 17:21:19 I]     mse = 0.24391277441978457\n",
            "[2024-10-23 17:21:19 I]     rmse = 0.49353272578655605\n",
            "[2024-10-23 17:21:19 I]     output_reg = 0.0\n",
            "[2024-10-23 17:21:19 I]     mae = 0.38564356837272645\n",
            "Training epochs:  16% 3996/25000 [01:16<05:53, 59.46it/s][2024-10-23 17:21:29 I] Starting validation at step 8000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 852.75it/s]\n",
            "[2024-10-23 17:21:29 I] Validation loop at step 8000:\n",
            "[2024-10-23 17:21:29 I]     loss = 0.2418531239271164\n",
            "[2024-10-23 17:21:29 I]     mse = 0.2418531239271164\n",
            "[2024-10-23 17:21:29 I]     rmse = 0.4914480999751568\n",
            "[2024-10-23 17:21:29 I]     output_reg = 0.0\n",
            "[2024-10-23 17:21:29 I]     mae = 0.38422486572265613\n",
            "Training epochs:  18% 4495/25000 [01:26<05:35, 61.08it/s][2024-10-23 17:21:38 I] Starting validation at step 9000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 912.48it/s]\n",
            "[2024-10-23 17:21:39 I] Validation loop at step 9000:\n",
            "[2024-10-23 17:21:39 I]     loss = 0.24173762702941895\n",
            "[2024-10-23 17:21:39 I]     mse = 0.24173762702941895\n",
            "[2024-10-23 17:21:39 I]     rmse = 0.49133655942065746\n",
            "[2024-10-23 17:21:39 I]     output_reg = 0.0\n",
            "[2024-10-23 17:21:39 I]     mae = 0.3842663407802583\n",
            "Training epochs:  20% 4996/25000 [01:35<06:18, 52.83it/s][2024-10-23 17:21:48 I] Starting validation at step 10000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 563.54it/s]\n",
            "[2024-10-23 17:21:48 I] Validation loop at step 10000:\n",
            "[2024-10-23 17:21:48 I]     loss = 0.2420160463333131\n",
            "[2024-10-23 17:21:48 I]     mse = 0.2420160463333131\n",
            "[2024-10-23 17:21:48 I]     rmse = 0.49162115548716484\n",
            "[2024-10-23 17:21:48 I]     output_reg = 0.0\n",
            "[2024-10-23 17:21:48 I]     mae = 0.38453836784362794\n",
            "Training epochs:  22% 5496/25000 [01:45<05:36, 58.03it/s][2024-10-23 17:21:57 I] Starting validation at step 11000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 883.89it/s]\n",
            "[2024-10-23 17:21:57 I] Validation loop at step 11000:\n",
            "[2024-10-23 17:21:57 I]     loss = 0.2422873342514038\n",
            "[2024-10-23 17:21:57 I]     mse = 0.2422873342514038\n",
            "[2024-10-23 17:21:57 I]     rmse = 0.4918956311761314\n",
            "[2024-10-23 17:21:57 I]     output_reg = 0.0\n",
            "[2024-10-23 17:21:57 I]     mae = 0.3848669257164\n",
            "Training epochs:  24% 5996/25000 [01:54<05:19, 59.55it/s][2024-10-23 17:22:07 I] Starting validation at step 12000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 876.28it/s]\n",
            "[2024-10-23 17:22:07 I] Validation loop at step 12000:\n",
            "[2024-10-23 17:22:07 I]     loss = 0.24209490964412692\n",
            "[2024-10-23 17:22:07 I]     mse = 0.24209490964412692\n",
            "[2024-10-23 17:22:07 I]     rmse = 0.4917008678948228\n",
            "[2024-10-23 17:22:07 I]     output_reg = 0.0\n",
            "[2024-10-23 17:22:07 I]     mae = 0.3846087985992433\n",
            "Training epochs:  26% 6495/25000 [02:04<05:11, 59.33it/s][2024-10-23 17:22:17 I] Starting validation at step 13000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 825.07it/s]\n",
            "[2024-10-23 17:22:17 I] Validation loop at step 13000:\n",
            "[2024-10-23 17:22:17 I]     loss = 0.24178020610809334\n",
            "[2024-10-23 17:22:17 I]     mse = 0.24178020610809334\n",
            "[2024-10-23 17:22:17 I]     rmse = 0.4913808310969954\n",
            "[2024-10-23 17:22:17 I]     output_reg = 0.0\n",
            "[2024-10-23 17:22:17 I]     mae = 0.384563268661499\n",
            "Training epochs:  28% 7000/25000 [02:14<05:09, 58.08it/s][2024-10-23 17:22:26 I] Starting validation at step 14000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 906.11it/s]\n",
            "[2024-10-23 17:22:26 I] Validation loop at step 14000:\n",
            "[2024-10-23 17:22:26 I]     loss = 0.2428937644720078\n",
            "[2024-10-23 17:22:26 I]     mse = 0.2428937644720078\n",
            "[2024-10-23 17:22:26 I]     rmse = 0.49250863133296985\n",
            "[2024-10-23 17:22:26 I]     output_reg = 0.0\n",
            "[2024-10-23 17:22:26 I]     mae = 0.3850592906951904\n",
            "Training epochs:  30% 7500/25000 [02:23<05:13, 55.83it/s][2024-10-23 17:22:36 I] Starting validation at step 15000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 605.18it/s]\n",
            "[2024-10-23 17:22:36 I] Validation loop at step 15000:\n",
            "[2024-10-23 17:22:36 I]     loss = 0.24367041869163508\n",
            "[2024-10-23 17:22:36 I]     mse = 0.24367041869163508\n",
            "[2024-10-23 17:22:36 I]     rmse = 0.49329315125122686\n",
            "[2024-10-23 17:22:36 I]     output_reg = 0.0\n",
            "[2024-10-23 17:22:36 I]     mae = 0.38577457475662247\n",
            "Training epochs:  32% 7996/25000 [02:32<04:43, 59.98it/s][2024-10-23 17:22:45 I] Starting validation at step 16000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 755.66it/s]\n",
            "[2024-10-23 17:22:45 I] Validation loop at step 16000:\n",
            "[2024-10-23 17:22:45 I]     loss = 0.24204846694469465\n",
            "[2024-10-23 17:22:45 I]     mse = 0.24204846694469465\n",
            "[2024-10-23 17:22:45 I]     rmse = 0.49165517936922315\n",
            "[2024-10-23 17:22:45 I]     output_reg = 0.0\n",
            "[2024-10-23 17:22:45 I]     mae = 0.3846766658782957\n",
            "Training epochs:  34% 8495/25000 [02:42<04:28, 61.39it/s][2024-10-23 17:22:55 I] Starting validation at step 17000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 882.73it/s]\n",
            "[2024-10-23 17:22:55 I] Validation loop at step 17000:\n",
            "[2024-10-23 17:22:55 I]     loss = 0.24438507323265082\n",
            "[2024-10-23 17:22:55 I]     mse = 0.24438507323265082\n",
            "[2024-10-23 17:22:55 I]     rmse = 0.49402053045299094\n",
            "[2024-10-23 17:22:55 I]     output_reg = 0.0\n",
            "[2024-10-23 17:22:55 I]     mae = 0.3863540807247162\n",
            "Training epochs:  36% 8996/25000 [02:51<04:29, 59.49it/s][2024-10-23 17:23:04 I] Starting validation at step 18000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 899.39it/s]\n",
            "[2024-10-23 17:23:04 I] Validation loop at step 18000:\n",
            "[2024-10-23 17:23:04 I]     loss = 0.24179511327743541\n",
            "[2024-10-23 17:23:04 I]     mse = 0.24179511327743541\n",
            "[2024-10-23 17:23:04 I]     rmse = 0.4913993386691016\n",
            "[2024-10-23 17:23:04 I]     output_reg = 0.0\n",
            "[2024-10-23 17:23:04 I]     mae = 0.38445624327659617\n",
            "Training epochs:  38% 9498/25000 [03:01<05:15, 49.19it/s][2024-10-23 17:23:14 I] Starting validation at step 19000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 823.56it/s]\n",
            "[2024-10-23 17:23:14 I] Validation loop at step 19000:\n",
            "[2024-10-23 17:23:14 I]     loss = 0.24393568744659436\n",
            "[2024-10-23 17:23:14 I]     mse = 0.24393568744659436\n",
            "[2024-10-23 17:23:14 I]     rmse = 0.4935610751452913\n",
            "[2024-10-23 17:23:14 I]     output_reg = 0.0\n",
            "[2024-10-23 17:23:14 I]     mae = 0.3860452061653137\n",
            "Training epochs:  40% 9998/25000 [03:10<04:09, 60.20it/s][2024-10-23 17:23:23 I] Starting validation at step 20000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 904.67it/s]\n",
            "[2024-10-23 17:23:23 I] Validation loop at step 20000:\n",
            "[2024-10-23 17:23:23 I]     loss = 0.24176367130279544\n",
            "[2024-10-23 17:23:23 I]     mse = 0.24176367130279544\n",
            "[2024-10-23 17:23:23 I]     rmse = 0.4913678802829712\n",
            "[2024-10-23 17:23:23 I]     output_reg = 0.0\n",
            "[2024-10-23 17:23:23 I]     mae = 0.38444027404785164\n",
            "Training epochs:  42% 10497/25000 [03:20<04:02, 59.73it/s][2024-10-23 17:23:32 I] Starting validation at step 21000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 851.66it/s]\n",
            "[2024-10-23 17:23:33 I] Validation loop at step 21000:\n",
            "[2024-10-23 17:23:33 I]     loss = 0.24285712561607362\n",
            "[2024-10-23 17:23:33 I]     mse = 0.24285712561607362\n",
            "[2024-10-23 17:23:33 I]     rmse = 0.4924770742299912\n",
            "[2024-10-23 17:23:33 I]     output_reg = 0.0\n",
            "[2024-10-23 17:23:33 I]     mae = 0.3854253762722014\n",
            "Training epochs:  44% 10996/25000 [03:29<03:56, 59.17it/s][2024-10-23 17:23:42 I] Starting validation at step 22000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 872.87it/s]\n",
            "[2024-10-23 17:23:42 I] Validation loop at step 22000:\n",
            "[2024-10-23 17:23:42 I]     loss = 0.2418091874837876\n",
            "[2024-10-23 17:23:42 I]     mse = 0.2418091874837876\n",
            "[2024-10-23 17:23:42 I]     rmse = 0.49141407248910085\n",
            "[2024-10-23 17:23:42 I]     output_reg = 0.0\n",
            "[2024-10-23 17:23:42 I]     mae = 0.38444981970787045\n",
            "Training epochs:  46% 11499/25000 [03:39<03:56, 57.02it/s][2024-10-23 17:23:52 I] Starting validation at step 23000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 892.54it/s]\n",
            "[2024-10-23 17:23:52 I] Validation loop at step 23000:\n",
            "[2024-10-23 17:23:52 I]     loss = 0.24114035575389864\n",
            "[2024-10-23 17:23:52 I]     mse = 0.24114035575389864\n",
            "[2024-10-23 17:23:52 I]     rmse = 0.4907356762830789\n",
            "[2024-10-23 17:23:52 I]     output_reg = 0.0\n",
            "[2024-10-23 17:23:52 I]     mae = 0.3839755313396453\n",
            "Training epochs:  48% 12000/25000 [03:49<04:31, 47.94it/s][2024-10-23 17:24:02 I] Starting validation at step 24000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 709.22it/s]\n",
            "[2024-10-23 17:24:02 I] Validation loop at step 24000:\n",
            "[2024-10-23 17:24:02 I]     loss = 0.2417491827487946\n",
            "[2024-10-23 17:24:02 I]     mse = 0.2417491827487946\n",
            "[2024-10-23 17:24:02 I]     rmse = 0.4913543426745874\n",
            "[2024-10-23 17:24:02 I]     output_reg = 0.0\n",
            "[2024-10-23 17:24:02 I]     mae = 0.3844206957817077\n",
            "Training epochs:  50% 12497/25000 [03:59<03:32, 58.86it/s][2024-10-23 17:24:11 I] Starting validation at step 25000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 870.86it/s]\n",
            "[2024-10-23 17:24:12 I] Validation loop at step 25000:\n",
            "[2024-10-23 17:24:12 I]     loss = 0.2416016971111298\n",
            "[2024-10-23 17:24:12 I]     mse = 0.2416016971111298\n",
            "[2024-10-23 17:24:12 I]     rmse = 0.4912072864605912\n",
            "[2024-10-23 17:24:12 I]     output_reg = 0.0\n",
            "[2024-10-23 17:24:12 I]     mae = 0.38440261135101306\n",
            "Training epochs:  52% 12994/25000 [04:08<03:23, 59.06it/s][2024-10-23 17:24:21 I] Starting validation at step 26000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 847.73it/s]\n",
            "[2024-10-23 17:24:21 I] Validation loop at step 26000:\n",
            "[2024-10-23 17:24:21 I]     loss = 0.24172510457038873\n",
            "[2024-10-23 17:24:21 I]     mse = 0.24172510457038873\n",
            "[2024-10-23 17:24:21 I]     rmse = 0.4913311487570504\n",
            "[2024-10-23 17:24:21 I]     output_reg = 0.0\n",
            "[2024-10-23 17:24:21 I]     mae = 0.3844777224540709\n",
            "Training epochs:  54% 13496/25000 [04:18<03:08, 61.11it/s][2024-10-23 17:24:30 I] Starting validation at step 27000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 886.81it/s]\n",
            "[2024-10-23 17:24:31 I] Validation loop at step 27000:\n",
            "[2024-10-23 17:24:31 I]     loss = 0.24244451615810395\n",
            "[2024-10-23 17:24:31 I]     mse = 0.24244451615810395\n",
            "[2024-10-23 17:24:31 I]     rmse = 0.4920613359281947\n",
            "[2024-10-23 17:24:31 I]     output_reg = 0.0\n",
            "[2024-10-23 17:24:31 I]     mae = 0.3849273716926575\n",
            "Training epochs:  56% 13995/25000 [04:27<03:01, 60.74it/s][2024-10-23 17:24:40 I] Starting validation at step 28000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 818.21it/s]\n",
            "[2024-10-23 17:24:40 I] Validation loop at step 28000:\n",
            "[2024-10-23 17:24:40 I]     loss = 0.2416995276927948\n",
            "[2024-10-23 17:24:40 I]     mse = 0.2416995276927948\n",
            "[2024-10-23 17:24:40 I]     rmse = 0.49130355752289523\n",
            "[2024-10-23 17:24:40 I]     output_reg = 0.0\n",
            "[2024-10-23 17:24:40 I]     mae = 0.3843898206710816\n",
            "Training epochs:  58% 14498/25000 [04:37<03:19, 52.68it/s][2024-10-23 17:24:49 I] Starting validation at step 29000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 598.24it/s]\n",
            "[2024-10-23 17:24:49 I] Validation loop at step 29000:\n",
            "[2024-10-23 17:24:49 I]     loss = 0.24160371031761174\n",
            "[2024-10-23 17:24:49 I]     mse = 0.24160371031761174\n",
            "[2024-10-23 17:24:49 I]     rmse = 0.4912066216452649\n",
            "[2024-10-23 17:24:49 I]     output_reg = 0.0\n",
            "[2024-10-23 17:24:49 I]     mae = 0.38433714752197273\n",
            "Training epochs:  60% 14996/25000 [04:46<02:49, 59.10it/s][2024-10-23 17:24:59 I] Starting validation at step 30000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 861.26it/s]\n",
            "[2024-10-23 17:24:59 I] Validation loop at step 30000:\n",
            "[2024-10-23 17:24:59 I]     loss = 0.24146937108039854\n",
            "[2024-10-23 17:24:59 I]     mse = 0.24146937108039854\n",
            "[2024-10-23 17:24:59 I]     rmse = 0.4910696423275016\n",
            "[2024-10-23 17:24:59 I]     output_reg = 0.0\n",
            "[2024-10-23 17:24:59 I]     mae = 0.38419272208213806\n",
            "Training epochs:  62% 15500/25000 [04:56<02:38, 59.79it/s][2024-10-23 17:25:08 I] Starting validation at step 31000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 857.44it/s]\n",
            "[2024-10-23 17:25:09 I] Validation loop at step 31000:\n",
            "[2024-10-23 17:25:09 I]     loss = 0.2423580631971359\n",
            "[2024-10-23 17:25:09 I]     mse = 0.2423580631971359\n",
            "[2024-10-23 17:25:09 I]     rmse = 0.4919694314148448\n",
            "[2024-10-23 17:25:09 I]     output_reg = 0.0\n",
            "[2024-10-23 17:25:09 I]     mae = 0.3848747710227967\n",
            "Training epochs:  64% 16000/25000 [05:06<02:35, 57.70it/s][2024-10-23 17:25:18 I] Starting validation at step 32000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 860.98it/s]\n",
            "[2024-10-23 17:25:18 I] Validation loop at step 32000:\n",
            "[2024-10-23 17:25:18 I]     loss = 0.24168204445838923\n",
            "[2024-10-23 17:25:18 I]     mse = 0.24168204445838923\n",
            "[2024-10-23 17:25:18 I]     rmse = 0.49128610996153155\n",
            "[2024-10-23 17:25:18 I]     output_reg = 0.0\n",
            "[2024-10-23 17:25:18 I]     mae = 0.38438566489219667\n",
            "Training epochs:  66% 16497/25000 [05:15<02:25, 58.45it/s][2024-10-23 17:25:28 I] Starting validation at step 33000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 850.99it/s]\n",
            "[2024-10-23 17:25:28 I] Validation loop at step 33000:\n",
            "[2024-10-23 17:25:28 I]     loss = 0.24164708275794988\n",
            "[2024-10-23 17:25:28 I]     mse = 0.24164708275794988\n",
            "[2024-10-23 17:25:28 I]     rmse = 0.491250697354307\n",
            "[2024-10-23 17:25:28 I]     output_reg = 0.0\n",
            "[2024-10-23 17:25:28 I]     mae = 0.3843549957275392\n",
            "Training epochs:  68% 16998/25000 [05:25<02:37, 50.75it/s][2024-10-23 17:25:37 I] Starting validation at step 34000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 670.21it/s]\n",
            "[2024-10-23 17:25:38 I] Validation loop at step 34000:\n",
            "[2024-10-23 17:25:38 I]     loss = 0.24165249059200283\n",
            "[2024-10-23 17:25:38 I]     mse = 0.24165249059200283\n",
            "[2024-10-23 17:25:38 I]     rmse = 0.4912561270739429\n",
            "[2024-10-23 17:25:38 I]     output_reg = 0.0\n",
            "[2024-10-23 17:25:38 I]     mae = 0.3843589066982269\n",
            "Training epochs:  70% 17500/25000 [05:34<02:07, 58.96it/s][2024-10-23 17:25:47 I] Starting validation at step 35000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 857.23it/s]\n",
            "[2024-10-23 17:25:47 I] Validation loop at step 35000:\n",
            "[2024-10-23 17:25:47 I]     loss = 0.24174535312652584\n",
            "[2024-10-23 17:25:47 I]     mse = 0.24174535312652584\n",
            "[2024-10-23 17:25:47 I]     rmse = 0.4913501191156745\n",
            "[2024-10-23 17:25:47 I]     output_reg = 0.0\n",
            "[2024-10-23 17:25:47 I]     mae = 0.38443373041152956\n",
            "Training epochs:  72% 18000/25000 [05:44<02:06, 55.51it/s][2024-10-23 17:25:57 I] Starting validation at step 36000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 869.25it/s]\n",
            "[2024-10-23 17:25:57 I] Validation loop at step 36000:\n",
            "[2024-10-23 17:25:57 I]     loss = 0.24167185409069067\n",
            "[2024-10-23 17:25:57 I]     mse = 0.24167185409069067\n",
            "[2024-10-23 17:25:57 I]     rmse = 0.4912757098579029\n",
            "[2024-10-23 17:25:57 I]     output_reg = 0.0\n",
            "[2024-10-23 17:25:57 I]     mae = 0.3843699988365173\n",
            "Training epochs:  74% 18496/25000 [05:54<01:52, 58.07it/s][2024-10-23 17:26:07 I] Starting validation at step 37000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 904.41it/s]\n",
            "[2024-10-23 17:26:07 I] Validation loop at step 37000:\n",
            "[2024-10-23 17:26:07 I]     loss = 0.24147419965267186\n",
            "[2024-10-23 17:26:07 I]     mse = 0.24147419965267186\n",
            "[2024-10-23 17:26:07 I]     rmse = 0.49107384165582496\n",
            "[2024-10-23 17:26:07 I]     output_reg = 0.0\n",
            "[2024-10-23 17:26:07 I]     mae = 0.38420512933731105\n",
            "Training epochs:  76% 18997/25000 [06:04<01:42, 58.40it/s][2024-10-23 17:26:16 I] Starting validation at step 38000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 876.43it/s]\n",
            "[2024-10-23 17:26:16 I] Validation loop at step 38000:\n",
            "[2024-10-23 17:26:16 I]     loss = 0.24162666976451885\n",
            "[2024-10-23 17:26:16 I]     mse = 0.24162666976451885\n",
            "[2024-10-23 17:26:16 I]     rmse = 0.4912300208133439\n",
            "[2024-10-23 17:26:16 I]     output_reg = 0.0\n",
            "[2024-10-23 17:26:16 I]     mae = 0.3843400211334231\n",
            "Training epochs:  78% 19499/25000 [06:13<01:46, 51.77it/s][2024-10-23 17:26:26 I] Starting validation at step 39000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 581.65it/s]\n",
            "[2024-10-23 17:26:26 I] Validation loop at step 39000:\n",
            "[2024-10-23 17:26:26 I]     loss = 0.2416670295238495\n",
            "[2024-10-23 17:26:26 I]     mse = 0.2416670295238495\n",
            "[2024-10-23 17:26:26 I]     rmse = 0.49127104354416584\n",
            "[2024-10-23 17:26:26 I]     output_reg = 0.0\n",
            "[2024-10-23 17:26:26 I]     mae = 0.3843816596984865\n",
            "Training epochs:  80% 19999/25000 [06:23<01:24, 59.00it/s][2024-10-23 17:26:35 I] Starting validation at step 40000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 893.00it/s]\n",
            "[2024-10-23 17:26:35 I] Validation loop at step 40000:\n",
            "[2024-10-23 17:26:35 I]     loss = 0.24164867310523996\n",
            "[2024-10-23 17:26:35 I]     mse = 0.24164867310523996\n",
            "[2024-10-23 17:26:35 I]     rmse = 0.4912523664540745\n",
            "[2024-10-23 17:26:35 I]     output_reg = 0.0\n",
            "[2024-10-23 17:26:35 I]     mae = 0.38435682697296153\n",
            "Training epochs:  82% 20499/25000 [06:32<01:17, 58.11it/s][2024-10-23 17:26:45 I] Starting validation at step 41000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 899.75it/s]\n",
            "[2024-10-23 17:26:45 I] Validation loop at step 41000:\n",
            "[2024-10-23 17:26:45 I]     loss = 0.24161128365993503\n",
            "[2024-10-23 17:26:45 I]     mse = 0.24161128365993503\n",
            "[2024-10-23 17:26:45 I]     rmse = 0.49121461935020017\n",
            "[2024-10-23 17:26:45 I]     output_reg = 0.0\n",
            "[2024-10-23 17:26:45 I]     mae = 0.3843407113075255\n",
            "Training epochs:  84% 21000/25000 [06:42<01:05, 61.06it/s][2024-10-23 17:26:55 I] Starting validation at step 42000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 843.13it/s]\n",
            "[2024-10-23 17:26:55 I] Validation loop at step 42000:\n",
            "[2024-10-23 17:26:55 I]     loss = 0.24168024621009826\n",
            "[2024-10-23 17:26:55 I]     mse = 0.24168024621009826\n",
            "[2024-10-23 17:26:55 I]     rmse = 0.4912848528985228\n",
            "[2024-10-23 17:26:55 I]     output_reg = 0.0\n",
            "[2024-10-23 17:26:55 I]     mae = 0.3843944147109985\n",
            "Training epochs:  86% 21495/25000 [06:52<01:02, 55.74it/s][2024-10-23 17:27:05 I] Starting validation at step 43000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 894.31it/s]\n",
            "[2024-10-23 17:27:05 I] Validation loop at step 43000:\n",
            "[2024-10-23 17:27:05 I]     loss = 0.24163927421569828\n",
            "[2024-10-23 17:27:05 I]     mse = 0.24163927421569828\n",
            "[2024-10-23 17:27:05 I]     rmse = 0.49124286037995063\n",
            "[2024-10-23 17:27:05 I]     output_reg = 0.0\n",
            "[2024-10-23 17:27:05 I]     mae = 0.38435148887634263\n",
            "Training epochs:  88% 21997/25000 [07:01<00:56, 52.89it/s][2024-10-23 17:27:14 I] Starting validation at step 44000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 587.59it/s]\n",
            "[2024-10-23 17:27:14 I] Validation loop at step 44000:\n",
            "[2024-10-23 17:27:14 I]     loss = 0.24161925036907192\n",
            "[2024-10-23 17:27:14 I]     mse = 0.24161925036907192\n",
            "[2024-10-23 17:27:14 I]     rmse = 0.49122253131753457\n",
            "[2024-10-23 17:27:14 I]     output_reg = 0.0\n",
            "[2024-10-23 17:27:14 I]     mae = 0.3843387662410737\n",
            "Training epochs:  90% 22499/25000 [07:11<00:41, 59.97it/s][2024-10-23 17:27:24 I] Starting validation at step 45000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 773.93it/s]\n",
            "[2024-10-23 17:27:24 I] Validation loop at step 45000:\n",
            "[2024-10-23 17:27:24 I]     loss = 0.24162691493034355\n",
            "[2024-10-23 17:27:24 I]     mse = 0.24162691493034355\n",
            "[2024-10-23 17:27:24 I]     rmse = 0.4912301122363011\n",
            "[2024-10-23 17:27:24 I]     output_reg = 0.0\n",
            "[2024-10-23 17:27:24 I]     mae = 0.3843463668823244\n",
            "Training epochs:  92% 22995/25000 [07:21<00:33, 60.14it/s][2024-10-23 17:27:33 I] Starting validation at step 46000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 866.83it/s]\n",
            "[2024-10-23 17:27:33 I] Validation loop at step 46000:\n",
            "[2024-10-23 17:27:33 I]     loss = 0.24164294631481173\n",
            "[2024-10-23 17:27:33 I]     mse = 0.24164294631481173\n",
            "[2024-10-23 17:27:33 I]     rmse = 0.4912465885028772\n",
            "[2024-10-23 17:27:33 I]     output_reg = 0.0\n",
            "[2024-10-23 17:27:33 I]     mae = 0.3843531550407411\n",
            "Training epochs:  94% 23498/25000 [07:30<00:24, 60.74it/s][2024-10-23 17:27:43 I] Starting validation at step 47000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 891.00it/s]\n",
            "[2024-10-23 17:27:43 I] Validation loop at step 47000:\n",
            "[2024-10-23 17:27:43 I]     loss = 0.2416432327985764\n",
            "[2024-10-23 17:27:43 I]     mse = 0.2416432327985764\n",
            "[2024-10-23 17:27:43 I]     rmse = 0.49124688000504474\n",
            "[2024-10-23 17:27:43 I]     output_reg = 0.0\n",
            "[2024-10-23 17:27:43 I]     mae = 0.3843533209800721\n",
            "Training epochs:  96% 23998/25000 [07:40<00:17, 57.66it/s][2024-10-23 17:27:52 I] Starting validation at step 48000\n",
            "\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 889.69it/s]\n",
            "[2024-10-23 17:27:53 I] Validation loop at step 48000:\n",
            "[2024-10-23 17:27:53 I]     loss = 0.24164117603302004\n",
            "[2024-10-23 17:27:53 I]     mse = 0.24164117603302004\n",
            "[2024-10-23 17:27:53 I]     rmse = 0.49124476690806845\n",
            "[2024-10-23 17:27:53 I]     output_reg = 0.0\n",
            "[2024-10-23 17:27:53 I]     mae = 0.3843521971702577\n",
            "Training epochs:  98% 24495/25000 [07:49<00:08, 61.21it/s][2024-10-23 17:28:02 I] Starting validation at step 49000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 783.65it/s]\n",
            "[2024-10-23 17:28:02 I] Validation loop at step 49000:\n",
            "[2024-10-23 17:28:02 I]     loss = 0.2416449021100997\n",
            "[2024-10-23 17:28:02 I]     mse = 0.2416449021100997\n",
            "[2024-10-23 17:28:02 I]     rmse = 0.49124855243351534\n",
            "[2024-10-23 17:28:02 I]     output_reg = 0.0\n",
            "[2024-10-23 17:28:02 I]     mae = 0.3843550191402436\n",
            "Training epochs: 100% 25000/25000 [07:59<00:00, 52.19it/s]\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 874.30it/s]\n",
            "[2024-10-23 17:28:11 I] Validation loop at step 50000:\n",
            "[2024-10-23 17:28:11 I]     loss = 0.24162901701927186\n",
            "[2024-10-23 17:28:11 I]     mse = 0.24162901701927186\n",
            "[2024-10-23 17:28:11 I]     rmse = 0.491232499020917\n",
            "[2024-10-23 17:28:11 I]     output_reg = 0.0\n",
            "[2024-10-23 17:28:11 I]     mae = 0.3843438043117523\n",
            "[2024-10-23 17:28:11 I] Early stopping after step 23000 with validation loss 0.24114035575389864\n",
            "[2024-10-23 17:28:11 I] Saving model at $/content/nbody_data/experiments/nbody/mlp100_50000/models/model_final.pt\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 874.46it/s]\n",
            "[2024-10-23 17:28:11 I] Ran evaluation on dataset eval:\n",
            "[2024-10-23 17:28:11 I]     loss = 0.2372561094284058\n",
            "[2024-10-23 17:28:11 I]     mse = 0.2372561094284058\n",
            "[2024-10-23 17:28:11 I]     rmse = 0.4867016005512179\n",
            "[2024-10-23 17:28:11 I]     output_reg = 0.0\n",
            "[2024-10-23 17:28:11 I]     mae = 0.3792950940608978\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 874.86it/s]\n",
            "[2024-10-23 17:28:11 I] Ran evaluation on dataset e3_generalization:\n",
            "[2024-10-23 17:28:11 I]     loss = 3.5076473533630375\n",
            "[2024-10-23 17:28:11 I]     mse = 3.5076473533630375\n",
            "[2024-10-23 17:28:11 I]     rmse = 1.8725573135663078\n",
            "[2024-10-23 17:28:11 I]     output_reg = 0.0\n",
            "[2024-10-23 17:28:11 I]     mae = 1.4967777526855472\n",
            "[2024-10-23 17:28:11 I] Anders nog iets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ordinary transformer"
      ],
      "metadata": {
        "id": "oyzTRWnLO7Td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=transformer_nbody data.subsample=0.001 training.steps=5000 run_name=transformer100_5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf2e11bf-92ba-46fc-d596-6ceb2f22467f",
        "id": "O0nQWniRO7Td"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 17:28:25 I] Hoi.\n",
            "[2024-10-23 17:28:25 I] Set experiment nbody with ID 1, artifact location file:/content/geometric-algebra-transformer/$/content/nbody_data/tracking/artifacts\n",
            "[2024-10-23 17:28:25 I] Logger already initialized - hi again!\n",
            "[2024-10-23 17:28:25 I] Running experiment at $/content/nbody_data/experiments/nbody/transformer100_5000\n",
            "[2024-10-23 17:28:25 I] Saving config at $/content/nbody_data/experiments/nbody/transformer100_5000/config.yml\n",
            "[2024-10-23 17:28:26 I] Model has 11.83M learnable parameters\n",
            "[2024-10-23 17:28:26 I] Starting training\n",
            "[2024-10-23 17:28:26 I] Training for 5000 steps, that is, 2500 epochs on a dataset of size 100 with batchsize 64\n",
            "Training epochs:   0% 0/2500 [00:00<?, ?it/s][2024-10-23 17:28:27 I] Finished first forward pass with loss 375.5052185058594\n",
            "Training epochs:  20% 499/2500 [00:30<01:47, 18.58it/s][2024-10-23 17:28:57 I] Starting validation at step 1000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 113.38it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 118.18it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 110.02it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 113.38it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 114.47it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.92it/s]\n",
            "[2024-10-23 17:28:57 I] Validation loop at step 1000:\n",
            "[2024-10-23 17:28:57 I]     loss = 0.23083340554237367\n",
            "[2024-10-23 17:28:57 I]     mse = 0.23083340554237367\n",
            "[2024-10-23 17:28:57 I]     rmse = 0.4568471639130132\n",
            "[2024-10-23 17:28:57 I]     output_reg = 0.0\n",
            "[2024-10-23 17:28:57 I]     mae = 0.22521378481388094\n",
            "Training epochs:  40% 999/2500 [01:01<01:35, 15.73it/s][2024-10-23 17:29:28 I] Starting validation at step 2000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  11% 9/79 [00:00<00:00, 89.62it/s]\u001b[A\n",
            "Evaluating:  24% 19/79 [00:00<00:00, 88.50it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:00<00:00, 88.27it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 91.32it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 91.98it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:00<00:00, 93.12it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:00<00:00, 87.81it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 86.37it/s]\n",
            "[2024-10-23 17:29:29 I] Validation loop at step 2000:\n",
            "[2024-10-23 17:29:29 I]     loss = 0.19970241683423526\n",
            "[2024-10-23 17:29:29 I]     mse = 0.19970241683423526\n",
            "[2024-10-23 17:29:29 I]     rmse = 0.42257233629607305\n",
            "[2024-10-23 17:29:29 I]     output_reg = 0.0\n",
            "[2024-10-23 17:29:29 I]     mae = 0.19764959986209865\n",
            "Training epochs:  60% 1499/2500 [01:32<00:53, 18.71it/s][2024-10-23 17:29:59 I] Starting validation at step 3000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 115.61it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 117.76it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 117.52it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 118.30it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 116.39it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.54it/s]\n",
            "[2024-10-23 17:29:59 I] Validation loop at step 3000:\n",
            "[2024-10-23 17:29:59 I]     loss = 0.18891560516953476\n",
            "[2024-10-23 17:29:59 I]     mse = 0.18891560516953476\n",
            "[2024-10-23 17:29:59 I]     rmse = 0.41059993508342135\n",
            "[2024-10-23 17:29:59 I]     output_reg = 0.0\n",
            "[2024-10-23 17:29:59 I]     mae = 0.19321322166919702\n",
            "Training epochs:  80% 1999/2500 [02:02<00:27, 18.19it/s][2024-10-23 17:30:29 I] Starting validation at step 4000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 123.92it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 121.00it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 120.21it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:00<00:00, 119.09it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 113.67it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 109.00it/s]\n",
            "[2024-10-23 17:30:30 I] Validation loop at step 4000:\n",
            "[2024-10-23 17:30:30 I]     loss = 0.1836296135365963\n",
            "[2024-10-23 17:30:30 I]     mse = 0.1836296135365963\n",
            "[2024-10-23 17:30:30 I]     rmse = 0.40468260239474496\n",
            "[2024-10-23 17:30:30 I]     output_reg = 0.0\n",
            "[2024-10-23 17:30:30 I]     mae = 0.19121588144302368\n",
            "Training epochs: 100% 2500/2500 [02:33<00:00, 16.27it/s]\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.71it/s]\n",
            "[2024-10-23 17:31:00 I] Validation loop at step 5000:\n",
            "[2024-10-23 17:31:00 I]     loss = 0.18091755864024162\n",
            "[2024-10-23 17:31:00 I]     mse = 0.18091755864024162\n",
            "[2024-10-23 17:31:00 I]     rmse = 0.4016115236759564\n",
            "[2024-10-23 17:31:00 I]     output_reg = 0.0\n",
            "[2024-10-23 17:31:00 I]     mae = 0.19034714467525476\n",
            "[2024-10-23 17:31:00 I] Saving model at $/content/nbody_data/experiments/nbody/transformer100_5000/models/model_final.pt\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.06it/s]\n",
            "[2024-10-23 17:31:01 I] Ran evaluation on dataset object_generalization:\n",
            "[2024-10-23 17:31:01 I]     loss = 0.1384066235661507\n",
            "[2024-10-23 17:31:01 I]     mse = 0.1384066235661507\n",
            "[2024-10-23 17:31:01 I]     rmse = 0.3595891708093122\n",
            "[2024-10-23 17:31:01 I]     output_reg = 0.0\n",
            "[2024-10-23 17:31:01 I]     mae = 0.18302724750041963\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.15it/s]\n",
            "[2024-10-23 17:31:02 I] Ran evaluation on dataset e3_generalization:\n",
            "[2024-10-23 17:31:02 I]     loss = 1041.880662304688\n",
            "[2024-10-23 17:31:02 I]     mse = 1041.880662304688\n",
            "[2024-10-23 17:31:02 I]     rmse = 32.27209350334863\n",
            "[2024-10-23 17:31:02 I]     output_reg = 0.0\n",
            "[2024-10-23 17:31:02 I]     mae = 21.59848073425293\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.17it/s]\n",
            "[2024-10-23 17:31:03 I] Ran evaluation on dataset eval:\n",
            "[2024-10-23 17:31:03 I]     loss = 0.15445799375772476\n",
            "[2024-10-23 17:31:03 I]     mse = 0.15445799375772476\n",
            "[2024-10-23 17:31:03 I]     rmse = 0.3730089556662861\n",
            "[2024-10-23 17:31:03 I]     output_reg = 0.0\n",
            "[2024-10-23 17:31:03 I]     mae = 0.1825844635009766\n",
            "[2024-10-23 17:31:03 I] Anders nog iets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=transformer_nbody data.subsample=0.001 training.steps=20000 run_name=transformer100_20000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "728384a0-d3e0-4eb2-b3d9-40c9984df443",
        "id": "PYqOephzO7Te"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 17:33:19 I] Hoi.\n",
            "[2024-10-23 17:33:19 I] Set experiment nbody with ID 1, artifact location file:/content/geometric-algebra-transformer/$/content/nbody_data/tracking/artifacts\n",
            "[2024-10-23 17:33:19 I] Logger already initialized - hi again!\n",
            "[2024-10-23 17:33:19 I] Running experiment at $/content/nbody_data/experiments/nbody/transformer100_20000\n",
            "[2024-10-23 17:33:19 I] Saving config at $/content/nbody_data/experiments/nbody/transformer100_20000/config.yml\n",
            "[2024-10-23 17:33:20 I] Model has 11.83M learnable parameters\n",
            "[2024-10-23 17:33:20 I] Starting training\n",
            "[2024-10-23 17:33:20 I] Training for 20000 steps, that is, 10000 epochs on a dataset of size 100 with batchsize 64\n",
            "Training epochs:   0% 0/10000 [00:00<?, ?it/s][2024-10-23 17:33:21 I] Finished first forward pass with loss 375.5052185058594\n",
            "Training epochs:   5% 499/10000 [00:30<09:16, 17.07it/s][2024-10-23 17:33:51 I] Starting validation at step 1000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 110.97it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 114.59it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 114.89it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 111.97it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 114.47it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.36it/s]\n",
            "[2024-10-23 17:33:52 I] Validation loop at step 1000:\n",
            "[2024-10-23 17:33:52 I]     loss = 0.23083340554237367\n",
            "[2024-10-23 17:33:52 I]     mse = 0.23083340554237367\n",
            "[2024-10-23 17:33:52 I]     rmse = 0.4568471639130132\n",
            "[2024-10-23 17:33:52 I]     output_reg = 0.0\n",
            "[2024-10-23 17:33:52 I]     mae = 0.22521378481388094\n",
            "Training epochs:  10% 999/10000 [01:01<08:31, 17.58it/s][2024-10-23 17:34:21 I] Starting validation at step 2000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  14% 11/79 [00:00<00:00, 108.85it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 116.36it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 118.87it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 114.24it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 116.02it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.58it/s]\n",
            "[2024-10-23 17:34:22 I] Validation loop at step 2000:\n",
            "[2024-10-23 17:34:22 I]     loss = 0.18359232307672493\n",
            "[2024-10-23 17:34:22 I]     mse = 0.18359232307672493\n",
            "[2024-10-23 17:34:22 I]     rmse = 0.4053869235186509\n",
            "[2024-10-23 17:34:22 I]     output_reg = 0.0\n",
            "[2024-10-23 17:34:22 I]     mae = 0.19900300214290612\n",
            "Training epochs:  15% 1499/10000 [01:32<10:13, 13.85it/s][2024-10-23 17:34:53 I] Starting validation at step 3000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 108.79it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 111.00it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 112.01it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 112.59it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 114.32it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 113.90it/s]\n",
            "[2024-10-23 17:34:54 I] Validation loop at step 3000:\n",
            "[2024-10-23 17:34:54 I]     loss = 0.14258979902267463\n",
            "[2024-10-23 17:34:54 I]     mse = 0.14258979902267463\n",
            "[2024-10-23 17:34:54 I]     rmse = 0.35482001689965303\n",
            "[2024-10-23 17:34:54 I]     output_reg = 0.0\n",
            "[2024-10-23 17:34:54 I]     mae = 0.16845430552959437\n",
            "Training epochs:  20% 1999/10000 [02:02<07:35, 17.55it/s][2024-10-23 17:35:23 I] Starting validation at step 4000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 122.77it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 122.60it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 119.95it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:00<00:00, 120.30it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:00<00:00, 119.53it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.46it/s]\n",
            "[2024-10-23 17:35:24 I] Validation loop at step 4000:\n",
            "[2024-10-23 17:35:24 I]     loss = 0.1274502852886915\n",
            "[2024-10-23 17:35:24 I]     mse = 0.1274502852886915\n",
            "[2024-10-23 17:35:24 I]     rmse = 0.33530588655375954\n",
            "[2024-10-23 17:35:24 I]     output_reg = 0.0\n",
            "[2024-10-23 17:35:24 I]     mae = 0.16188092446327212\n",
            "Training epochs:  25% 2499/10000 [02:33<08:30, 14.69it/s][2024-10-23 17:35:54 I] Starting validation at step 5000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  11% 9/79 [00:00<00:00, 84.25it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:00<00:00, 76.82it/s]\u001b[A\n",
            "Evaluating:  34% 27/79 [00:00<00:00, 78.08it/s]\u001b[A\n",
            "Evaluating:  44% 35/79 [00:00<00:00, 76.03it/s]\u001b[A\n",
            "Evaluating:  54% 43/79 [00:00<00:00, 77.23it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:00<00:00, 78.04it/s]\u001b[A\n",
            "Evaluating:  75% 59/79 [00:00<00:00, 78.61it/s]\u001b[A\n",
            "Evaluating:  85% 67/79 [00:00<00:00, 77.17it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:01<00:00, 77.36it/s]\n",
            "[2024-10-23 17:35:55 I] Validation loop at step 5000:\n",
            "[2024-10-23 17:35:55 I]     loss = 0.11592042936980727\n",
            "[2024-10-23 17:35:55 I]     mse = 0.11592042936980727\n",
            "[2024-10-23 17:35:55 I]     rmse = 0.31939610059584994\n",
            "[2024-10-23 17:35:55 I]     output_reg = 0.0\n",
            "[2024-10-23 17:35:55 I]     mae = 0.15439884696006778\n",
            "Training epochs:  30% 2999/10000 [03:04<06:18, 18.51it/s][2024-10-23 17:36:24 I] Starting validation at step 6000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  14% 11/79 [00:00<00:00, 106.76it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 115.09it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 116.83it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 117.58it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 116.47it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.76it/s]\n",
            "[2024-10-23 17:36:25 I] Validation loop at step 6000:\n",
            "[2024-10-23 17:36:25 I]     loss = 0.10985081069469455\n",
            "[2024-10-23 17:36:25 I]     mse = 0.10985081069469455\n",
            "[2024-10-23 17:36:25 I]     rmse = 0.3105867904157202\n",
            "[2024-10-23 17:36:25 I]     output_reg = 0.0\n",
            "[2024-10-23 17:36:25 I]     mae = 0.1511590951681137\n",
            "Training epochs:  35% 3499/10000 [03:35<07:36, 14.25it/s][2024-10-23 17:36:56 I] Starting validation at step 7000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:00, 93.36it/s]\u001b[A\n",
            "Evaluating:  25% 20/79 [00:00<00:00, 92.21it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:00<00:00, 84.90it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 52.87it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:00<00:00, 48.92it/s]\u001b[A\n",
            "Evaluating:  67% 53/79 [00:00<00:00, 53.28it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:01<00:00, 58.94it/s]\u001b[A\n",
            "Evaluating:  87% 69/79 [00:01<00:00, 62.39it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:01<00:00, 63.40it/s]\n",
            "[2024-10-23 17:36:57 I] Validation loop at step 7000:\n",
            "[2024-10-23 17:36:57 I]     loss = 0.10195779061913492\n",
            "[2024-10-23 17:36:57 I]     mse = 0.10195779061913492\n",
            "[2024-10-23 17:36:57 I]     rmse = 0.2993993751421667\n",
            "[2024-10-23 17:36:57 I]     output_reg = 0.0\n",
            "[2024-10-23 17:36:57 I]     mae = 0.14768111804723738\n",
            "Training epochs:  40% 4000/10000 [04:08<06:00, 16.65it/s][2024-10-23 17:37:28 I] Starting validation at step 8000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 117.83it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 119.92it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 104.21it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 109.31it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 111.37it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 96.45it/s]\n",
            "[2024-10-23 17:37:29 I] Validation loop at step 8000:\n",
            "[2024-10-23 17:37:29 I]     loss = 0.09865992119014262\n",
            "[2024-10-23 17:37:29 I]     mse = 0.09865992119014262\n",
            "[2024-10-23 17:37:29 I]     rmse = 0.2946638393355659\n",
            "[2024-10-23 17:37:29 I]     output_reg = 0.0\n",
            "[2024-10-23 17:37:29 I]     mae = 0.14664061632156378\n",
            "Training epochs:  45% 4500/10000 [04:41<05:26, 16.84it/s][2024-10-23 17:38:01 I] Starting validation at step 9000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 120.79it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 120.35it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 119.50it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:00<00:00, 117.85it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 118.41it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 118.28it/s]\n",
            "[2024-10-23 17:38:02 I] Validation loop at step 9000:\n",
            "[2024-10-23 17:38:02 I]     loss = 0.09389349764883514\n",
            "[2024-10-23 17:38:02 I]     mse = 0.09389349764883514\n",
            "[2024-10-23 17:38:02 I]     rmse = 0.2871903892224088\n",
            "[2024-10-23 17:38:02 I]     output_reg = 0.0\n",
            "[2024-10-23 17:38:02 I]     mae = 0.14370107123851783\n",
            "Training epochs:  50% 5000/10000 [05:11<04:26, 18.74it/s][2024-10-23 17:38:32 I] Starting validation at step 10000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 122.64it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 118.92it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 111.58it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 113.01it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 114.57it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.40it/s]\n",
            "[2024-10-23 17:38:32 I] Validation loop at step 10000:\n",
            "[2024-10-23 17:38:32 I]     loss = 0.09156380888819694\n",
            "[2024-10-23 17:38:32 I]     mse = 0.09156380888819694\n",
            "[2024-10-23 17:38:32 I]     rmse = 0.2832437646577983\n",
            "[2024-10-23 17:38:32 I]     output_reg = 0.0\n",
            "[2024-10-23 17:38:32 I]     mae = 0.14225579670667649\n",
            "Training epochs:  55% 5499/10000 [05:43<04:16, 17.58it/s][2024-10-23 17:39:04 I] Starting validation at step 11000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 121.11it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 122.45it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 120.06it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:00<00:00, 119.61it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 116.74it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.36it/s]\n",
            "[2024-10-23 17:39:05 I] Validation loop at step 11000:\n",
            "[2024-10-23 17:39:05 I]     loss = 0.09015421008467675\n",
            "[2024-10-23 17:39:05 I]     mse = 0.09015421008467675\n",
            "[2024-10-23 17:39:05 I]     rmse = 0.28136207190797585\n",
            "[2024-10-23 17:39:05 I]     output_reg = 0.0\n",
            "[2024-10-23 17:39:05 I]     mae = 0.14215874713659293\n",
            "Training epochs:  60% 5999/10000 [06:14<03:33, 18.75it/s][2024-10-23 17:39:35 I] Starting validation at step 12000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 113.57it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 118.04it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 117.83it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 116.71it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 117.31it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.95it/s]\n",
            "[2024-10-23 17:39:35 I] Validation loop at step 12000:\n",
            "[2024-10-23 17:39:35 I]     loss = 0.08944066885113718\n",
            "[2024-10-23 17:39:35 I]     mse = 0.08944066885113718\n",
            "[2024-10-23 17:39:35 I]     rmse = 0.28060306919888056\n",
            "[2024-10-23 17:39:35 I]     output_reg = 0.0\n",
            "[2024-10-23 17:39:35 I]     mae = 0.14428675823211665\n",
            "Training epochs:  65% 6499/10000 [06:46<03:12, 18.18it/s][2024-10-23 17:40:07 I] Starting validation at step 13000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 115.45it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 118.27it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 118.97it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 118.24it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 116.66it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 117.01it/s]\n",
            "[2024-10-23 17:40:07 I] Validation loop at step 13000:\n",
            "[2024-10-23 17:40:07 I]     loss = 0.08874372485876086\n",
            "[2024-10-23 17:40:07 I]     mse = 0.08874372485876086\n",
            "[2024-10-23 17:40:07 I]     rmse = 0.27973458329897694\n",
            "[2024-10-23 17:40:07 I]     output_reg = 0.0\n",
            "[2024-10-23 17:40:07 I]     mae = 0.14510945458412172\n",
            "Training epochs:  70% 6999/10000 [07:16<02:45, 18.16it/s][2024-10-23 17:40:37 I] Starting validation at step 14000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 120.60it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 117.89it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 119.11it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:00<00:00, 116.60it/s]\u001b[A\n",
            "Evaluating:  80% 63/79 [00:00<00:00, 116.95it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.43it/s]\n",
            "[2024-10-23 17:40:37 I] Validation loop at step 14000:\n",
            "[2024-10-23 17:40:37 I]     loss = 0.09079808620810512\n",
            "[2024-10-23 17:40:37 I]     mse = 0.09079808620810512\n",
            "[2024-10-23 17:40:37 I]     rmse = 0.2840244157112099\n",
            "[2024-10-23 17:40:37 I]     output_reg = 0.0\n",
            "[2024-10-23 17:40:37 I]     mae = 0.15067029325962064\n",
            "Training epochs:  75% 7499/10000 [07:46<03:17, 12.69it/s][2024-10-23 17:41:07 I] Starting validation at step 15000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  14% 11/79 [00:00<00:00, 107.34it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 116.60it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 118.80it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 118.89it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 119.73it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 117.86it/s]\n",
            "[2024-10-23 17:41:08 I] Validation loop at step 15000:\n",
            "[2024-10-23 17:41:08 I]     loss = 0.09483067799806597\n",
            "[2024-10-23 17:41:08 I]     mse = 0.09483067799806597\n",
            "[2024-10-23 17:41:08 I]     rmse = 0.29194561866750424\n",
            "[2024-10-23 17:41:08 I]     output_reg = 0.0\n",
            "[2024-10-23 17:41:08 I]     mae = 0.15824102891683578\n",
            "Training epochs:  80% 7999/10000 [08:16<01:49, 18.25it/s][2024-10-23 17:41:37 I] Starting validation at step 16000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 122.26it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 121.41it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 119.81it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:00<00:00, 120.63it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:00<00:00, 119.34it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 119.03it/s]\n",
            "[2024-10-23 17:41:38 I] Validation loop at step 16000:\n",
            "[2024-10-23 17:41:38 I]     loss = 0.09866193221211435\n",
            "[2024-10-23 17:41:38 I]     mse = 0.09866193221211435\n",
            "[2024-10-23 17:41:38 I]     rmse = 0.29893391131023683\n",
            "[2024-10-23 17:41:38 I]     output_reg = 0.0\n",
            "[2024-10-23 17:41:38 I]     mae = 0.16379219260215758\n",
            "Training epochs:  85% 8499/10000 [08:47<01:46, 14.06it/s][2024-10-23 17:42:08 I] Starting validation at step 17000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:00, 72.11it/s]\u001b[A\n",
            "Evaluating:  22% 17/79 [00:00<00:00, 75.79it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 76.46it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:00<00:00, 77.81it/s]\u001b[A\n",
            "Evaluating:  53% 42/79 [00:00<00:00, 77.33it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:00<00:00, 78.62it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 79.72it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:00<00:00, 78.54it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:01<00:00, 77.04it/s]\n",
            "[2024-10-23 17:42:09 I] Validation loop at step 17000:\n",
            "[2024-10-23 17:42:09 I]     loss = 0.09884727437496185\n",
            "[2024-10-23 17:42:09 I]     mse = 0.09884727437496185\n",
            "[2024-10-23 17:42:09 I]     rmse = 0.2994006049058743\n",
            "[2024-10-23 17:42:09 I]     output_reg = 0.0\n",
            "[2024-10-23 17:42:09 I]     mae = 0.16478662159442903\n",
            "Training epochs:  90% 8999/10000 [09:18<00:54, 18.40it/s][2024-10-23 17:42:38 I] Starting validation at step 18000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  14% 11/79 [00:00<00:00, 108.10it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 115.08it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 113.50it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 112.52it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 113.87it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.01it/s]\n",
            "[2024-10-23 17:42:39 I] Validation loop at step 18000:\n",
            "[2024-10-23 17:42:39 I]     loss = 0.09814564664363856\n",
            "[2024-10-23 17:42:39 I]     mse = 0.09814564664363856\n",
            "[2024-10-23 17:42:39 I]     rmse = 0.2983002039665986\n",
            "[2024-10-23 17:42:39 I]     output_reg = 0.0\n",
            "[2024-10-23 17:42:39 I]     mae = 0.16442459580898286\n",
            "Training epochs:  95% 9499/10000 [09:48<00:31, 16.11it/s][2024-10-23 17:43:09 I] Starting validation at step 19000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:00, 78.00it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:00<00:00, 85.74it/s]\u001b[A\n",
            "Evaluating:  34% 27/79 [00:00<00:00, 82.26it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 84.65it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:00<00:00, 87.71it/s]\u001b[A\n",
            "Evaluating:  71% 56/79 [00:00<00:00, 89.78it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:00<00:00, 85.52it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 83.49it/s]\n",
            "[2024-10-23 17:43:10 I] Validation loop at step 19000:\n",
            "[2024-10-23 17:43:10 I]     loss = 0.09774484812617308\n",
            "[2024-10-23 17:43:10 I]     mse = 0.09774484812617308\n",
            "[2024-10-23 17:43:10 I]     rmse = 0.2976712989936245\n",
            "[2024-10-23 17:43:10 I]     output_reg = 0.0\n",
            "[2024-10-23 17:43:10 I]     mae = 0.16435579990148544\n",
            "Training epochs: 100% 10000/10000 [10:19<00:00, 16.13it/s]\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 112.15it/s]\n",
            "[2024-10-23 17:43:41 I] Validation loop at step 20000:\n",
            "[2024-10-23 17:43:41 I]     loss = 0.09775275341868404\n",
            "[2024-10-23 17:43:41 I]     mse = 0.09775275341868404\n",
            "[2024-10-23 17:43:41 I]     rmse = 0.2977254503081877\n",
            "[2024-10-23 17:43:41 I]     output_reg = 0.0\n",
            "[2024-10-23 17:43:41 I]     mae = 0.16459053289890294\n",
            "[2024-10-23 17:43:41 I] Early stopping after step 13000 with validation loss 0.08874372485876086\n",
            "[2024-10-23 17:43:41 I] Saving model at $/content/nbody_data/experiments/nbody/transformer100_20000/models/model_final.pt\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 111.93it/s]\n",
            "[2024-10-23 17:43:42 I] Ran evaluation on dataset object_generalization:\n",
            "[2024-10-23 17:43:42 I]     loss = 0.08182250019311907\n",
            "[2024-10-23 17:43:42 I]     mse = 0.08182250019311907\n",
            "[2024-10-23 17:43:42 I]     rmse = 0.2814989642174418\n",
            "[2024-10-23 17:43:42 I]     output_reg = 0.0\n",
            "[2024-10-23 17:43:42 I]     mae = 0.16679008808135987\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.38it/s]\n",
            "[2024-10-23 17:43:42 I] Ran evaluation on dataset eval:\n",
            "[2024-10-23 17:43:42 I]     loss = 0.08120962335169316\n",
            "[2024-10-23 17:43:42 I]     mse = 0.08120962335169316\n",
            "[2024-10-23 17:43:42 I]     rmse = 0.2766174855908482\n",
            "[2024-10-23 17:43:42 I]     output_reg = 0.0\n",
            "[2024-10-23 17:43:42 I]     mae = 0.1592028067946435\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 117.43it/s]\n",
            "[2024-10-23 17:43:43 I] Ran evaluation on dataset e3_generalization:\n",
            "[2024-10-23 17:43:43 I]     loss = 614.5716083496092\n",
            "[2024-10-23 17:43:43 I]     mse = 614.5716083496092\n",
            "[2024-10-23 17:43:43 I]     rmse = 24.78520708167794\n",
            "[2024-10-23 17:43:43 I]     output_reg = 0.0\n",
            "[2024-10-23 17:43:43 I]     mae = 16.7557491760254\n",
            "[2024-10-23 17:43:43 I] Anders nog iets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/nbody_experiment.py base_dir=\"${BASEDIR}\" seed=42 model=transformer_nbody data.subsample=0.001 training.steps=50000 run_name=transformer100_50000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10103944-d2cd-457e-a091-96ea7f5587ff",
        "id": "_T8cRuBxO7Te"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/geometric-algebra-transformer/gatr/primitives/bilinear.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_basis = torch.load(filename).to(torch.float32)\n",
            "[2024-10-23 17:43:51 I] Hoi.\n",
            "[2024-10-23 17:43:52 I] Set experiment nbody with ID 1, artifact location file:/content/geometric-algebra-transformer/$/content/nbody_data/tracking/artifacts\n",
            "[2024-10-23 17:43:52 I] Logger already initialized - hi again!\n",
            "[2024-10-23 17:43:52 I] Running experiment at $/content/nbody_data/experiments/nbody/transformer100_50000\n",
            "[2024-10-23 17:43:52 I] Saving config at $/content/nbody_data/experiments/nbody/transformer100_50000/config.yml\n",
            "[2024-10-23 17:43:52 I] Model has 11.83M learnable parameters\n",
            "[2024-10-23 17:43:52 I] Starting training\n",
            "[2024-10-23 17:43:53 I] Training for 50000 steps, that is, 25000 epochs on a dataset of size 100 with batchsize 64\n",
            "Training epochs:   0% 0/25000 [00:00<?, ?it/s][2024-10-23 17:43:53 I] Finished first forward pass with loss 375.5052185058594\n",
            "Training epochs:   2% 499/25000 [00:30<22:40, 18.01it/s][2024-10-23 17:44:23 I] Starting validation at step 1000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  14% 11/79 [00:00<00:00, 108.68it/s]\u001b[A\n",
            "Evaluating:  29% 23/79 [00:00<00:00, 112.90it/s]\u001b[A\n",
            "Evaluating:  44% 35/79 [00:00<00:00, 106.83it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:00<00:00, 90.90it/s] \u001b[A\n",
            "Evaluating:  71% 56/79 [00:00<00:00, 86.96it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:00<00:00, 86.13it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 90.99it/s]\n",
            "[2024-10-23 17:44:24 I] Validation loop at step 1000:\n",
            "[2024-10-23 17:44:24 I]     loss = 0.23083340554237367\n",
            "[2024-10-23 17:44:24 I]     mse = 0.23083340554237367\n",
            "[2024-10-23 17:44:24 I]     rmse = 0.4568471639130132\n",
            "[2024-10-23 17:44:24 I]     output_reg = 0.0\n",
            "[2024-10-23 17:44:24 I]     mae = 0.22521378481388094\n",
            "Training epochs:   4% 999/25000 [01:01<21:45, 18.39it/s][2024-10-23 17:44:54 I] Starting validation at step 2000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  14% 11/79 [00:00<00:00, 108.45it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 115.65it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 117.49it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 118.73it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 118.67it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 117.11it/s]\n",
            "[2024-10-23 17:44:55 I] Validation loop at step 2000:\n",
            "[2024-10-23 17:44:55 I]     loss = 0.16793868510425097\n",
            "[2024-10-23 17:44:55 I]     mse = 0.16793868510425097\n",
            "[2024-10-23 17:44:55 I]     rmse = 0.3873707836420934\n",
            "[2024-10-23 17:44:55 I]     output_reg = 0.0\n",
            "[2024-10-23 17:44:55 I]     mae = 0.18384597041606912\n",
            "Training epochs:   6% 1499/25000 [01:32<21:12, 18.46it/s][2024-10-23 17:45:25 I] Starting validation at step 3000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  14% 11/79 [00:00<00:00, 99.51it/s]\u001b[A\n",
            "Evaluating:  27% 21/79 [00:00<00:00, 84.90it/s]\u001b[A\n",
            "Evaluating:  38% 30/79 [00:00<00:00, 84.11it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 84.65it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 83.66it/s]\u001b[A\n",
            "Evaluating:  72% 57/79 [00:00<00:00, 84.74it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:00<00:00, 86.07it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 85.47it/s]\n",
            "[2024-10-23 17:45:26 I] Validation loop at step 3000:\n",
            "[2024-10-23 17:45:26 I]     loss = 0.11803650226294995\n",
            "[2024-10-23 17:45:26 I]     mse = 0.11803650226294995\n",
            "[2024-10-23 17:45:26 I]     rmse = 0.3221963951251365\n",
            "[2024-10-23 17:45:26 I]     output_reg = 0.0\n",
            "[2024-10-23 17:45:26 I]     mae = 0.15228557481765748\n",
            "Training epochs:   8% 1999/25000 [02:03<20:38, 18.57it/s][2024-10-23 17:45:57 I] Starting validation at step 4000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 115.68it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 112.62it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 114.90it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 116.80it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 117.58it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.17it/s]\n",
            "[2024-10-23 17:45:57 I] Validation loop at step 4000:\n",
            "[2024-10-23 17:45:57 I]     loss = 0.09134642893671989\n",
            "[2024-10-23 17:45:57 I]     mse = 0.09134642893671989\n",
            "[2024-10-23 17:45:57 I]     rmse = 0.2835295989680359\n",
            "[2024-10-23 17:45:57 I]     output_reg = 0.0\n",
            "[2024-10-23 17:45:57 I]     mae = 0.14274460716247556\n",
            "Training epochs:  10% 2499/25000 [02:34<20:26, 18.35it/s][2024-10-23 17:46:27 I] Starting validation at step 5000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 121.18it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 121.83it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 122.33it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:00<00:00, 113.79it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 114.72it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 110.83it/s]\n",
            "[2024-10-23 17:46:28 I] Validation loop at step 5000:\n",
            "[2024-10-23 17:46:28 I]     loss = 0.07149111713171002\n",
            "[2024-10-23 17:46:28 I]     mse = 0.07149111713171002\n",
            "[2024-10-23 17:46:28 I]     rmse = 0.2500496229388675\n",
            "[2024-10-23 17:46:28 I]     output_reg = 0.0\n",
            "[2024-10-23 17:46:28 I]     mae = 0.12174741289615634\n",
            "Training epochs:  12% 2999/25000 [03:05<19:56, 18.39it/s][2024-10-23 17:46:58 I] Starting validation at step 6000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  13% 10/79 [00:00<00:00, 99.00it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:00<00:00, 110.46it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:00<00:00, 110.51it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:00<00:00, 112.95it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:00<00:00, 115.15it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.45it/s]\n",
            "[2024-10-23 17:46:59 I] Validation loop at step 6000:\n",
            "[2024-10-23 17:46:59 I]     loss = 0.05976727816313506\n",
            "[2024-10-23 17:46:59 I]     mse = 0.05976727816313506\n",
            "[2024-10-23 17:46:59 I]     rmse = 0.22893374683058726\n",
            "[2024-10-23 17:46:59 I]     output_reg = 0.0\n",
            "[2024-10-23 17:46:59 I]     mae = 0.1136457837343216\n",
            "Training epochs:  14% 3499/25000 [03:35<19:50, 18.05it/s][2024-10-23 17:47:29 I] Starting validation at step 7000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 117.70it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 117.61it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 116.27it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 116.69it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 116.60it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.58it/s]\n",
            "[2024-10-23 17:47:30 I] Validation loop at step 7000:\n",
            "[2024-10-23 17:47:30 I]     loss = 0.0536521018266678\n",
            "[2024-10-23 17:47:30 I]     mse = 0.0536521018266678\n",
            "[2024-10-23 17:47:30 I]     rmse = 0.21797927407561882\n",
            "[2024-10-23 17:47:30 I]     output_reg = 0.0\n",
            "[2024-10-23 17:47:30 I]     mae = 0.11178850587606431\n",
            "Training epochs:  16% 3999/25000 [04:06<19:13, 18.20it/s][2024-10-23 17:48:00 I] Starting validation at step 8000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 116.47it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 118.87it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 116.54it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 117.21it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 114.07it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.20it/s]\n",
            "[2024-10-23 17:48:01 I] Validation loop at step 8000:\n",
            "[2024-10-23 17:48:01 I]     loss = 0.05064439503550531\n",
            "[2024-10-23 17:48:01 I]     mse = 0.05064439503550531\n",
            "[2024-10-23 17:48:01 I]     rmse = 0.21219726859158097\n",
            "[2024-10-23 17:48:01 I]     output_reg = 0.0\n",
            "[2024-10-23 17:48:01 I]     mae = 0.10945793821811675\n",
            "Training epochs:  18% 4499/25000 [04:37<18:44, 18.23it/s][2024-10-23 17:48:30 I] Starting validation at step 9000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 119.70it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 118.26it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 112.99it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 113.94it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 115.77it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.13it/s]\n",
            "[2024-10-23 17:48:31 I] Validation loop at step 9000:\n",
            "[2024-10-23 17:48:31 I]     loss = 0.040899045792222026\n",
            "[2024-10-23 17:48:31 I]     mse = 0.040899045792222026\n",
            "[2024-10-23 17:48:31 I]     rmse = 0.1901810466259001\n",
            "[2024-10-23 17:48:31 I]     output_reg = 0.0\n",
            "[2024-10-23 17:48:31 I]     mae = 0.09557831912040712\n",
            "Training epochs:  20% 4999/25000 [05:07<17:54, 18.61it/s][2024-10-23 17:49:01 I] Starting validation at step 10000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 122.78it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 115.28it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 114.66it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 115.36it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 115.41it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.16it/s]\n",
            "[2024-10-23 17:49:01 I] Validation loop at step 10000:\n",
            "[2024-10-23 17:49:01 I]     loss = 0.03515497938096523\n",
            "[2024-10-23 17:49:01 I]     mse = 0.03515497938096523\n",
            "[2024-10-23 17:49:01 I]     rmse = 0.176916793215946\n",
            "[2024-10-23 17:49:01 I]     output_reg = 0.0\n",
            "[2024-10-23 17:49:01 I]     mae = 0.0905025768637657\n",
            "Training epochs:  22% 5499/25000 [05:37<17:18, 18.78it/s][2024-10-23 17:49:31 I] Starting validation at step 11000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 120.58it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 119.00it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 118.00it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 117.07it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 116.93it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.36it/s]\n",
            "[2024-10-23 17:49:31 I] Validation loop at step 11000:\n",
            "[2024-10-23 17:49:31 I]     loss = 0.03354895343035459\n",
            "[2024-10-23 17:49:31 I]     mse = 0.03354895343035459\n",
            "[2024-10-23 17:49:31 I]     rmse = 0.17367318124879189\n",
            "[2024-10-23 17:49:32 I]     output_reg = 0.0\n",
            "[2024-10-23 17:49:32 I]     mae = 0.09213893069028854\n",
            "Training epochs:  24% 5999/25000 [06:08<17:50, 17.75it/s][2024-10-23 17:50:02 I] Starting validation at step 12000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 106.83it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 109.74it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 113.71it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 114.50it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 115.75it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.80it/s]\n",
            "[2024-10-23 17:50:02 I] Validation loop at step 12000:\n",
            "[2024-10-23 17:50:02 I]     loss = 0.03398575445711613\n",
            "[2024-10-23 17:50:02 I]     mse = 0.03398575445711613\n",
            "[2024-10-23 17:50:02 I]     rmse = 0.1757773562388315\n",
            "[2024-10-23 17:50:02 I]     output_reg = 0.0\n",
            "[2024-10-23 17:50:02 I]     mae = 0.09478736261129382\n",
            "Training epochs:  26% 6499/25000 [06:39<17:26, 17.68it/s][2024-10-23 17:50:33 I] Starting validation at step 13000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 118.12it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 114.28it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 115.64it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 115.33it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 116.58it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 117.07it/s]\n",
            "[2024-10-23 17:50:33 I] Validation loop at step 13000:\n",
            "[2024-10-23 17:50:33 I]     loss = 0.031468442305922516\n",
            "[2024-10-23 17:50:33 I]     mse = 0.031468442305922516\n",
            "[2024-10-23 17:50:33 I]     rmse = 0.16918880218796498\n",
            "[2024-10-23 17:50:33 I]     output_reg = 0.0\n",
            "[2024-10-23 17:50:33 I]     mae = 0.09194598363637925\n",
            "Training epochs:  28% 6999/25000 [07:10<16:32, 18.14it/s][2024-10-23 17:51:03 I] Starting validation at step 14000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 119.88it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 120.88it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 118.38it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:00<00:00, 119.70it/s]\u001b[A\n",
            "Evaluating:  80% 63/79 [00:00<00:00, 118.83it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 118.14it/s]\n",
            "[2024-10-23 17:51:04 I] Validation loop at step 14000:\n",
            "[2024-10-23 17:51:04 I]     loss = 0.03131421117186548\n",
            "[2024-10-23 17:51:04 I]     mse = 0.03131421117186548\n",
            "[2024-10-23 17:51:04 I]     rmse = 0.16927723963861296\n",
            "[2024-10-23 17:51:04 I]     output_reg = 0.0\n",
            "[2024-10-23 17:51:04 I]     mae = 0.09292622942924497\n",
            "Training epochs:  30% 7499/25000 [07:40<15:38, 18.64it/s][2024-10-23 17:51:34 I] Starting validation at step 15000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 119.16it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 119.90it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 117.27it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 113.24it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 114.30it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.02it/s]\n",
            "[2024-10-23 17:51:34 I] Validation loop at step 15000:\n",
            "[2024-10-23 17:51:34 I]     loss = 0.02860784196257591\n",
            "[2024-10-23 17:51:34 I]     mse = 0.02860784196257591\n",
            "[2024-10-23 17:51:34 I]     rmse = 0.16153356455192175\n",
            "[2024-10-23 17:51:34 I]     output_reg = 0.0\n",
            "[2024-10-23 17:51:34 I]     mae = 0.08791150970458986\n",
            "Training epochs:  32% 7999/25000 [08:11<16:02, 17.66it/s][2024-10-23 17:52:05 I] Starting validation at step 16000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 118.86it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 118.12it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 118.88it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 113.86it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 114.74it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.31it/s]\n",
            "[2024-10-23 17:52:05 I] Validation loop at step 16000:\n",
            "[2024-10-23 17:52:05 I]     loss = 0.027993497359752654\n",
            "[2024-10-23 17:52:05 I]     mse = 0.027993497359752654\n",
            "[2024-10-23 17:52:05 I]     rmse = 0.16007666789529928\n",
            "[2024-10-23 17:52:05 I]     output_reg = 0.0\n",
            "[2024-10-23 17:52:05 I]     mae = 0.08811366069316863\n",
            "Training epochs:  34% 8499/25000 [08:41<14:37, 18.81it/s][2024-10-23 17:52:35 I] Starting validation at step 17000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 118.50it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 120.20it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 118.65it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 118.41it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 117.73it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 117.93it/s]\n",
            "[2024-10-23 17:52:35 I] Validation loop at step 17000:\n",
            "[2024-10-23 17:52:35 I]     loss = 0.027901151537895203\n",
            "[2024-10-23 17:52:35 I]     mse = 0.027901151537895203\n",
            "[2024-10-23 17:52:35 I]     rmse = 0.16015702860356448\n",
            "[2024-10-23 17:52:35 I]     output_reg = 0.0\n",
            "[2024-10-23 17:52:35 I]     mae = 0.08941394650936127\n",
            "Training epochs:  36% 8999/25000 [09:12<15:42, 16.97it/s][2024-10-23 17:53:06 I] Starting validation at step 18000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 123.27it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 121.16it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 120.73it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:00<00:00, 121.31it/s]\u001b[A\n",
            "Evaluating:  82% 65/79 [00:00<00:00, 120.70it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 119.19it/s]\n",
            "[2024-10-23 17:53:07 I] Validation loop at step 18000:\n",
            "[2024-10-23 17:53:07 I]     loss = 0.027143460091948506\n",
            "[2024-10-23 17:53:07 I]     mse = 0.027143460091948506\n",
            "[2024-10-23 17:53:07 I]     rmse = 0.15820909927341376\n",
            "[2024-10-23 17:53:07 I]     output_reg = 0.0\n",
            "[2024-10-23 17:53:07 I]     mae = 0.08859044294357303\n",
            "Training epochs:  38% 9499/25000 [09:43<13:59, 18.46it/s][2024-10-23 17:53:36 I] Starting validation at step 19000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 112.56it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 116.45it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 119.02it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:00<00:00, 120.46it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 116.92it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 118.03it/s]\n",
            "[2024-10-23 17:53:37 I] Validation loop at step 19000:\n",
            "[2024-10-23 17:53:37 I]     loss = 0.026411831462383264\n",
            "[2024-10-23 17:53:37 I]     mse = 0.026411831462383264\n",
            "[2024-10-23 17:53:37 I]     rmse = 0.15600391414295783\n",
            "[2024-10-23 17:53:37 I]     output_reg = 0.0\n",
            "[2024-10-23 17:53:37 I]     mae = 0.08691771588325502\n",
            "Training epochs:  40% 9999/25000 [10:14<16:13, 15.41it/s][2024-10-23 17:54:07 I] Starting validation at step 20000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 121.90it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 113.98it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 115.55it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:00<00:00, 117.53it/s]\u001b[A\n",
            "Evaluating:  80% 63/79 [00:00<00:00, 118.09it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 117.61it/s]\n",
            "[2024-10-23 17:54:08 I] Validation loop at step 20000:\n",
            "[2024-10-23 17:54:08 I]     loss = 0.02731050507128239\n",
            "[2024-10-23 17:54:08 I]     mse = 0.02731050507128239\n",
            "[2024-10-23 17:54:08 I]     rmse = 0.15943903024734254\n",
            "[2024-10-23 17:54:08 I]     output_reg = 0.0\n",
            "[2024-10-23 17:54:08 I]     mae = 0.091188829267025\n",
            "Training epochs:  42% 10499/25000 [10:44<13:25, 18.00it/s][2024-10-23 17:54:37 I] Starting validation at step 21000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 124.69it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 122.10it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 121.56it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:00<00:00, 119.88it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 117.67it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 119.03it/s]\n",
            "[2024-10-23 17:54:38 I] Validation loop at step 21000:\n",
            "[2024-10-23 17:54:38 I]     loss = 0.02746133101582527\n",
            "[2024-10-23 17:54:38 I]     mse = 0.02746133101582527\n",
            "[2024-10-23 17:54:38 I]     rmse = 0.15996764428655266\n",
            "[2024-10-23 17:54:38 I]     output_reg = 0.0\n",
            "[2024-10-23 17:54:38 I]     mae = 0.09195863714218142\n",
            "Training epochs:  44% 10999/25000 [11:15<18:11, 12.83it/s][2024-10-23 17:55:08 I] Starting validation at step 22000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:00, 74.21it/s]\u001b[A\n",
            "Evaluating:  20% 16/79 [00:00<00:00, 73.49it/s]\u001b[A\n",
            "Evaluating:  35% 28/79 [00:00<00:00, 92.90it/s]\u001b[A\n",
            "Evaluating:  52% 41/79 [00:00<00:00, 103.50it/s]\u001b[A\n",
            "Evaluating:  67% 53/79 [00:00<00:00, 106.49it/s]\u001b[A\n",
            "Evaluating:  84% 66/79 [00:00<00:00, 111.22it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 102.62it/s]\n",
            "[2024-10-23 17:55:09 I] Validation loop at step 22000:\n",
            "[2024-10-23 17:55:09 I]     loss = 0.02930883702039719\n",
            "[2024-10-23 17:55:09 I]     mse = 0.02930883702039719\n",
            "[2024-10-23 17:55:09 I]     rmse = 0.1660579351508442\n",
            "[2024-10-23 17:55:09 I]     output_reg = 0.0\n",
            "[2024-10-23 17:55:09 I]     mae = 0.09611231297254563\n",
            "Training epochs:  46% 11499/25000 [11:45<12:19, 18.25it/s][2024-10-23 17:55:38 I] Starting validation at step 23000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 111.39it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 116.58it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 115.02it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 118.04it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 117.75it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 117.95it/s]\n",
            "[2024-10-23 17:55:39 I] Validation loop at step 23000:\n",
            "[2024-10-23 17:55:39 I]     loss = 0.03090078570246696\n",
            "[2024-10-23 17:55:39 I]     mse = 0.03090078570246696\n",
            "[2024-10-23 17:55:39 I]     rmse = 0.1707751081325709\n",
            "[2024-10-23 17:55:39 I]     output_reg = 0.0\n",
            "[2024-10-23 17:55:39 I]     mae = 0.09820149230957029\n",
            "Training epochs:  48% 11999/25000 [12:17<13:54, 15.59it/s][2024-10-23 17:56:10 I] Starting validation at step 24000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 122.77it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 115.85it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 116.38it/s]\u001b[A\n",
            "Evaluating:  65% 51/79 [00:00<00:00, 118.33it/s]\u001b[A\n",
            "Evaluating:  80% 63/79 [00:00<00:00, 117.88it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 118.10it/s]\n",
            "[2024-10-23 17:56:11 I] Validation loop at step 24000:\n",
            "[2024-10-23 17:56:11 I]     loss = 0.035361536633968356\n",
            "[2024-10-23 17:56:11 I]     mse = 0.035361536633968356\n",
            "[2024-10-23 17:56:11 I]     rmse = 0.18370334383828757\n",
            "[2024-10-23 17:56:11 I]     output_reg = 0.0\n",
            "[2024-10-23 17:56:11 I]     mae = 0.10904994292259218\n",
            "Training epochs:  50% 12499/25000 [12:47<11:34, 17.99it/s][2024-10-23 17:56:41 I] Starting validation at step 25000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 117.63it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 116.25it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 115.35it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 115.94it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 117.16it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.86it/s]\n",
            "[2024-10-23 17:56:41 I] Validation loop at step 25000:\n",
            "[2024-10-23 17:56:41 I]     loss = 0.04873898684978485\n",
            "[2024-10-23 17:56:41 I]     mse = 0.04873898684978485\n",
            "[2024-10-23 17:56:41 I]     rmse = 0.21665268816611682\n",
            "[2024-10-23 17:56:41 I]     output_reg = 0.0\n",
            "[2024-10-23 17:56:41 I]     mae = 0.11907720201015479\n",
            "Training epochs:  52% 12999/25000 [13:18<15:09, 13.19it/s][2024-10-23 17:57:12 I] Starting validation at step 26000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 114.16it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 118.01it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 114.86it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 110.73it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 112.60it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.29it/s]\n",
            "[2024-10-23 17:57:12 I] Validation loop at step 26000:\n",
            "[2024-10-23 17:57:12 I]     loss = 0.046440557265281665\n",
            "[2024-10-23 17:57:12 I]     mse = 0.046440557265281665\n",
            "[2024-10-23 17:57:12 I]     rmse = 0.2115353192086333\n",
            "[2024-10-23 17:57:12 I]     output_reg = 0.0\n",
            "[2024-10-23 17:57:12 I]     mae = 0.11664360647201535\n",
            "Training epochs:  54% 13499/25000 [13:49<10:53, 17.60it/s][2024-10-23 17:57:42 I] Starting validation at step 27000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 116.13it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 116.50it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 118.56it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 117.30it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 117.50it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.18it/s]\n",
            "[2024-10-23 17:57:43 I] Validation loop at step 27000:\n",
            "[2024-10-23 17:57:43 I]     loss = 0.04609285097122193\n",
            "[2024-10-23 17:57:43 I]     mse = 0.04609285097122193\n",
            "[2024-10-23 17:57:43 I]     rmse = 0.21069722825943532\n",
            "[2024-10-23 17:57:43 I]     output_reg = 0.0\n",
            "[2024-10-23 17:57:43 I]     mae = 0.11610459623336791\n",
            "Training epochs:  56% 13999/25000 [14:20<13:52, 13.22it/s][2024-10-23 17:58:13 I] Starting validation at step 28000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  10% 8/79 [00:00<00:00, 78.22it/s]\u001b[A\n",
            "Evaluating:  22% 17/79 [00:00<00:00, 81.31it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 81.91it/s]\u001b[A\n",
            "Evaluating:  44% 35/79 [00:00<00:00, 76.96it/s]\u001b[A\n",
            "Evaluating:  54% 43/79 [00:00<00:00, 76.93it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:00<00:00, 78.19it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 76.92it/s]\u001b[A\n",
            "Evaluating:  86% 68/79 [00:00<00:00, 75.44it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:01<00:00, 78.49it/s]\n",
            "[2024-10-23 17:58:14 I] Validation loop at step 28000:\n",
            "[2024-10-23 17:58:14 I]     loss = 0.044295524072647106\n",
            "[2024-10-23 17:58:14 I]     mse = 0.044295524072647106\n",
            "[2024-10-23 17:58:14 I]     rmse = 0.2065325279586847\n",
            "[2024-10-23 17:58:14 I]     output_reg = 0.0\n",
            "[2024-10-23 17:58:14 I]     mae = 0.11470222077369692\n",
            "Training epochs:  58% 14499/25000 [14:50<09:31, 18.37it/s][2024-10-23 17:58:44 I] Starting validation at step 29000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 115.37it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 119.30it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 112.87it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 116.26it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 115.61it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.04it/s]\n",
            "[2024-10-23 17:58:44 I] Validation loop at step 29000:\n",
            "[2024-10-23 17:58:44 I]     loss = 0.04418216884136199\n",
            "[2024-10-23 17:58:44 I]     mse = 0.04418216884136199\n",
            "[2024-10-23 17:58:44 I]     rmse = 0.20617791673787217\n",
            "[2024-10-23 17:58:44 I]     output_reg = 0.0\n",
            "[2024-10-23 17:58:44 I]     mae = 0.11412297840118409\n",
            "Training epochs:  60% 14999/25000 [15:20<10:57, 15.22it/s][2024-10-23 17:59:14 I] Starting validation at step 30000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  11% 9/79 [00:00<00:00, 84.41it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:00<00:00, 87.19it/s]\u001b[A\n",
            "Evaluating:  34% 27/79 [00:00<00:00, 85.93it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 86.71it/s]\u001b[A\n",
            "Evaluating:  57% 45/79 [00:00<00:00, 87.76it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:00<00:00, 82.61it/s]\u001b[A\n",
            "Evaluating:  80% 63/79 [00:00<00:00, 80.86it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 82.01it/s]\n",
            "[2024-10-23 17:59:15 I] Validation loop at step 30000:\n",
            "[2024-10-23 17:59:15 I]     loss = 0.043421148705482464\n",
            "[2024-10-23 17:59:15 I]     mse = 0.043421148705482464\n",
            "[2024-10-23 17:59:15 I]     rmse = 0.2044275521264531\n",
            "[2024-10-23 17:59:15 I]     output_reg = 0.0\n",
            "[2024-10-23 17:59:15 I]     mae = 0.1132638967990875\n",
            "Training epochs:  62% 15499/25000 [15:51<08:37, 18.36it/s][2024-10-23 17:59:44 I] Starting validation at step 31000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 117.25it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 118.84it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 117.95it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 117.64it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 113.50it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.69it/s]\n",
            "[2024-10-23 17:59:45 I] Validation loop at step 31000:\n",
            "[2024-10-23 17:59:45 I]     loss = 0.046618350362777713\n",
            "[2024-10-23 17:59:45 I]     mse = 0.046618350362777713\n",
            "[2024-10-23 17:59:45 I]     rmse = 0.21113676919844462\n",
            "[2024-10-23 17:59:45 I]     output_reg = 0.0\n",
            "[2024-10-23 17:59:45 I]     mae = 0.11542806422710417\n",
            "Training epochs:  64% 15999/25000 [16:21<08:13, 18.26it/s][2024-10-23 18:00:15 I] Starting validation at step 32000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  11% 9/79 [00:00<00:00, 89.25it/s]\u001b[A\n",
            "Evaluating:  23% 18/79 [00:00<00:00, 78.20it/s]\u001b[A\n",
            "Evaluating:  34% 27/79 [00:00<00:00, 80.19it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 81.70it/s]\u001b[A\n",
            "Evaluating:  57% 45/79 [00:00<00:00, 83.88it/s]\u001b[A\n",
            "Evaluating:  68% 54/79 [00:00<00:00, 84.66it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 86.59it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 84.87it/s]\n",
            "[2024-10-23 18:00:15 I] Validation loop at step 32000:\n",
            "[2024-10-23 18:00:15 I]     loss = 0.04505182678699494\n",
            "[2024-10-23 18:00:15 I]     mse = 0.04505182678699494\n",
            "[2024-10-23 18:00:15 I]     rmse = 0.20761083849529177\n",
            "[2024-10-23 18:00:15 I]     output_reg = 0.0\n",
            "[2024-10-23 18:00:16 I]     mae = 0.11428800292015076\n",
            "Training epochs:  66% 16499/25000 [16:52<07:51, 18.03it/s][2024-10-23 18:00:46 I] Starting validation at step 33000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  14% 11/79 [00:00<00:00, 107.88it/s]\u001b[A\n",
            "Evaluating:  29% 23/79 [00:00<00:00, 112.34it/s]\u001b[A\n",
            "Evaluating:  44% 35/79 [00:00<00:00, 115.69it/s]\u001b[A\n",
            "Evaluating:  59% 47/79 [00:00<00:00, 115.52it/s]\u001b[A\n",
            "Evaluating:  75% 59/79 [00:00<00:00, 114.20it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.28it/s]\n",
            "[2024-10-23 18:00:46 I] Validation loop at step 33000:\n",
            "[2024-10-23 18:00:46 I]     loss = 0.044414646816253664\n",
            "[2024-10-23 18:00:46 I]     mse = 0.044414646816253664\n",
            "[2024-10-23 18:00:46 I]     rmse = 0.2061413310960404\n",
            "[2024-10-23 18:00:46 I]     output_reg = 0.0\n",
            "[2024-10-23 18:00:46 I]     mae = 0.11338262555599213\n",
            "Training epochs:  68% 17000/25000 [17:28<07:48, 17.06it/s][2024-10-23 18:01:21 I] Starting validation at step 34000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 121.35it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 118.91it/s]\u001b[A\n",
            "Evaluating:  49% 39/79 [00:00<00:00, 120.30it/s]\u001b[A\n",
            "Evaluating:  66% 52/79 [00:00<00:00, 118.38it/s]\u001b[A\n",
            "Evaluating:  81% 64/79 [00:00<00:00, 118.91it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 118.49it/s]\n",
            "[2024-10-23 18:01:22 I] Validation loop at step 34000:\n",
            "[2024-10-23 18:01:22 I]     loss = 0.04407984952926634\n",
            "[2024-10-23 18:01:22 I]     mse = 0.04407984952926634\n",
            "[2024-10-23 18:01:22 I]     rmse = 0.20542592893108205\n",
            "[2024-10-23 18:01:22 I]     output_reg = 0.0\n",
            "[2024-10-23 18:01:22 I]     mae = 0.11318310143947599\n",
            "Training epochs:  70% 17500/25000 [17:58<06:55, 18.06it/s][2024-10-23 18:01:52 I] Starting validation at step 35000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 121.76it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 117.51it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 117.71it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 115.51it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 115.34it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.21it/s]\n",
            "[2024-10-23 18:01:52 I] Validation loop at step 35000:\n",
            "[2024-10-23 18:01:52 I]     loss = 0.04397360854148865\n",
            "[2024-10-23 18:01:52 I]     mse = 0.04397360854148865\n",
            "[2024-10-23 18:01:52 I]     rmse = 0.20534010806883932\n",
            "[2024-10-23 18:01:52 I]     output_reg = 0.0\n",
            "[2024-10-23 18:01:52 I]     mae = 0.1130923876523972\n",
            "Training epochs:  72% 18000/25000 [18:30<07:05, 16.47it/s][2024-10-23 18:02:23 I] Starting validation at step 36000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 116.09it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 111.39it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 115.10it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 112.51it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 114.99it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.71it/s]\n",
            "[2024-10-23 18:02:24 I] Validation loop at step 36000:\n",
            "[2024-10-23 18:02:24 I]     loss = 0.0435972202539444\n",
            "[2024-10-23 18:02:24 I]     mse = 0.0435972202539444\n",
            "[2024-10-23 18:02:24 I]     rmse = 0.2044589175962757\n",
            "[2024-10-23 18:02:24 I]     output_reg = 0.0\n",
            "[2024-10-23 18:02:24 I]     mae = 0.11305316705703736\n",
            "Training epochs:  74% 18500/25000 [19:01<05:59, 18.09it/s][2024-10-23 18:02:54 I] Starting validation at step 37000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 118.75it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 119.23it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 117.20it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 112.86it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 113.57it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.87it/s]\n",
            "[2024-10-23 18:02:55 I] Validation loop at step 37000:\n",
            "[2024-10-23 18:02:55 I]     loss = 0.04317123694419861\n",
            "[2024-10-23 18:02:55 I]     mse = 0.04317123694419861\n",
            "[2024-10-23 18:02:55 I]     rmse = 0.20345256707061535\n",
            "[2024-10-23 18:02:55 I]     output_reg = 0.0\n",
            "[2024-10-23 18:02:55 I]     mae = 0.11239189052581787\n",
            "Training epochs:  76% 19000/25000 [19:32<06:22, 15.69it/s][2024-10-23 18:03:25 I] Starting validation at step 38000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 119.89it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 118.10it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 114.31it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 114.19it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 113.09it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 111.22it/s]\n",
            "[2024-10-23 18:03:26 I] Validation loop at step 38000:\n",
            "[2024-10-23 18:03:26 I]     loss = 0.04281266052722932\n",
            "[2024-10-23 18:03:26 I]     mse = 0.04281266052722932\n",
            "[2024-10-23 18:03:26 I]     rmse = 0.2026129947634214\n",
            "[2024-10-23 18:03:26 I]     output_reg = 0.0\n",
            "[2024-10-23 18:03:26 I]     mae = 0.11220143003463748\n",
            "Training epochs:  78% 19500/25000 [20:03<05:08, 17.81it/s][2024-10-23 18:03:56 I] Starting validation at step 39000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 114.95it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 108.88it/s]\u001b[A\n",
            "Evaluating:  44% 35/79 [00:00<00:00, 107.65it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:00<00:00, 107.27it/s]\u001b[A\n",
            "Evaluating:  72% 57/79 [00:00<00:00, 106.91it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 108.73it/s]\n",
            "[2024-10-23 18:03:57 I] Validation loop at step 39000:\n",
            "[2024-10-23 18:03:57 I]     loss = 0.04267220447063446\n",
            "[2024-10-23 18:03:57 I]     mse = 0.04267220447063446\n",
            "[2024-10-23 18:03:57 I]     rmse = 0.20230720165723515\n",
            "[2024-10-23 18:03:57 I]     output_reg = 0.0\n",
            "[2024-10-23 18:03:57 I]     mae = 0.11235103607177732\n",
            "Training epochs:  80% 19999/25000 [20:36<05:26, 15.32it/s][2024-10-23 18:04:29 I] Starting validation at step 40000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 118.81it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 121.10it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 104.48it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 108.43it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 108.07it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 110.98it/s]\n",
            "[2024-10-23 18:04:30 I] Validation loop at step 40000:\n",
            "[2024-10-23 18:04:30 I]     loss = 0.04259833583831787\n",
            "[2024-10-23 18:04:30 I]     mse = 0.04259833583831787\n",
            "[2024-10-23 18:04:30 I]     rmse = 0.20213090053208416\n",
            "[2024-10-23 18:04:30 I]     output_reg = 0.0\n",
            "[2024-10-23 18:04:30 I]     mae = 0.11222371530532839\n",
            "Training epochs:  82% 20499/25000 [21:06<04:07, 18.19it/s][2024-10-23 18:05:00 I] Starting validation at step 41000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 119.90it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 117.88it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 116.22it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 116.89it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 117.81it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 115.42it/s]\n",
            "[2024-10-23 18:05:01 I] Validation loop at step 41000:\n",
            "[2024-10-23 18:05:01 I]     loss = 0.042430824637413024\n",
            "[2024-10-23 18:05:01 I]     mse = 0.042430824637413024\n",
            "[2024-10-23 18:05:01 I]     rmse = 0.2017319249806811\n",
            "[2024-10-23 18:05:01 I]     output_reg = 0.0\n",
            "[2024-10-23 18:05:01 I]     mae = 0.11210995121002196\n",
            "Training epochs:  84% 20999/25000 [21:38<04:29, 14.84it/s][2024-10-23 18:05:32 I] Starting validation at step 42000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 114.84it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 109.70it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 112.67it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 115.98it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 115.51it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.03it/s]\n",
            "[2024-10-23 18:05:32 I] Validation loop at step 42000:\n",
            "[2024-10-23 18:05:32 I]     loss = 0.04230563161373139\n",
            "[2024-10-23 18:05:32 I]     mse = 0.04230563161373139\n",
            "[2024-10-23 18:05:32 I]     rmse = 0.20145072770872774\n",
            "[2024-10-23 18:05:32 I]     output_reg = 0.0\n",
            "[2024-10-23 18:05:32 I]     mae = 0.11198139085769653\n",
            "Training epochs:  86% 21499/25000 [22:09<03:11, 18.24it/s][2024-10-23 18:06:03 I] Starting validation at step 43000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 113.35it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 116.35it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 117.32it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 116.60it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 116.42it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.45it/s]\n",
            "[2024-10-23 18:06:04 I] Validation loop at step 43000:\n",
            "[2024-10-23 18:06:04 I]     loss = 0.04332050566673279\n",
            "[2024-10-23 18:06:04 I]     mse = 0.04332050566673279\n",
            "[2024-10-23 18:06:04 I]     rmse = 0.20384926997615152\n",
            "[2024-10-23 18:06:04 I]     output_reg = 0.0\n",
            "[2024-10-23 18:06:04 I]     mae = 0.11316163840293886\n",
            "Training epochs:  88% 22000/25000 [22:42<03:25, 14.63it/s][2024-10-23 18:06:36 I] Starting validation at step 44000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 110.35it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 113.74it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 110.54it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 113.28it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 109.98it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 112.10it/s]\n",
            "[2024-10-23 18:06:36 I] Validation loop at step 44000:\n",
            "[2024-10-23 18:06:36 I]     loss = 0.04306132504940034\n",
            "[2024-10-23 18:06:36 I]     mse = 0.04306132504940034\n",
            "[2024-10-23 18:06:36 I]     rmse = 0.20324723869661743\n",
            "[2024-10-23 18:06:36 I]     output_reg = 0.0\n",
            "[2024-10-23 18:06:36 I]     mae = 0.11281780192852019\n",
            "Training epochs:  90% 22500/25000 [23:14<02:17, 18.12it/s][2024-10-23 18:07:07 I] Starting validation at step 45000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  16% 13/79 [00:00<00:00, 121.60it/s]\u001b[A\n",
            "Evaluating:  33% 26/79 [00:00<00:00, 118.37it/s]\u001b[A\n",
            "Evaluating:  48% 38/79 [00:00<00:00, 116.97it/s]\u001b[A\n",
            "Evaluating:  63% 50/79 [00:00<00:00, 113.17it/s]\u001b[A\n",
            "Evaluating:  78% 62/79 [00:00<00:00, 110.91it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.47it/s]\n",
            "[2024-10-23 18:07:08 I] Validation loop at step 45000:\n",
            "[2024-10-23 18:07:08 I]     loss = 0.04296398921012878\n",
            "[2024-10-23 18:07:08 I]     mse = 0.04296398921012878\n",
            "[2024-10-23 18:07:08 I]     rmse = 0.20304614862623724\n",
            "[2024-10-23 18:07:08 I]     output_reg = 0.0\n",
            "[2024-10-23 18:07:08 I]     mae = 0.1128266556739807\n",
            "Training epochs:  92% 23000/25000 [23:45<02:27, 13.51it/s][2024-10-23 18:07:39 I] Starting validation at step 46000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  14% 11/79 [00:00<00:00, 108.05it/s]\u001b[A\n",
            "Evaluating:  28% 22/79 [00:00<00:00, 106.09it/s]\u001b[A\n",
            "Evaluating:  43% 34/79 [00:00<00:00, 111.62it/s]\u001b[A\n",
            "Evaluating:  58% 46/79 [00:00<00:00, 114.63it/s]\u001b[A\n",
            "Evaluating:  73% 58/79 [00:00<00:00, 109.92it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 111.04it/s]\n",
            "[2024-10-23 18:07:39 I] Validation loop at step 46000:\n",
            "[2024-10-23 18:07:39 I]     loss = 0.042916356229782106\n",
            "[2024-10-23 18:07:39 I]     mse = 0.042916356229782106\n",
            "[2024-10-23 18:07:40 I]     rmse = 0.20295652534133593\n",
            "[2024-10-23 18:07:40 I]     output_reg = 0.0\n",
            "[2024-10-23 18:07:40 I]     mae = 0.11285866947174074\n",
            "Training epochs:  94% 23499/25000 [24:17<01:22, 18.24it/s][2024-10-23 18:08:11 I] Starting validation at step 47000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 118.25it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 111.55it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 114.53it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 114.35it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 116.04it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 116.05it/s]\n",
            "[2024-10-23 18:08:12 I] Validation loop at step 47000:\n",
            "[2024-10-23 18:08:12 I]     loss = 0.0429040369272232\n",
            "[2024-10-23 18:08:12 I]     mse = 0.0429040369272232\n",
            "[2024-10-23 18:08:12 I]     rmse = 0.20294593138628084\n",
            "[2024-10-23 18:08:12 I]     output_reg = 0.0\n",
            "[2024-10-23 18:08:12 I]     mae = 0.11302154903411869\n",
            "Training epochs:  96% 23999/25000 [24:49<00:58, 17.25it/s][2024-10-23 18:08:43 I] Starting validation at step 48000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 119.00it/s]\u001b[A\n",
            "Evaluating:  30% 24/79 [00:00<00:00, 113.32it/s]\u001b[A\n",
            "Evaluating:  46% 36/79 [00:00<00:00, 113.50it/s]\u001b[A\n",
            "Evaluating:  61% 48/79 [00:00<00:00, 113.40it/s]\u001b[A\n",
            "Evaluating:  76% 60/79 [00:00<00:00, 112.28it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 112.45it/s]\n",
            "[2024-10-23 18:08:44 I] Validation loop at step 48000:\n",
            "[2024-10-23 18:08:44 I]     loss = 0.0428515367746353\n",
            "[2024-10-23 18:08:44 I]     mse = 0.0428515367746353\n",
            "[2024-10-23 18:08:44 I]     rmse = 0.20285054952464657\n",
            "[2024-10-23 18:08:44 I]     output_reg = 0.0\n",
            "[2024-10-23 18:08:44 I]     mae = 0.11298433525562289\n",
            "Training epochs:  98% 24499/25000 [25:21<00:29, 17.08it/s][2024-10-23 18:09:14 I] Starting validation at step 49000\n",
            "\n",
            "Evaluating:   0% 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  15% 12/79 [00:00<00:00, 113.79it/s]\u001b[A\n",
            "Evaluating:  32% 25/79 [00:00<00:00, 118.91it/s]\u001b[A\n",
            "Evaluating:  47% 37/79 [00:00<00:00, 113.89it/s]\u001b[A\n",
            "Evaluating:  62% 49/79 [00:00<00:00, 112.06it/s]\u001b[A\n",
            "Evaluating:  77% 61/79 [00:00<00:00, 113.35it/s]\u001b[A\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 110.78it/s]\n",
            "[2024-10-23 18:09:15 I] Validation loop at step 49000:\n",
            "[2024-10-23 18:09:15 I]     loss = 0.04279590804576875\n",
            "[2024-10-23 18:09:15 I]     mse = 0.04279590804576875\n",
            "[2024-10-23 18:09:15 I]     rmse = 0.2027465465949883\n",
            "[2024-10-23 18:09:15 I]     output_reg = 0.0\n",
            "[2024-10-23 18:09:15 I]     mae = 0.11311863646507266\n",
            "Training epochs: 100% 25000/25000 [25:53<00:00, 16.09it/s]\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 113.27it/s]\n",
            "[2024-10-23 18:09:47 I] Validation loop at step 50000:\n",
            "[2024-10-23 18:09:47 I]     loss = 0.042644063425064084\n",
            "[2024-10-23 18:09:47 I]     mse = 0.042644063425064084\n",
            "[2024-10-23 18:09:47 I]     rmse = 0.20243426179631474\n",
            "[2024-10-23 18:09:47 I]     output_reg = 0.0\n",
            "[2024-10-23 18:09:47 I]     mae = 0.11300377130508424\n",
            "[2024-10-23 18:09:47 I] Early stopping after step 19000 with validation loss 0.026411831462383264\n",
            "[2024-10-23 18:09:47 I] Saving model at $/content/nbody_data/experiments/nbody/transformer100_50000/models/model_final.pt\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 112.47it/s]\n",
            "[2024-10-23 18:09:48 I] Ran evaluation on dataset eval:\n",
            "[2024-10-23 18:09:48 I]     loss = 0.03962949382513763\n",
            "[2024-10-23 18:09:48 I]     mse = 0.03962949382513763\n",
            "[2024-10-23 18:09:48 I]     rmse = 0.19612822999825963\n",
            "[2024-10-23 18:09:48 I]     output_reg = 0.0\n",
            "[2024-10-23 18:09:48 I]     mae = 0.11069514095783234\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 114.17it/s]\n",
            "[2024-10-23 18:09:48 I] Ran evaluation on dataset object_generalization:\n",
            "[2024-10-23 18:09:48 I]     loss = 0.05607044000923634\n",
            "[2024-10-23 18:09:48 I]     mse = 0.05607044000923634\n",
            "[2024-10-23 18:09:48 I]     rmse = 0.23327396673648326\n",
            "[2024-10-23 18:09:48 I]     output_reg = 0.0\n",
            "[2024-10-23 18:09:48 I]     mae = 0.12997334630489343\n",
            "Evaluating: 100% 79/79 [00:00<00:00, 109.37it/s]\n",
            "[2024-10-23 18:09:49 I] Ran evaluation on dataset e3_generalization:\n",
            "[2024-10-23 18:09:49 I]     loss = 186.68723229980475\n",
            "[2024-10-23 18:09:49 I]     mse = 186.68723229980475\n",
            "[2024-10-23 18:09:49 I]     rmse = 13.66007093623536\n",
            "[2024-10-23 18:09:49 I]     output_reg = 0.0\n",
            "[2024-10-23 18:09:49 I]     mae = 9.607181828308105\n",
            "[2024-10-23 18:09:49 I] Anders nog iets?\n"
          ]
        }
      ]
    }
  ]
}